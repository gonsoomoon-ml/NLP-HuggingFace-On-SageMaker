{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bf24480-8149-4fd1-98d8-0ecd0e9ead3c",
   "metadata": {},
   "source": [
    "# Warming Up - Combined Multiple Models\n",
    "\n",
    "\n",
    "이 노트북은 독립적으로 모델1, 모델2를 생성을 하고, 이 두개의 모델의 추론 결과를 한개의 통합된 모델에서 추론하는 예제 입니다. 이를 위해서 다음과 같은 작업을 합니다.\n",
    "\n",
    "- 첫번재 Mnist 모델 생성 및 훈련\n",
    "- 두번째 Mnist 모델 생성 및 훈련\n",
    "- 첫번재, 두번째의 모델을 한개의 모델로 통합\n",
    "- 통합된 모델에서 각각 모델의 추론 결과를 얻음\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 참조: \n",
    "- 딥러닝으로 리뷰에서 제품 속성 정보 추출하기\n",
    "    * http://blog.hwahae.co.kr/all/tech/tech-tech/5967/\n",
    "- PyTorch Quick Start\n",
    "    - https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299541e1-1145-4800-b8d9-a1e19b1ffada",
   "metadata": {},
   "source": [
    "# 0. 환경 셋업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3be84f41-a29a-4ccc-93dd-015837e14929",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e220c15d-3cc4-4cd5-b9b2-dbbee9eaff99",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4a2639a-d64e-4f84-bfda-983d45b52407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49db3c14-273a-42d2-a704-938b738e486a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([100, 1, 28, 28])\n",
      "Shape of y: torch.Size([100]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "train_batch_size = 64\n",
    "test_batch_size = 100\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=train_batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=test_batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e586f5-daa6-4c14-87a1-c4ce9a02c5f5",
   "metadata": {},
   "source": [
    "# 2. 첫번째 및 두번째 모델  준비"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c63fb0-1a86-407b-b6fb-7706c3500375",
   "metadata": {},
   "source": [
    "## 2.1 두개의 모델 정의 및 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "712cf05c-d85d-432d-8920-89b5a2512a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model_01 = NeuralNetwork().to(device)\n",
    "print(model_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ad3559f-de74-4b65-bc86-32e059773fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_02 = NeuralNetwork().to(device)\n",
    "print(model_02)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371ad0e3-419c-44a5-b1c5-1063d477ce6d",
   "metadata": {},
   "source": [
    "## 2.2. 훈련 준비 작업\n",
    "- Loss() 정의\n",
    "- 옵티아이저 정의\n",
    "- 훈련, 테스트 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0666d191-6d58-451e-aca0-dbd683123972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_loss_optimizer(model):\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "    \n",
    "    return loss_fn, optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "184858ad-7fa3-4e96-9581-e3beb74b15a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66478b9b-c190-4556-abdd-9e2f629e9a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d82000-136e-4c42-b99c-6b7fbbbe5252",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.3. 첫번째 모델 훈련 및 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5ede74e-820d-4cb7-aa44-280f83cbba47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.302132  [    0/60000]\n",
      "loss: 2.289945  [ 6400/60000]\n",
      "loss: 2.266256  [12800/60000]\n",
      "loss: 2.263689  [19200/60000]\n",
      "loss: 2.238970  [25600/60000]\n",
      "loss: 2.215589  [32000/60000]\n",
      "loss: 2.228728  [38400/60000]\n",
      "loss: 2.196063  [44800/60000]\n",
      "loss: 2.193371  [51200/60000]\n",
      "loss: 2.154253  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 38.5%, Avg loss: 2.151891 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "loss_fn , optimizer = create_loss_optimizer(model_01)\n",
    "\n",
    "epochs = 1\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    model_01 = train(train_dataloader, model_01, loss_fn, optimizer)\n",
    "    test(test_dataloader, model_01, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1c67e9-f0c8-4f9f-8a99-9762d4c27f2e",
   "metadata": {},
   "source": [
    "### 2.3.1 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6fd221b-bb5a-4424-a92c-1bfe802a972f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model_01.pth\n"
     ]
    }
   ],
   "source": [
    "def save_model(model, i):\n",
    "    torch.save(model.state_dict(), f\"model_0{i}.pth\")\n",
    "    print(f\"Saved PyTorch Model State to model_0{i}.pth\")\n",
    "    \n",
    "save_model(model_01, i=1)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8030c5e4-9b1f-478b-bbf5-0e50fe832fbf",
   "metadata": {},
   "source": [
    "### 2.3.2 모델 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2179f9cd-f98c-491d-be3b-f0408767e72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path,i):\n",
    "    model = NeuralNetwork()\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.to(device)\n",
    "    \n",
    "    return model\n",
    "    \n",
    "model_path = \"model_01.pth\"    \n",
    "model_01 = load_model(model_path,i=1)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb0f769-517a-4b7e-82e6-8a5cb65acbc9",
   "metadata": {},
   "source": [
    "### 2.3.3. 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68f64c63-2f68-4804-ab6b-9da28a97bd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "\n",
    "def predict(model):\n",
    "\n",
    "    model.eval()\n",
    "    X, y = test_data[0][0], test_data[0][1]\n",
    "    X = X.to(device)\n",
    "    with torch.no_grad():\n",
    "        pred = model(X)\n",
    "        predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "        print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d4bcaee-95ac-48c0-9009-cfdf29114b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "predict(model_01)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a09a18e-4e57-4694-a7ef-3f7b84b76a9c",
   "metadata": {},
   "source": [
    "## 2.4 두 번째 모델 훈련 및 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87186186-0f01-4e74-aaa0-75455590d821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.298704  [    0/60000]\n",
      "loss: 2.292320  [ 6400/60000]\n",
      "loss: 2.266799  [12800/60000]\n",
      "loss: 2.265103  [19200/60000]\n",
      "loss: 2.254033  [25600/60000]\n",
      "loss: 2.208532  [32000/60000]\n",
      "loss: 2.227392  [38400/60000]\n",
      "loss: 2.183111  [44800/60000]\n",
      "loss: 2.189458  [51200/60000]\n",
      "loss: 2.147223  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 36.2%, Avg loss: 2.141000 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.154752  [    0/60000]\n",
      "loss: 2.148218  [ 6400/60000]\n",
      "loss: 2.082286  [12800/60000]\n",
      "loss: 2.097595  [19200/60000]\n",
      "loss: 2.059641  [25600/60000]\n",
      "loss: 1.988723  [32000/60000]\n",
      "loss: 2.019038  [38400/60000]\n",
      "loss: 1.933569  [44800/60000]\n",
      "loss: 1.944044  [51200/60000]\n",
      "loss: 1.859702  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 56.4%, Avg loss: 1.858879 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.898810  [    0/60000]\n",
      "loss: 1.870333  [ 6400/60000]\n",
      "loss: 1.743841  [12800/60000]\n",
      "loss: 1.780634  [19200/60000]\n",
      "loss: 1.692805  [25600/60000]\n",
      "loss: 1.639441  [32000/60000]\n",
      "loss: 1.656315  [38400/60000]\n",
      "loss: 1.557989  [44800/60000]\n",
      "loss: 1.586953  [51200/60000]\n",
      "loss: 1.475935  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 60.2%, Avg loss: 1.496894 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "loss_fn , optimizer = create_loss_optimizer(model_02)\n",
    "\n",
    "epochs = 3\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    model_02 = train(train_dataloader, model_02, loss_fn, optimizer)\n",
    "    test(test_dataloader, model_02, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7bbd317d-39da-4e79-ba3d-b67e286919da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model_02.pth\n"
     ]
    }
   ],
   "source": [
    "save_model(model_02, i=2)    \n",
    "model_path = \"model_02.pth\"    \n",
    "model_02 = load_model(model_path,i=2)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98609287-0182-4fc8-aed3-e83292d6d65f",
   "metadata": {},
   "source": [
    "# 3. 두 개의 모델을 한개의 모델로 통합"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50aafdcb-3e40-47c6-abb4-4ffc770c64c9",
   "metadata": {},
   "source": [
    "## 3.1. 두개의모델을 통합 및 네트워크 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c210acc6-c291-44cc-b645-808055a5ffea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CombinedNeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (base_model): NeuralNetwork(\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "    (linear_relu_stack): Sequential(\n",
      "      (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (add_model): NeuralNetwork(\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "    (linear_relu_stack): Sequential(\n",
      "      (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "class CombinedNeuralNetwork(nn.Module):\n",
    "    def __init__(self, base_model, add_model):\n",
    "        super(CombinedNeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()        \n",
    "        self.base_model = base_model\n",
    "        self.add_model = add_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x_base = self.base_model(x)\n",
    "        x_add  = self.add_model(x)\n",
    "\n",
    "        return x_base, x_add\n",
    "\n",
    "CombinedModel = CombinedNeuralNetwork(model_01, model_02).to(device)\n",
    "print(CombinedModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c68579-ed1c-4065-820d-59c83e97e2ce",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3.2. 통합된 모델을 예측 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2e99eb3-bbc6-401a-bf68-33608d5bdba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X :  torch.Size([100, 1, 28, 28])\n",
      "Combined Model - probs shape:  (2,)\n",
      "Ground_Truth: \n",
      " tensor([9, 2, 1, 1, 6, 1, 4, 6, 5, 7, 4, 5, 7, 3, 4, 1, 2, 4, 8, 0, 2, 5, 7, 9,\n",
      "        1, 4, 6, 0, 9, 3, 8, 8, 3, 3, 8, 0, 7, 5, 7, 9, 6, 1, 3, 7, 6, 7, 2, 1,\n",
      "        2, 2, 4, 4, 5, 8, 2, 2, 8, 4, 8, 0, 7, 7, 8, 5, 1, 1, 2, 3, 9, 8, 7, 0,\n",
      "        2, 6, 2, 3, 1, 2, 8, 4, 1, 8, 5, 9, 5, 0, 3, 2, 0, 6, 5, 3, 6, 7, 1, 8,\n",
      "        0, 1, 4, 2], device='cuda:0') \n",
      "\n",
      "From model_01 - Predicted Label:\n",
      "tensor([9, 4, 1, 1, 4, 4, 4, 4, 8, 7, 4, 9, 9, 3, 4, 1, 4, 4, 8, 0, 4, 9, 9, 9,\n",
      "        1, 4, 4, 0, 9, 4, 8, 4, 1, 4, 4, 4, 8, 8, 8, 9, 0, 1, 4, 9, 4, 9, 4, 1,\n",
      "        4, 4, 4, 4, 8, 4, 4, 4, 8, 4, 8, 0, 8, 9, 9, 9, 1, 1, 4, 0, 9, 8, 9, 4,\n",
      "        4, 4, 4, 4, 1, 4, 9, 4, 1, 8, 9, 9, 9, 0, 4, 4, 0, 4, 9, 4, 4, 9, 1, 9,\n",
      "        4, 1, 4, 4], device='cuda:0')\n",
      "From model_01 Accuracy: 41.00% \n",
      "\n",
      "From model_02 - Predicted Label:\n",
      "tensor([9, 2, 1, 1, 2, 1, 4, 4, 7, 7, 4, 9, 7, 3, 4, 1, 2, 2, 8, 0, 2, 7, 7, 9,\n",
      "        1, 4, 4, 3, 9, 0, 8, 0, 3, 0, 8, 0, 7, 7, 7, 9, 0, 1, 0, 9, 4, 9, 2, 1,\n",
      "        4, 4, 2, 2, 7, 2, 4, 2, 8, 4, 8, 0, 7, 7, 8, 7, 1, 1, 3, 1, 9, 8, 7, 0,\n",
      "        2, 0, 4, 1, 1, 2, 8, 4, 1, 8, 9, 9, 7, 0, 3, 4, 0, 2, 7, 3, 4, 7, 1, 8,\n",
      "        0, 1, 4, 2], device='cuda:0')\n",
      "From model_02 Accuracy: 64.00% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def predict(dataloader, model, i, test_batch_size):\n",
    "    '''\n",
    "    싱글 모델의 첫번째 배치만 평가 함.\n",
    "    '''\n",
    "    \n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            ground_truth = y\n",
    "            print(\"Ground_Truth: \\n\", ground_truth, \"\\n\")\n",
    "            \n",
    "            pred = model(X)\n",
    "            print(f\"From model_0{i+1} - Predicted Label:\")                \n",
    "            print(pred.argmax(1))\n",
    "\n",
    "            \n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            \n",
    "            break\n",
    "\n",
    "    correct /=  test_batch_size\n",
    "    print(f\"From model_0{i} Accuracy: {(100*correct):>0.2f}% \\n\")\n",
    "\n",
    "\n",
    "\n",
    "def predict_c(dataloader, model, test_batch_size):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            print(\"X : \", X.shape)\n",
    "            probs = model(X)\n",
    "            \n",
    "            print(\"Combined Model - probs shape: \", np.array(probs).shape)\n",
    "            #print(\"probs \\n\", probs)\n",
    "            \n",
    "            ground_truth = y\n",
    "            print(\"Ground_Truth: \\n\", ground_truth, \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "            for i, pred in enumerate(probs):\n",
    "                print(f\"From model_0{i+1} - Predicted Label:\")                \n",
    "                print(pred.argmax(1))\n",
    "                correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "                correct /= test_batch_size\n",
    "\n",
    "                print(f\"From model_0{i+1} Accuracy: {(100*correct):>0.2f}% \\n\")\n",
    "                \n",
    "                correct= 0\n",
    "                \n",
    "            break\n",
    "                \n",
    "predict_c(test_dataloader, CombinedModel, test_batch_size)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8023229b-ce80-4c07-9ea6-51697da29c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground_Truth: \n",
      " tensor([9, 2, 1, 1, 6, 1, 4, 6, 5, 7, 4, 5, 7, 3, 4, 1, 2, 4, 8, 0, 2, 5, 7, 9,\n",
      "        1, 4, 6, 0, 9, 3, 8, 8, 3, 3, 8, 0, 7, 5, 7, 9, 6, 1, 3, 7, 6, 7, 2, 1,\n",
      "        2, 2, 4, 4, 5, 8, 2, 2, 8, 4, 8, 0, 7, 7, 8, 5, 1, 1, 2, 3, 9, 8, 7, 0,\n",
      "        2, 6, 2, 3, 1, 2, 8, 4, 1, 8, 5, 9, 5, 0, 3, 2, 0, 6, 5, 3, 6, 7, 1, 8,\n",
      "        0, 1, 4, 2], device='cuda:0') \n",
      "\n",
      "From model_03 - Predicted Label:\n",
      "tensor([9, 2, 1, 1, 2, 1, 4, 4, 7, 7, 4, 9, 7, 3, 4, 1, 2, 2, 8, 0, 2, 7, 7, 9,\n",
      "        1, 4, 4, 3, 9, 0, 8, 0, 3, 0, 8, 0, 7, 7, 7, 9, 0, 1, 0, 9, 4, 9, 2, 1,\n",
      "        4, 4, 2, 2, 7, 2, 4, 2, 8, 4, 8, 0, 7, 7, 8, 7, 1, 1, 3, 1, 9, 8, 7, 0,\n",
      "        2, 0, 4, 1, 1, 2, 8, 4, 1, 8, 9, 9, 7, 0, 3, 4, 0, 2, 7, 3, 4, 7, 1, 8,\n",
      "        0, 1, 4, 2], device='cuda:0')\n",
      "From model_02 Accuracy: 64.00% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict(test_dataloader, model_02, 2, test_batch_size)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca49a4e-40bf-4f81-9120-b8efe26b0cce",
   "metadata": {},
   "source": [
    "# 4. 세 번째 모델을 추가 하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37600571-5fa4-41d5-a3e2-d3aa9fbbcd05",
   "metadata": {},
   "source": [
    "## 4.1. 세번째 모델 생성 및 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ff89315-b49a-43dc-87dd-0613fe8e8caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_03 = NeuralNetwork().to(device)\n",
    "print(model_03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5bd8dd43-435a-4954-9da2-0793515a0c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.305949  [    0/60000]\n",
      "loss: 2.298587  [ 6400/60000]\n",
      "loss: 2.277089  [12800/60000]\n",
      "loss: 2.269028  [19200/60000]\n",
      "loss: 2.261537  [25600/60000]\n",
      "loss: 2.230896  [32000/60000]\n",
      "loss: 2.242368  [38400/60000]\n",
      "loss: 2.206961  [44800/60000]\n",
      "loss: 2.200840  [51200/60000]\n",
      "loss: 2.171412  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 42.0%, Avg loss: 2.165270 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "loss_fn , optimizer = create_loss_optimizer(model_03)\n",
    "\n",
    "epochs = 1\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    model_03 = train(train_dataloader, model_03, loss_fn, optimizer)\n",
    "    test(test_dataloader, model_03, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1069d940-a446-4fe5-abb3-61f399e216ee",
   "metadata": {},
   "source": [
    "## 4.2. 기존의 CombinedModel 에 세번째 모델 추가 하기\n",
    "- 모델 네트워크가 아래와 같이 구성 됨\n",
    "    - x = Flatten(x) (x 는 입력)\n",
    "    - x_base_model = CombinedNeuralNetwork(x)\n",
    "        - model_01\n",
    "        - model_02\n",
    "    - x_add_model = NeuralNetwork(x)\n",
    "        - model_03\n",
    "    - return x_base_model, x_add_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ddfbb93c-c244-4c05-be11-f1294a953343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CombinedNeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (base_model): CombinedNeuralNetwork(\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "    (base_model): NeuralNetwork(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (linear_relu_stack): Sequential(\n",
      "        (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (3): ReLU()\n",
      "        (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (add_model): NeuralNetwork(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (linear_relu_stack): Sequential(\n",
      "        (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (3): ReLU()\n",
      "        (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (add_model): NeuralNetwork(\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "    (linear_relu_stack): Sequential(\n",
      "      (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "CombinedModel_3 = CombinedNeuralNetwork(CombinedModel, model_03).to(device)\n",
    "print(CombinedModel_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb37b0b-7943-44c3-b39f-5b5336bb5d91",
   "metadata": {},
   "source": [
    "## 4.3. 통합된 모델 (세 개의 모델들) 의 추론 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dcc0d365-6ecb-49ab-8beb-f9731c72dd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_c2(dataloader, model, test_batch_size):\n",
    "    def depth(l):\n",
    "        if isinstance(l, list):\n",
    "            return 1 + max(depth(item) for item in l)\n",
    "        elif isinstance(l, tuple):\n",
    "            return 1 + max(depth(item) for item in l)\n",
    "\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def unflatten_tuple(t, depth):\n",
    "        e_list = []\n",
    "        while True:\n",
    "            if depth ==0:\n",
    "                e_list.append(x)\n",
    "                break\n",
    "            x, y = t\n",
    "            e_list.append(y)\n",
    "\n",
    "            t = x\n",
    "            #print(\"x: \", x)\n",
    "\n",
    "            depth -= 1\n",
    "\n",
    "        e_list.reverse()\n",
    "\n",
    "        return e_list\n",
    "    \n",
    "    \n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            print(\"X : \", X.shape)\n",
    "            probs = model(X)\n",
    "            \n",
    "            print(\"Combined Model - probs shape: \", np.array(probs).shape)\n",
    "            #print(\"probs \\n\", probs)\n",
    "            \n",
    "            ground_truth = y\n",
    "            print(\"Ground_Truth: \\n\", ground_truth, \"\\n\")\n",
    "            \n",
    "            depth = depth(probs)    \n",
    "            probs_list = unflatten_tuple(probs, depth)            \n",
    "            #print(\"probs_list: \\n\", probs_list)\n",
    "            \n",
    "            for i, pred in enumerate(probs_list):\n",
    "                print(f\"From model_0{i+1} - Predicted Label:\")                \n",
    "                print(pred.argmax(1))\n",
    "                correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "                correct /= test_batch_size\n",
    "\n",
    "                print(f\"From model_0{i+1} Accuracy: {(100*correct):>0.2f}% \\n\")\n",
    "                \n",
    "                correct= 0\n",
    "                \n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee26a090-c0a2-48e9-a26d-0802ecb00ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X :  torch.Size([100, 1, 28, 28])\n",
      "Combined Model - probs shape:  (2,)\n",
      "Ground_Truth: \n",
      " tensor([9, 2, 1, 1, 6, 1, 4, 6, 5, 7, 4, 5, 7, 3, 4, 1, 2, 4, 8, 0, 2, 5, 7, 9,\n",
      "        1, 4, 6, 0, 9, 3, 8, 8, 3, 3, 8, 0, 7, 5, 7, 9, 6, 1, 3, 7, 6, 7, 2, 1,\n",
      "        2, 2, 4, 4, 5, 8, 2, 2, 8, 4, 8, 0, 7, 7, 8, 5, 1, 1, 2, 3, 9, 8, 7, 0,\n",
      "        2, 6, 2, 3, 1, 2, 8, 4, 1, 8, 5, 9, 5, 0, 3, 2, 0, 6, 5, 3, 6, 7, 1, 8,\n",
      "        0, 1, 4, 2], device='cuda:0') \n",
      "\n",
      "From model_01 - Predicted Label:\n",
      "tensor([9, 4, 1, 1, 4, 4, 4, 4, 8, 7, 4, 9, 9, 3, 4, 1, 4, 4, 8, 0, 4, 9, 9, 9,\n",
      "        1, 4, 4, 0, 9, 4, 8, 4, 1, 4, 4, 4, 8, 8, 8, 9, 0, 1, 4, 9, 4, 9, 4, 1,\n",
      "        4, 4, 4, 4, 8, 4, 4, 4, 8, 4, 8, 0, 8, 9, 9, 9, 1, 1, 4, 0, 9, 8, 9, 4,\n",
      "        4, 4, 4, 4, 1, 4, 9, 4, 1, 8, 9, 9, 9, 0, 4, 4, 0, 4, 9, 4, 4, 9, 1, 9,\n",
      "        4, 1, 4, 4], device='cuda:0')\n",
      "From model_01 Accuracy: 41.00% \n",
      "\n",
      "From model_02 - Predicted Label:\n",
      "tensor([9, 2, 1, 1, 2, 1, 4, 4, 7, 7, 4, 9, 7, 3, 4, 1, 2, 2, 8, 0, 2, 7, 7, 9,\n",
      "        1, 4, 4, 3, 9, 0, 8, 0, 3, 0, 8, 0, 7, 7, 7, 9, 0, 1, 0, 9, 4, 9, 2, 1,\n",
      "        4, 4, 2, 2, 7, 2, 4, 2, 8, 4, 8, 0, 7, 7, 8, 7, 1, 1, 3, 1, 9, 8, 7, 0,\n",
      "        2, 0, 4, 1, 1, 2, 8, 4, 1, 8, 9, 9, 7, 0, 3, 4, 0, 2, 7, 3, 4, 7, 1, 8,\n",
      "        0, 1, 4, 2], device='cuda:0')\n",
      "From model_02 Accuracy: 64.00% \n",
      "\n",
      "From model_03 - Predicted Label:\n",
      "tensor([9, 2, 1, 1, 2, 4, 4, 4, 8, 8, 4, 9, 8, 3, 4, 1, 4, 4, 8, 0, 4, 8, 9, 9,\n",
      "        1, 4, 4, 4, 9, 4, 8, 4, 3, 4, 8, 4, 8, 4, 9, 9, 4, 1, 4, 9, 4, 9, 2, 1,\n",
      "        4, 4, 4, 4, 4, 2, 4, 4, 8, 4, 8, 4, 9, 9, 8, 8, 1, 1, 4, 4, 9, 8, 9, 4,\n",
      "        4, 4, 4, 4, 1, 2, 8, 2, 4, 8, 9, 9, 4, 4, 3, 4, 0, 4, 9, 4, 4, 9, 1, 8,\n",
      "        4, 1, 2, 2], device='cuda:0')\n",
      "From model_03 Accuracy: 44.00% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_c2(test_dataloader, CombinedModel_3, test_batch_size)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c692b46-e9dc-4526-b3bb-f1faf180fec1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 커널 리스타팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d887405-0897-4acc-9ba7-5cb358932f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "\n",
    "IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d429a653-fa0b-4a25-bb7e-366656f8a37a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
