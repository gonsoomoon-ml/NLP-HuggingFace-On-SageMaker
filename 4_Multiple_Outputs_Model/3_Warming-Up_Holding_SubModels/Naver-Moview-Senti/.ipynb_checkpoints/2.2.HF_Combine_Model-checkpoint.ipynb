{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8e350e8-d8fc-4a24-96b1-5fdcd52d9033",
   "metadata": {
    "tags": []
   },
   "source": [
    "# NSMC 데이터 - PLM + 그룹 Custom Classifiers 만들기\n",
    "\n",
    "이 노트북은 크게 2개의 모델을 생성하여 파이프라인으로 연결를 결과로 만듧니다.\n",
    "- 첫 번재 모델\n",
    "    - Electra Pretrained Model (PLM)\n",
    "- 두 번째 모델\n",
    "    - 4 개의 Classifiers 로 구성된 모델 \n",
    "        - Classifiers_01, Classifiers02, Classifiers_03, Classifiers_04\n",
    "- 추론\n",
    "    - PLM --> Classifiers 로 이루어 지며, 최종 4개의 Classifier 의 모델 결과가 제공 됨.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 참조: \n",
    "- 딥러닝으로 리뷰에서 제품 속성 정보 추출하기\n",
    "    * http://blog.hwahae.co.kr/all/tech/tech-tech/5967/\n",
    "- A Visual Guide to Using BERT for the First Time\n",
    "    - http://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/\n",
    "- PyTorch 101, Part 3: Going Deep with PyTorch\n",
    "    - https://blog.paperspace.com/pytorch-101-advanced/\n",
    "- Pytorch freeze part of the layers\n",
    "    - https://jimmy-shen.medium.com/pytorch-freeze-part-of-the-layers-4554105e03a6\n",
    "- BERT Fine-Tuning Tutorial with PyTorch\n",
    "    - https://mccormickml.com/2019/07/22/BERT-fine-tuning/\n",
    "- How many layers of my BERT model should I freeze?\n",
    "    - https://raphaelb.org/posts/freezing-bert/\n",
    "- Add dense layer on top of Huggingface BERT model\n",
    "    - https://pyquestions.com/add-dense-layer-on-top-of-huggingface-bert-model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2875c6b1-8e6f-40be-945c-e97fd0ae98e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 0. 환경 셋업"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fceb19a1-53c3-4ffb-a614-91c94bc8266e",
   "metadata": {},
   "source": [
    "## 0.1. 변수 로딩 및 라이브러리 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db7ea0dc-301f-4431-be2e-9db8e06175b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r local_train_output_path\n",
    "%store -r local_test_output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "644e2357-c62a-4d5c-9447-1d229c1e48fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# src 폴더 경로 설정\n",
    "import sys\n",
    "sys.path.append('./src')\n",
    "import config\n",
    "from  data_util import read_nsmc_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51d2307c-2193-4b32-b017-b4f2b3b3a313",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "# logger.setLevel(logging.WARNING)\n",
    "logger.addHandler(logging.StreamHandler(sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a540b2e-302b-4587-b4d1-e60e3c16f387",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "from datasets import load_dataset,Dataset,DatasetDict\n",
    "from transformers import DataCollatorWithPadding,AutoModelForSequenceClassification, Trainer, TrainingArguments,AutoTokenizer,AutoModel,AutoConfig\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989c9258-6266-4339-8594-7835868bb42d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 0.2. Pre-trained model_id, tokenizer_id 지정\n",
    "- [KoElectra Git](https://github.com/monologg/KoELECTRA)\n",
    "- KoElectra Model\n",
    "    - Small:\n",
    "        - \"monologg/koelectra-small-v3-discriminator\n",
    "    - Base: \n",
    "        - monologg/koelectra-base-v3-discriminator\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6a1032b-1df2-4df7-b2e3-be6692c6b672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import load_dataset\n",
    "from transformers import (\n",
    "    ElectraModel, \n",
    "    ElectraTokenizer, \n",
    ")\n",
    "\n",
    "tokenizer_id = 'monologg/koelectra-small-v3-discriminator'\n",
    "model_id = \"monologg/koelectra-small-v3-discriminator\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce1acee-f913-44c2-9530-13d34ec2518a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. 데이터 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f8f5e7-c499-4fac-8fe1-108db63af538",
   "metadata": {},
   "source": [
    "## 1.1 데이터 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d55d3b9b-e6a4-46d5-8ebd-9c83f0586c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, train_labels = read_nsmc_split(local_train_output_path)\n",
    "test_texts, test_labels = read_nsmc_split(local_test_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f15afaf3-1e98-4def-bf87-db72ff3cd59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len: 149552 \n",
      "Sample: ['흠   포스터보고 초딩영화줄    오버연기조차 가볍지 않구나', '너무재밓었다그래서보는것을추천한다', '교도소 이야기구먼   솔직히 재미는 없다  평점 조정', '사이몬페그의 익살스런 연기가 돋보였던 영화 스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다', '막 걸음마 뗀 세부터 초등학교 학년생인 살용영화 ㅋㅋㅋ   별반개도 아까움']\n",
      "len: 149552 \n",
      "Sample: [1, 0, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"len: {len(train_texts)} \\nSample: {train_texts[0:5]}\")\n",
    "logger.info(f\"len: {len(train_labels)} \\nSample: {train_labels[0:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d972b56-d794-4895-9d20-fbfe299a4be4",
   "metadata": {},
   "source": [
    "## 1.2. 훈련 데이타를 분리하여 검증 데이터 세트 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "246bc915-9e1b-4083-b1e6-919cdbd7376f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd21a9d-977e-4b7d-a8d4-d708e50be0fc",
   "metadata": {},
   "source": [
    "# 1.3. Electra Model 입력 인코딩 변환 및 torch custome Dataset 생성 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f61a15-bc0e-45a8-8faa-8a206ccd8c44",
   "metadata": {},
   "source": [
    "### 1.3.1. 토큰나이저 로딩 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62f06c57-371d-4e74-be1f-f43c6e496371",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = ElectraTokenizer.from_pretrained(tokenizer_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7f45c7-e61c-44f7-bc1e-6571fa41a1fb",
   "metadata": {},
   "source": [
    "### 1.3.2. Electra Model 입력 인코딩 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60d42fad-a6c4-47cf-a61a-fff7aed5844c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42.5 s, sys: 272 ms, total: 42.8 s\n",
      "Wall time: 42.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "tokenizer = ElectraTokenizer.from_pretrained(tokenizer_id)\n",
    "\n",
    "train_encodings = tokenizer(train_texts, return_token_type_ids = False, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_texts, return_token_type_ids = False, truncation=True, padding=True)\n",
    "test_encodings = tokenizer(test_texts, return_token_type_ids = False, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90b62ee-fca6-4547-9cc3-b9ba85a786d9",
   "metadata": {},
   "source": [
    "### 1.3.3. torch custome dataset 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "490410c4-d4cc-4aa5-8944-f85a92f0211d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_util import NSMCDataset\n",
    "\n",
    "train_dataset = NSMCDataset(train_encodings, train_labels)\n",
    "val_dataset = NSMCDataset(val_encodings, val_labels)\n",
    "test_dataset = NSMCDataset(test_encodings, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17ba1348-9791-45ee-916b-92fe4e11000c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_dataset) : 119641\n",
      "len(val_dataset) : 29911\n",
      "len(test_dataset) : 49832\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"len(train_dataset) : {len(train_dataset)}\")\n",
    "logger.info(f\"len(val_dataset) : {len(val_dataset)}\")\n",
    "logger.info(f\"len(test_dataset) : {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ddf4a5-7656-43f7-a68c-3226983f4b61",
   "metadata": {},
   "source": [
    "### 1.3.4. 데이터 로더 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "249311f4-aa81-4d68-9bf4-4abaa03418de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size with frac: 0.01 ==> 1196\n",
      "dataset size with frac: 1 ==> 119641\n",
      "dataset size with frac: 0.001 ==> 29\n",
      "dataset size with frac: 1 ==> 29911\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "\n",
    "\n",
    "from train_util import create_random_sampler\n",
    "    \n",
    "subset_train_sampler = create_random_sampler(train_dataset, frac=0.01, is_shuffle=True, logger=logger)\n",
    "train_sampler = create_random_sampler(train_dataset, frac=1, is_shuffle=True, logger=logger)\n",
    "\n",
    "subset_eval_sampler = create_random_sampler(val_dataset, frac=0.001, is_shuffle=False, logger=logger)\n",
    "# eval_sampler = create_random_sampler(val_dataset, frac=1, is_shuffle=False, logger=logger)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ba138bd-04b5-4427-b3df-ecb73a6a4592",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 16\n",
    "eval_batch_size = 32\n",
    "test_batch_size = 32\n",
    "\n",
    "\n",
    "train_sample_loader = DataLoader(dataset=train_dataset, \n",
    "                          shuffle=False, \n",
    "                          batch_size=train_batch_size, \n",
    "                          sampler=subset_train_sampler)    \n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_dataset, \n",
    "                          shuffle=False, \n",
    "                          batch_size=train_batch_size, \n",
    "                          sampler=train_sampler)    \n",
    "\n",
    "eval_sample_loader = DataLoader(dataset=val_dataset, \n",
    "                          shuffle=False, \n",
    "                          batch_size=eval_batch_size, \n",
    "                          sampler=subset_eval_sampler)    \n",
    "\n",
    "eval_dataloader = DataLoader(dataset=val_dataset, \n",
    "                          shuffle=False, \n",
    "                          batch_size=eval_batch_size)    \n",
    "\n",
    "\n",
    "test_dataloader = DataLoader(dataset=test_dataset, \n",
    "                          shuffle=False, \n",
    "                          batch_size=test_batch_size\n",
    "                            )    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165ea065-8111-4fdb-a03d-2e982e2ddebe",
   "metadata": {},
   "source": [
    "# 2.모델 정의 및 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea28a4c-bb65-4fe1-a85a-01e6396191fd",
   "metadata": {},
   "source": [
    "## 2.1. Pre-Trained Model 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1202dfa8-5989-4f09-8b0b-871c51185e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at monologg/koelectra-small-v3-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "plm = AutoModel.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f588900d-7b83-4fb4-b564-8e4128d3781b",
   "metadata": {},
   "source": [
    "## 2.2. Electra Model 아키텍쳐 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c870af1-4eef-40b0-acdc-e853eebf4eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_module(model):\n",
    "    for name, child in model.named_children():\n",
    "        print(\"name :\", name)\n",
    "        #print(\"child: \\n\", child)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21fe8f79-2277-4ab9-8603-ec6639d49225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name : embeddings\n",
      "name : embeddings_project\n",
      "name : encoder\n"
     ]
    }
   ],
   "source": [
    "show_module(plm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e155afb-f150-4b91-8278-32c34651eef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(plm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec64eadd-2545-40c4-a276-5d4bbaccde0d",
   "metadata": {},
   "source": [
    "## 2.3. Custom Classifier 추가 하여 Custom Model 생성 하기\n",
    "- PLM + Classifier 로 구성됨.\n",
    "- PLM 레이어는 훈련을 안하기 위해 파라이터 Freezing 을 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3dd03189-b6f2-42d7-981e-d42b77ed47b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomBERTModel(nn.Module):\n",
    "    '''\n",
    "    plm 파라미터는 freezing 하여 훈련을 하지 않음.\n",
    "    '''\n",
    "    def __init__(self,model ,num_labels): \n",
    "        super(CustomBERTModel,self).__init__() \n",
    "        self.num_labels = num_labels \n",
    "\n",
    "        self.plm = model\n",
    "        # self.dropout = nn.Dropout(0.1) \n",
    "        # self.classifier = nn.Linear(768,num_labels) # load and initialize weights\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.1),            \n",
    "            nn.Linear(256,128),        \n",
    "            nn.Dropout(0.1),                        \n",
    "            nn.Linear(128,num_labels) \n",
    "        )\n",
    "                \n",
    "        self.freeze_plm()        \n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None,labels=None):\n",
    "        #Extract outputs from the body\n",
    "        outputs = self.plm(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        #print(\"outputs shape: \", outputs[0].shape)\n",
    "        \n",
    "        #sequence_output = self.dropout(outputs[0]) # outputs[0]=last hidden state\n",
    "        # print(\"sequence_output shape: \", sequence_output.shape)\n",
    "        \n",
    "        cls_vector = outputs[0][:,0,:].view(-1,256) # outputs[0] 은 last_hidden_state, outputs[1] 은 pooled_output_state\n",
    "        # print(\"cls_vector shape: \", cls_vector.shape)        \n",
    "        \n",
    "        logits = self.classifier(cls_vector) \n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "\n",
    "        return TokenClassifierOutput(loss=loss, logits=logits, hidden_states=cls_vector ,attentions=outputs.attentions)\n",
    "\n",
    "    def freeze_plm(self):\n",
    "        \"\"\"\n",
    "        Freezes the parameters of BERT so when BertWithCustomNNClassifier is trained\n",
    "        only the wieghts of the custom classifier are modified.\n",
    "        \"\"\"\n",
    "        for param in self.plm.parameters():\n",
    "            param.requires_grad=False\n",
    "        #     print(param.requires_grad)\n",
    "        \n",
    "    \n",
    "    def unfreeze_plm(self):\n",
    "        \"\"\"\n",
    "        Unfreezes the parameters of BERT so when BertWithCustomNNClassifier is trained\n",
    "        both the wieghts of the custom classifier and of the underlying BERT are modified.\n",
    "        \"\"\"\n",
    "        for param in self.plm.parameters():\n",
    "            param.requires_grad=True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "05928664-cf83-42c1-aee9-27dd047b82b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "custom_model=CustomBERTModel(model = plm ,num_labels=2).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8ed72f-60bb-4507-b1f6-a6e714d7fd2c",
   "metadata": {},
   "source": [
    "최상위 모듈(레이어)  확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f330da11-8745-488a-a234-198abae665af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name : plm\n",
      "name : classifier\n"
     ]
    }
   ],
   "source": [
    "show_module(custom_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9f90c0-5207-43ba-8ed3-888411678d8a",
   "metadata": {},
   "source": [
    "파라미터 Freezing 여부 확인. plm == freezing , classifier == trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e235cdbc-b8a8-409e-9bd2-64271f15b8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier.1.weight\n",
      "classifier.1.bias\n",
      "classifier.3.weight\n",
      "classifier.3.bias\n"
     ]
    }
   ],
   "source": [
    "def show_trainable_layer(model):\n",
    "    # requires_grad == true 만 출력\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad: print(name) \n",
    "\n",
    "show_trainable_layer(custom_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908100ea-bf3b-424f-98cf-43151532c22a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.4. Custome Model 아키텍쳐 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8901768d-e36a-4bd4-bcaa-2dc7c9755577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(custom_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947cf866-7801-42ca-96b7-dd3db93c34ed",
   "metadata": {},
   "source": [
    "# 3. 훈련 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e53f52d-057f-4791-8305-9fc1d47d389d",
   "metadata": {},
   "source": [
    "## 3.1. 모델 평가 지표 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a7c553d0-627c-4454-9311-dc31cea1ba70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "# metric = load_metric(\"f1\")\n",
    "metric = load_metric(\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf03f4f-3a9d-4c6e-b674-6153bbeb9272",
   "metadata": {},
   "source": [
    "## 3.2. 옵티마이저, 스케줄러, 훈련 루프 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "99abb865-3cbb-4de8-a415-e5771b4cc1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW,get_scheduler\n",
    "\n",
    "def create_optimizer_scheduler(num_epochs, model, train_dataloader):\n",
    "    # plm freezing optimizer\n",
    "    optimizer = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=5e-5)\n",
    "    # optimizer withoud frezzing\n",
    "    # optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "    \n",
    "    def get_lr_scheduler(num_epochs, train_dataloader, optimizer):\n",
    "        num_training_steps = num_epochs * len(train_dataloader)\n",
    "        lr_scheduler = get_scheduler(\n",
    "            \"linear\",\n",
    "            optimizer=optimizer,\n",
    "            num_warmup_steps=0,\n",
    "            num_training_steps=num_training_steps,\n",
    "        )\n",
    "\n",
    "        print(num_training_steps)\n",
    "\n",
    "        return lr_scheduler, num_training_steps\n",
    "    \n",
    "    lr_scheduler, num_training_steps = get_lr_scheduler(num_epochs, train_dataloader, optimizer)\n",
    "    \n",
    "    return optimizer, lr_scheduler, num_training_steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "967963b0-ab70-4ab9-856d-7eb11bc0f2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(num_epochs, model, train_dataloader, progress_bar_train, \\\n",
    "               eval_dataloader, progress_bar_eval, metric, optimizer, lr_scheduler):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for batch in train_dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            progress_bar_train.update(1)\n",
    "                \n",
    "        # 모델 평가\n",
    "        model.eval()\n",
    "        for batch in eval_dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            with torch.no_grad():\n",
    "                outputs = custom_model(**batch)\n",
    "\n",
    "            logits = outputs.logits\n",
    "            predictions = torch.argmax(logits, dim=-1)\n",
    "            metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "            progress_bar_eval.update(1)\n",
    "            \n",
    "\n",
    "        print(metric.compute())\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4182abae-475d-4786-8023-d65f27c94f11",
   "metadata": {},
   "source": [
    "# 3.3. 훈련 루프 실행 및 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8679a041-6d01-42ad-a800-36f90ff3defc",
   "metadata": {},
   "source": [
    "훈련 루프에 입력이 될 Batch 확인 함. 'eval_dataloader' 를 'train_dataloader' 로 바꾸어서 보시면 됩니다.\n",
    "레코드가 많이 출력이 되어서 eval_dataloader 로 확인 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9ecf33b9-2878-4df2-b9ed-96b882a12354",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for batch in eval_dataloader:\n",
    "#     batch = {k: v.to(device) for k, v in batch.items()}\n",
    "#     print(batch)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2a7f935f-337c-4d48-b26c-3f29c465f8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59171179f0e142f196e0b63627c49a4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7478 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac52335432c84fc9972d882766a20d23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/935 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.6572164086790813}\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "num_epochs = 1\n",
    "optimizer, lr_scheduler, num_training_steps = create_optimizer_scheduler(num_epochs, custom_model, train_dataloader)\n",
    "\n",
    "progress_bar_train = tqdm(range(num_training_steps))\n",
    "progress_bar_eval = tqdm(range(num_epochs * len(eval_dataloader)))\n",
    "\n",
    "custom_model_01 = train_loop(num_epochs, custom_model, train_dataloader, progress_bar_train, \\\n",
    "               eval_dataloader, progress_bar_eval, metric, optimizer, lr_scheduler)      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410ec30a-60f1-47db-8dd7-36ff39557e01",
   "metadata": {},
   "source": [
    "# 5. 테스트 데이터 로 모델 평가 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "462f65e8-aef2-4867-83b4-4a2d3a95ca2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.6574891635896613}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def evaL_model(model, test_dataloader, metric):\n",
    "    model.eval()\n",
    "\n",
    "\n",
    "    for i, batch in enumerate(test_dataloader):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "\n",
    "        logits = outputs.logits\n",
    "        # print(\"outputs: \\n\", outputs)\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        # print(\"batch: \\n\", batch)\n",
    "        # print(\"hidden_states: \", outputs.hidden_states.shape)\n",
    "        # print(\"Ground Truth: \\n\", batch[\"labels\"])        \n",
    "        # print(\"predictions: \\n\", predictions)\n",
    "        metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "        \n",
    "\n",
    "    print(metric.compute())\n",
    "    \n",
    "evaL_model(custom_model_01, test_dataloader, metric)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf66b786-7686-49a3-9190-f0b45ef8faec",
   "metadata": {},
   "source": [
    "# 6. 모델 분리 후 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "586d1c24-8064-4c17-ba85-27ea003445c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name : plm\n",
      "name : classifier\n"
     ]
    }
   ],
   "source": [
    "show_module(custom_model_01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702b8c94-ed34-402c-b3c2-0874d4e025cc",
   "metadata": {},
   "source": [
    "## 6.1. 추론 PLM Model 생성 \n",
    "- custom_model (PLM + Classifier) 에서 PLM 만을 분리 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f7fe3ec7-0b71-4a3f-bc78-4fe14eebddd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLM: \n",
      "name : plm\n"
     ]
    }
   ],
   "source": [
    "class PLModel(nn.Module):\n",
    "    def __init__(self, base_model, num_labels): \n",
    "        super(PLModel,self).__init__() \n",
    "\n",
    "        self.plm = base_model.plm\n",
    "        \n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None,labels=None):\n",
    "        #Extract outputs from the body\n",
    "\n",
    "        #Add custom layers\n",
    "        outputs = self.plm(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        \n",
    "        cls_vector = outputs[0][:,0,:].view(-1,256)\n",
    "        # print(\"cls_vector shape: \", cls_vector.shape)                \n",
    "\n",
    "        return cls_vector\n",
    "\n",
    "PL_Model=PLModel(base_model = custom_model_01 ,num_labels=2).to(device)\n",
    "print(\"PLM: \")\n",
    "show_module(PL_Model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddec29e5-3c6f-4bf8-81db-91df3da33d3f",
   "metadata": {},
   "source": [
    "## 6.2. 추천 이진 분류기 모델 \n",
    "- custom_model (PLM + Classifier) 에서 Classifier 만을 분리 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7ad572b9-0943-4a82-80a9-f1326f4a9064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classifier: \n",
      "\n",
      "name : classifier\n"
     ]
    }
   ],
   "source": [
    "class ClassifierModel(nn.Module):\n",
    "    def __init__(self, base_model, num_labels): \n",
    "        super(ClassifierModel,self).__init__() \n",
    "\n",
    "        self.num_labels = num_labels \n",
    "        #self.dropout = nn.Dropout(0.1)     \n",
    "        self.classifier = base_model.classifier    \n",
    "        \n",
    "\n",
    "    def forward(self, cls_vector=None, labels=None):\n",
    "\n",
    "        #Add custom layers\n",
    "        #cls_vector = self.dropout(cls_vector) #outputs[0]=last hidden state\n",
    "        logits = self.classifier(cls_vector)\n",
    "        \n",
    "        # logits = self.classifier(sequence_output[:,0,:].view(-1,768)) # calculate losses\n",
    "\n",
    "\n",
    "        return logits\n",
    "\n",
    "\n",
    "classifier_01 = ClassifierModel(base_model = custom_model_01 ,num_labels=2).to(device)\n",
    "print(\"\\nClassifier: \\n\")\n",
    "show_module(classifier_01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde78ad2-405e-4eea-86cc-469b634df10f",
   "metadata": {},
   "source": [
    "## 6.3. PLM 모델 추론\n",
    "- BERT Encoding 을 입력하여 PLM 모델을 통해서 (Batch_Size, 25, 768) 벡터를 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7b755eb7-ca9b-417f-9494-404fa3b42ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size:  1558\n",
      "one batch shape:  torch.Size([32, 256])\n"
     ]
    }
   ],
   "source": [
    "def inference_plm(model, sample_dataloader):\n",
    "    model.eval()\n",
    "\n",
    "    output_list = []\n",
    "    for i, batch in enumerate(sample_dataloader):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "            output_list.append(outputs)\n",
    "        \n",
    "        # if i == 10:\n",
    "        #     break\n",
    "            \n",
    "    return output_list\n",
    "\n",
    "    \n",
    "plm_vector = inference_plm(PL_Model, test_dataloader)\n",
    "print(\"batch size: \" , len(plm_vector))\n",
    "print(\"one batch shape: \" , plm_vector[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa797a7-e722-460c-93ac-d79759acd59a",
   "metadata": {},
   "source": [
    "## 6.4. 이진 분류기 추론\n",
    "PLM 모델을 통해서 (Batch_Size, 25, 768) 벡터를 입력으로 하여 Classifier 로 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "79e27208-7c48-4d8f-8a9b-51af99c66e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "25308e41-7a7d-4f27-a1f5-a2ff7696f8cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.6574891635896613}\n"
     ]
    }
   ],
   "source": [
    "def inference_classifier(model, plm_vector, test_loader):\n",
    "    model.eval()\n",
    "\n",
    "    output_list = []\n",
    "    for i , (batch, reference) in enumerate(zip(plm_vector, test_loader)):\n",
    "        # batch = batch[0].to(device)\n",
    "\n",
    "        #print(\"batch shape: \", batch.shape)\n",
    "        # batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(batch)\n",
    "            # print(\"outputs: \", outputs)\n",
    "            predictions = torch.argmax(outputs, dim=-1)\n",
    "            # print(\"batch: \\n\", batch)      \n",
    "            # print(\"Ground Truth : \\n\", reference['labels'])            \n",
    "            # print(\"Predictions: \", predictions)\n",
    "            metric.add_batch(predictions=predictions, references=reference[\"labels\"])\n",
    "            \n",
    "            output_list.append(outputs)\n",
    "\n",
    "        \n",
    "    print(metric.compute())        \n",
    "                \n",
    "    return output_list\n",
    "\n",
    "output_list = inference_classifier(classifier_01, plm_vector, test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccb0800-a043-4d22-8ec0-cbf119ee521d",
   "metadata": {},
   "source": [
    "# 7. 두번째 모델 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af95376b-661d-4cb2-b0f8-d61a87413601",
   "metadata": {},
   "source": [
    "## 7.1. plm plus custom classifier 로 두번째 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "566359cb-a046-4153-950a-4c5285455474",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model =CustomBERTModel(model = plm ,num_labels=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f148b7d3-64c3-4cd9-aee3-64cdb0427df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier.1.weight\n",
      "classifier.1.bias\n",
      "classifier.3.weight\n",
      "classifier.3.bias\n"
     ]
    }
   ],
   "source": [
    "show_trainable_layer(custom_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a78c85-e29c-43cf-98b1-43ee780c184a",
   "metadata": {},
   "source": [
    "## 7.2. 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b0db76d1-350f-42d9-b865-4daf1196069c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 2\n",
    "\n",
    "optimizer, lr_scheduler, num_training_steps = create_optimizer_scheduler(num_epochs, custom_model, train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dc659cd2-f326-4728-8838-abce355fecf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e117727238604843a185759540e1f38b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14956 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "742bc4c75f8246a69058b1559fb46485",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1870 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.663501721774598}\n",
      "{'accuracy': 0.6717261208251145}\n"
     ]
    }
   ],
   "source": [
    "progress_bar_train = tqdm(range(num_training_steps))\n",
    "progress_bar_eval = tqdm(range(num_epochs * len(eval_dataloader)))\n",
    "\n",
    "custom_model_02 = train_loop(num_epochs, custom_model, train_dataloader, progress_bar_train, \\\n",
    "               eval_dataloader, progress_bar_eval, metric, optimizer, lr_scheduler)      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ed69c6-75db-48d2-85d5-f5b6c7b727f6",
   "metadata": {},
   "source": [
    "## 7.3. 테스트 데이터로 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3ec150c8-e166-4a94-a7d3-7d7631d02409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.6708139348209986}\n"
     ]
    }
   ],
   "source": [
    "evaL_model(custom_model_02, test_dataloader, metric)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b28f7e-32c7-4b64-9c75-2685970935f9",
   "metadata": {},
   "source": [
    "## 7.4. 두번째 모델에서 Classifier 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d867f2b0-b1a1-494b-a679-25d723c7fa08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name : classifier\n"
     ]
    }
   ],
   "source": [
    "classifier_02 = ClassifierModel(base_model = custom_model_02 ,num_labels=2).to(device)\n",
    "show_module(classifier_02)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15fecef-675b-4155-8126-3f846005a800",
   "metadata": {},
   "source": [
    "## 7.6. 이진 분류기로 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7803161e-ccd6-43ee-b42f-0a2fc58eb843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.6708139348209986}\n"
     ]
    }
   ],
   "source": [
    "output_list = inference_classifier(classifier_02, plm_vector, test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0df1776-c080-46c7-8e1b-6fe2a14828ab",
   "metadata": {},
   "source": [
    "# 8. 첫번째, 두번째의 모델을 한개의 모델로 통합\n",
    "- Classifier_01 , Classifier_02 를 한개의 모델 안으로 포함 시킴 (Combine_Classifier_02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7a3803b1-9bca-4277-aa58-ad224ca0e7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name : base_classifier\n",
      "name : add_classifier\n"
     ]
    }
   ],
   "source": [
    "class CombineClassifier(nn.Module):\n",
    "    def __init__(self, base_classifier, add_classifier): \n",
    "        super(CombineClassifier,self).__init__() \n",
    "\n",
    "        # self.dropout = nn.Dropout(0.1)     \n",
    "        \n",
    "        self.base_classifier = base_classifier\n",
    "        self.add_classifier = add_classifier\n",
    "\n",
    "    def forward(self, cls_vector=None, labels=None):\n",
    "\n",
    "        #Add custom layers\n",
    "        #print(\"cls_vector shape: \", cls_vector.shape)\n",
    "        x = cls_vector\n",
    "        base_logits = self.base_classifier(x) \n",
    "        add_logits = self.add_classifier(x)\n",
    "\n",
    "\n",
    "        return base_logits, add_logits\n",
    "\n",
    "\n",
    "Combine_Classifier_02 = CombineClassifier(base_classifier = classifier_01 ,add_classifier = classifier_02).to(device)\n",
    "show_module(Combine_Classifier_02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0e68f816-2f62-416d-ba45-5dcfec5a5cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CombineClassifier(\n",
      "  (base_classifier): ClassifierModel(\n",
      "    (classifier): Sequential(\n",
      "      (0): Dropout(p=0.1, inplace=False)\n",
      "      (1): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (2): Dropout(p=0.1, inplace=False)\n",
      "      (3): Linear(in_features=128, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (add_classifier): ClassifierModel(\n",
      "    (classifier): Sequential(\n",
      "      (0): Dropout(p=0.1, inplace=False)\n",
      "      (1): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (2): Dropout(p=0.1, inplace=False)\n",
      "      (3): Linear(in_features=128, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(Combine_Classifier_02)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c207a221-3caf-49ab-9e8e-7a20e06696b6",
   "metadata": {},
   "source": [
    "복수개의 Classifier 가 있는 Combine_Classifier 모델의 추론을 및 평가를 하는 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1e99ead7-e0d0-4846-be7d-17001d002631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_classifier2(model, plm_vector, test_dataloader, test_batch_size, verbose=False):\n",
    "    def get_depth(l):\n",
    "        if isinstance(l, list):\n",
    "            return 1 + max(get_depth(item) for item in l)\n",
    "        elif isinstance(l, tuple):\n",
    "            return 1 + max(get_depth(item) for item in l)\n",
    "\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def unflatten_tuple(t, depth):\n",
    "        e_list = []\n",
    "        while True:\n",
    "            if depth ==0:\n",
    "                e_list.append(x)\n",
    "                break\n",
    "            x, y = t\n",
    "            e_list.append(y)\n",
    "\n",
    "            t = x\n",
    "            #print(\"x: \", x)\n",
    "\n",
    "            depth -= 1\n",
    "\n",
    "        e_list.reverse()\n",
    "\n",
    "        return e_list\n",
    "\n",
    "    def get_num_model():\n",
    "        model.eval()\n",
    "\n",
    "        test_batch_num = len(test_dataloader)\n",
    "        total_correct, correct = 0 , 0\n",
    "\n",
    "        output_list = []\n",
    "        for batch, reference in zip(plm_vector, test_dataloader):\n",
    "            # print(reference['labels'])\n",
    "            batch = batch[0].to(device)\n",
    "            # batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            with torch.no_grad():\n",
    "                probs = model(batch)\n",
    "                # print(\"outputs: \", probs)   \n",
    "                depth = get_depth(probs)    \n",
    "                probs_list = unflatten_tuple(probs, depth)            \n",
    "            break\n",
    "        return len(probs_list), depth\n",
    "    \n",
    "    def eval_model():\n",
    "        #############################\n",
    "        # 정확도 계산 위한 변수 정의\n",
    "        #############################        \n",
    "        test_batch_num = len(test_dataloader) # 총 배치 숫자\n",
    "        num_models , depth = get_num_model() # 총 모델안의 분류기 수\n",
    "        print(\"# of Moddels: \", num_models)\n",
    "        \n",
    "        total_correct = np.zeros((num_models,1)) # 통계를 내기 위해 각 모델마다 할당\n",
    "        \n",
    "        correct = 0 \n",
    "        output_list = []\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        for batch, reference in zip(plm_vector, test_dataloader):\n",
    "            # print(reference['labels'])\n",
    "            # batch = batch[0].to(device)\n",
    "            # batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            with torch.no_grad():\n",
    "                probs = model(batch)\n",
    "                # print(\"outputs: \", probs)   \n",
    "                #depth = get_depth(probs)    \n",
    "                probs_list = unflatten_tuple(probs, depth)            \n",
    "                # print(\"probs_list: \", probs_list)\n",
    "\n",
    "                ground_truth = reference[\"labels\"].to(device)\n",
    "                \n",
    "                if verbose:\n",
    "                    print(\"Ground_Truth: \\n\", ground_truth, \"\\n\")            \n",
    "                # print(\"outputs: \", outputs.shape)   \n",
    "\n",
    "                # 각 모델 마다 correct 수를 구함.\n",
    "                for i, pred in enumerate(probs_list):\n",
    "\n",
    "                    correct += (pred.argmax(1) == ground_truth).type(torch.float).sum().item()\n",
    "                    total_correct[i] +=correct                \n",
    "                    correct /= test_batch_size\n",
    "\n",
    "                    correct = 0\n",
    "\n",
    "                    if verbose:\n",
    "                        print(f\"From model_0{i+1} - Predicted Label:\")                \n",
    "                        print(pred.argmax(1))\n",
    "\n",
    "                        print(f\"From model_0{i+1} Accuracy: {(100*correct):>0.2f}% \\n\")\n",
    "\n",
    "\n",
    "        # 전체 배치에 대한 모델 마다 정확도 구함.\n",
    "        num_total_payload = test_batch_num * test_batch_size                \n",
    "        for i in range(num_models):\n",
    "            total_correct[i] /= num_total_payload    \n",
    "            #print(\" total_correct[i] : \",         total_correct[i])\n",
    "            print(f\"From model_0{i+1} Accuracy: {(100*total_correct[i][0]):>0.2f}% \\n\")    \n",
    "    \n",
    "    \n",
    "    eval_model()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f334bff4-f08a-4e43-ac6a-c89ad7e5c4d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Moddels:  2\n",
      "From model_01 Accuracy: 65.72% \n",
      "\n",
      "From model_02 Accuracy: 67.05% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "output_list = inference_classifier2(Combine_Classifier_02, plm_vector, test_dataloader, test_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6fb79b-8194-453f-ab9b-82d1e3bcbd6d",
   "metadata": {},
   "source": [
    "# 9. 세번째 모델 생성 및 통합 추론"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6570d47c-88a7-42c5-9766-f355ff1c4415",
   "metadata": {},
   "source": [
    "## 9.1. 세번째 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4db214fe-f5a7-4208-ba66-b2eff69f78a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eaaab746ad04b40a10ad314b432c86e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14956 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "064b19b227ba4f54a7631d204a813d52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1870 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval dataset accuracy in training loop\n",
      "{'accuracy': 0.6650061850155461}\n",
      "{'accuracy': 0.6750359399552004}\n",
      "inference accuracy for plm plus classifer\n",
      "{'accuracy': 0.6743257344678119}\n",
      "classifier architecture: \n",
      "name : classifier\n",
      "inference accuracy for classifer\n",
      "{'accuracy': 0.6743257344678119}\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 2\n",
    "# 모델 훈련\n",
    "custom_model =CustomBERTModel(model = plm ,num_labels=2).to(device)\n",
    "optimizer, lr_scheduler, num_training_steps = create_optimizer_scheduler(num_epochs, custom_model, train_dataloader)\n",
    "progress_bar_train = tqdm(range(num_training_steps))\n",
    "progress_bar_eval = tqdm(range(num_epochs * len(eval_dataloader)))\n",
    "\n",
    "\n",
    "def create_bert_model(num_epochs, custom_model):\n",
    "    print(\"eval dataset accuracy in training loop\")\n",
    "    custom_model = train_loop(num_epochs, custom_model, train_dataloader, progress_bar_train, \\\n",
    "                   eval_dataloader, progress_bar_eval, metric, optimizer, lr_scheduler)      \n",
    "\n",
    "    # 모델 평가\n",
    "    print(\"inference accuracy for plm plus classifer\")    \n",
    "    evaL_model(custom_model, test_dataloader, metric)    \n",
    "\n",
    "    # Classifier 추출\n",
    "    classifier = ClassifierModel(base_model = custom_model ,num_labels=2).to(device)\n",
    "\n",
    "    # Classifier 모델 구조 확인\n",
    "    print(\"classifier architecture: \")        \n",
    "    show_module(classifier)\n",
    "\n",
    "    # plm vector 추출\n",
    "    plm_vector = inference_plm(PL_Model, test_dataloader)\n",
    "    # print(\"batch size: \" , len(plm_vector))\n",
    "    # print(\"one batch shape: \" , plm_vector[0][0].shape)\n",
    "\n",
    "    # Classifier 로 추론\n",
    "    print(\"inference accuracy for classifer\")\n",
    "    output_list = inference_classifier(classifier, plm_vector, test_dataloader)\n",
    "    \n",
    "    return classifier\n",
    "\n",
    "    \n",
    "classifier_03 = create_bert_model(num_epochs, custom_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b815551-9774-4f9f-81ab-4822f295fe3b",
   "metadata": {},
   "source": [
    "## 9.2. 세 번째 모델(classifier_03) 을 기존의 모델 (classifier_01, classifier_02) 로 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d4cd6383-61b3-43da-a8f6-4831d84f9152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name : base_classifier\n",
      "name : add_classifier\n"
     ]
    }
   ],
   "source": [
    "Combine_Classifier_03 = CombineClassifier(base_classifier=Combine_Classifier_02 ,\n",
    "                                          add_classifier=classifier_03).to(device)\n",
    "show_module(Combine_Classifier_03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cde72e50-3b4a-40a1-a629-77c0d3dcf509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CombineClassifier(\n",
      "  (base_classifier): CombineClassifier(\n",
      "    (base_classifier): ClassifierModel(\n",
      "      (classifier): Sequential(\n",
      "        (0): Dropout(p=0.1, inplace=False)\n",
      "        (1): Linear(in_features=256, out_features=128, bias=True)\n",
      "        (2): Dropout(p=0.1, inplace=False)\n",
      "        (3): Linear(in_features=128, out_features=2, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (add_classifier): ClassifierModel(\n",
      "      (classifier): Sequential(\n",
      "        (0): Dropout(p=0.1, inplace=False)\n",
      "        (1): Linear(in_features=256, out_features=128, bias=True)\n",
      "        (2): Dropout(p=0.1, inplace=False)\n",
      "        (3): Linear(in_features=128, out_features=2, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (add_classifier): ClassifierModel(\n",
      "    (classifier): Sequential(\n",
      "      (0): Dropout(p=0.1, inplace=False)\n",
      "      (1): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (2): Dropout(p=0.1, inplace=False)\n",
      "      (3): Linear(in_features=128, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(Combine_Classifier_03)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbcf3d1-7d02-4691-aeb9-e49e4e28c9a3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 9.3. 통합 모델 (classifier_01, classifier_02, classifier_03) 을 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "012a04fd-9138-49ca-9342-2e3d2852bada",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Moddels:  3\n",
      "From model_01 Accuracy: 65.72% \n",
      "\n",
      "From model_02 Accuracy: 67.05% \n",
      "\n",
      "From model_03 Accuracy: 67.40% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "output_list = inference_classifier2(Combine_Classifier_03, plm_vector, test_dataloader, test_batch_size, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021a1517-4351-464c-bd76-a3febb982e99",
   "metadata": {},
   "source": [
    "# 10. 4번째 모델 생성 및 통합 모델 (classifier_01, classifier_02, classifier_03, classifier_04) 을 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3cc3004d-2a34-492f-bdf1-eec90c35d8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1) Create Bert MOdel (plm + classifier)\n",
      "29912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcf0203c13a241afbeeb9161de559fdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29912 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1dd646817f24eabacbadc5b04e97fc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3740 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval dataset accuracy in training loop\n",
      "{'accuracy': 0.6545418073618401}\n",
      "{'accuracy': 0.6624653137641671}\n",
      "{'accuracy': 0.6824245260940791}\n",
      "{'accuracy': 0.6810203604025274}\n",
      "inference accuracy for plm plus classifer\n",
      "{'accuracy': 0.6813493337614385}\n",
      "classifier architecture: \n",
      "name : classifier\n",
      "inference accuracy for classifer\n",
      "{'accuracy': 0.6813493337614385}\n",
      "\n",
      "(2) Create a group of four classifiers\n",
      "\n",
      "(3) Look at the architecture\n",
      "name : base_classifier\n",
      "name : add_classifier\n",
      "CombineClassifier(\n",
      "  (base_classifier): CombineClassifier(\n",
      "    (base_classifier): CombineClassifier(\n",
      "      (base_classifier): ClassifierModel(\n",
      "        (classifier): Sequential(\n",
      "          (0): Dropout(p=0.1, inplace=False)\n",
      "          (1): Linear(in_features=256, out_features=128, bias=True)\n",
      "          (2): Dropout(p=0.1, inplace=False)\n",
      "          (3): Linear(in_features=128, out_features=2, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (add_classifier): ClassifierModel(\n",
      "        (classifier): Sequential(\n",
      "          (0): Dropout(p=0.1, inplace=False)\n",
      "          (1): Linear(in_features=256, out_features=128, bias=True)\n",
      "          (2): Dropout(p=0.1, inplace=False)\n",
      "          (3): Linear(in_features=128, out_features=2, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (add_classifier): ClassifierModel(\n",
      "      (classifier): Sequential(\n",
      "        (0): Dropout(p=0.1, inplace=False)\n",
      "        (1): Linear(in_features=256, out_features=128, bias=True)\n",
      "        (2): Dropout(p=0.1, inplace=False)\n",
      "        (3): Linear(in_features=128, out_features=2, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (add_classifier): ClassifierModel(\n",
      "    (classifier): Sequential(\n",
      "      (0): Dropout(p=0.1, inplace=False)\n",
      "      (1): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (2): Dropout(p=0.1, inplace=False)\n",
      "      (3): Linear(in_features=128, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "(4) Inference the group of 4 classifier\n",
      "# of Moddels:  4\n",
      "From model_01 Accuracy: 65.72% \n",
      "\n",
      "From model_02 Accuracy: 67.05% \n",
      "\n",
      "From model_03 Accuracy: 67.40% \n",
      "\n",
      "From model_04 Accuracy: 68.10% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"(1) Create Bert MOdel (plm + classifier)\")\n",
    "\n",
    "num_epochs = 4\n",
    "custom_model =CustomBERTModel(model = plm ,num_labels=2).to(device)\n",
    "optimizer, lr_scheduler, num_training_steps = create_optimizer_scheduler(num_epochs, custom_model, train_dataloader)\n",
    "progress_bar_train = tqdm(range(num_training_steps))\n",
    "progress_bar_eval = tqdm(range(num_epochs * len(eval_dataloader)))\n",
    "classifier_04 = create_bert_model(num_epochs, custom_model)\n",
    "\n",
    "print(\"\\n(2) Create a group of four classifiers\")\n",
    "Combine_Classifier_04 = CombineClassifier(base_classifier=Combine_Classifier_03 ,\n",
    "                                          add_classifier=classifier_04).to(device)\n",
    "print(\"\\n(3) Look at the architecture\")\n",
    "show_module(Combine_Classifier_04)\n",
    "print(Combine_Classifier_04)\n",
    "print(\"\\n(4) Inference the group of 4 classifier\")\n",
    "output_list = inference_classifier2(Combine_Classifier_04, plm_vector, test_dataloader, test_batch_size, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4523038b-fb36-4d06-873d-681551c7d58f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# E. 커널 리스타팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cda480f7-c9dd-422f-a6ac-61557b7ff5d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "\n",
    "IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26f24a7-3514-4e2d-94ba-332ef6a0960b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1dcebd-c78c-4f9b-af5b-4ca56769d543",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cfd3ef-7500-4991-92b0-003026bfe3cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
