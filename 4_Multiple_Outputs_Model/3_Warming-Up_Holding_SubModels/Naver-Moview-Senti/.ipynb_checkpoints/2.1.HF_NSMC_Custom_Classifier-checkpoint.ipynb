{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8e350e8-d8fc-4a24-96b1-5fdcd52d9033",
   "metadata": {
    "tags": []
   },
   "source": [
    "# KoElectr Model 로 네이버 리뷰 감성 분석\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 참조: \n",
    "Adding Custom Layers on Top of a Hugging Face Model\n",
    "- https://towardsdatascience.com/adding-custom-layers-on-top-of-a-hugging-face-model-f1ccdfc257bd\n",
    "- code\n",
    "    - https://jovian.ai/rajbsangani/emotion-tuned-sarcasm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edae9044-ee12-4674-b344-c58323a1ddee",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. 환경 셋업"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20322497-69ac-430c-8307-a794d10e062a",
   "metadata": {},
   "source": [
    "## 1.1 변수 로딩 및 라이브러리 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25b22dd0-0905-46ca-87c8-fbcaa26df55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r local_train_output_path\n",
    "%store -r local_test_output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3977b704-e0e2-454a-8c3a-5c0e41cc3224",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# src 폴더 경로 설정\n",
    "import sys\n",
    "sys.path.append('./src')\n",
    "import config\n",
    "from  data_util import read_nsmc_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d48beefd-c093-4eea-ab8b-7eb55c9513f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "# logger.setLevel(logging.WARNING)\n",
    "logger.addHandler(logging.StreamHandler(sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d65b01ce-944d-4897-be9e-45bd6c8ea29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "from datasets import load_dataset,Dataset,DatasetDict\n",
    "from transformers import DataCollatorWithPadding,AutoModelForSequenceClassification, Trainer, TrainingArguments,AutoTokenizer,AutoModel,AutoConfig\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29595f10-46a0-41ee-ba2e-d5a0bef72eb7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.2. Pre-trained model_id, tokenizer_id 지정\n",
    "- [KoElectra Git](https://github.com/monologg/KoELECTRA)\n",
    "- KoElectra Model\n",
    "    - Small:\n",
    "        - \"monologg/koelectra-small-v3-discriminator\n",
    "    - Base: \n",
    "        - monologg/koelectra-base-v3-discriminator\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df68d46c-82c4-4986-a5cb-c37e3f6b7cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import load_dataset\n",
    "from transformers import (\n",
    "    ElectraModel, \n",
    "    ElectraTokenizer, \n",
    ")\n",
    "\n",
    "tokenizer_id = 'monologg/koelectra-small-v3-discriminator'\n",
    "model_id = \"monologg/koelectra-small-v3-discriminator\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad78dd5-fbd9-4327-bdda-f9bca048bb9c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2. 데이터 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a30c77-427c-4654-97f3-89b6b84b7d36",
   "metadata": {},
   "source": [
    "## 2.1 데이터 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a26888d2-e275-4e7b-9bb5-de5673017606",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, train_labels = read_nsmc_split(local_train_output_path)\n",
    "test_texts, test_labels = read_nsmc_split(local_test_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17fbe7fb-4167-40f7-86f7-69d192b9a03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len: 149552 \n",
      "Sample: ['흠   포스터보고 초딩영화줄    오버연기조차 가볍지 않구나', '너무재밓었다그래서보는것을추천한다', '교도소 이야기구먼   솔직히 재미는 없다  평점 조정', '사이몬페그의 익살스런 연기가 돋보였던 영화 스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다', '막 걸음마 뗀 세부터 초등학교 학년생인 살용영화 ㅋㅋㅋ   별반개도 아까움']\n",
      "len: 149552 \n",
      "Sample: [1, 0, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"len: {len(train_texts)} \\nSample: {train_texts[0:5]}\")\n",
    "logger.info(f\"len: {len(train_labels)} \\nSample: {train_labels[0:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07852d1-7620-4e6d-abc7-3dabb887243a",
   "metadata": {},
   "source": [
    "## 2.2. 훈련 데이타를 분리하여 검증 데이터 세트 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d40bbdd8-6939-44e7-b5f6-4a8181f98408",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4701654-9186-427e-bb5b-a0a2438f021e",
   "metadata": {},
   "source": [
    "# 3. Electra Model 입력 인코딩 변환 및 torch custome Dataset 생성 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadb5211-c576-4eaa-b55d-7dddfc0a8d27",
   "metadata": {},
   "source": [
    "## 3.1. 토큰나이저 로딩 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cc8ca07-27c4-481c-8a38-67f96eba761d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = ElectraTokenizer.from_pretrained(tokenizer_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d08c7b-e5ae-47f1-918b-c36508524476",
   "metadata": {},
   "source": [
    "## 3.2. Electra Model 입력 인코딩 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa5c2a75-1475-4622-9030-09dfbbe5ef33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42.7 s, sys: 260 ms, total: 43 s\n",
      "Wall time: 43 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "tokenizer = ElectraTokenizer.from_pretrained(tokenizer_id)\n",
    "\n",
    "train_encodings = tokenizer(train_texts, return_token_type_ids = False, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_texts, return_token_type_ids = False, truncation=True, padding=True)\n",
    "test_encodings = tokenizer(test_texts, return_token_type_ids = False, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e248c7-b923-4796-85ac-cb6a8c9d903b",
   "metadata": {},
   "source": [
    "## 3.3. torch custome dataset 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "605d7dc4-1684-4d29-8683-c6a8fa1746ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_util import NSMCDataset\n",
    "\n",
    "train_dataset = NSMCDataset(train_encodings, train_labels)\n",
    "val_dataset = NSMCDataset(val_encodings, val_labels)\n",
    "test_dataset = NSMCDataset(test_encodings, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b38f4ee8-c3a6-4ba9-a2ab-abefad3b1fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_dataset) : 119641\n",
      "len(val_dataset) : 29911\n",
      "len(test_dataset) : 49832\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"len(train_dataset) : {len(train_dataset)}\")\n",
    "logger.info(f\"len(val_dataset) : {len(val_dataset)}\")\n",
    "logger.info(f\"len(test_dataset) : {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac537ef-c266-4194-a1de-f47653816f8f",
   "metadata": {},
   "source": [
    "## 3.4. 데이터 로더 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce566fd-8e8d-46a4-ba57-e3555c1fff5c",
   "metadata": {},
   "source": [
    "### Sampler 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cd4f28c-8716-4787-8d82-c9372e935953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size with frac: 0.01 ==> 1196\n",
      "dataset size with frac: 1 ==> 119641\n",
      "dataset size with frac: 0.001 ==> 29\n",
      "dataset size with frac: 1 ==> 29911\n",
      "dataset size with frac: 1 ==> 49832\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "\n",
    "\n",
    "from train_util import create_random_sampler\n",
    "    \n",
    "subset_train_sampler = create_random_sampler(train_dataset, frac=0.01, is_shuffle=True, logger=logger)\n",
    "train_sampler = create_random_sampler(train_dataset, frac=1, is_shuffle=True, logger=logger)\n",
    "\n",
    "subset_eval_sampler = create_random_sampler(val_dataset, frac=0.001, is_shuffle=False, logger=logger)\n",
    "eval_sampler = create_random_sampler(val_dataset, frac=1, is_shuffle=False, logger=logger)\n",
    "test_sampler = create_random_sampler(test_dataset, frac=1, is_shuffle=False, logger=logger)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a78e465-6d44-46ad-b308-7bb8759c2b3c",
   "metadata": {},
   "source": [
    "### 데이터 로더 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75cfd507-8cf8-4aa8-b5d1-88245cc8f908",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 32\n",
    "eval_batch_size = 4\n",
    "test_batch_size = 32\n",
    "\n",
    "\n",
    "train_sample_loader = DataLoader(dataset=train_dataset, \n",
    "                          shuffle=False, \n",
    "                          batch_size=train_batch_size, \n",
    "                          sampler=subset_train_sampler)    \n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_dataset, \n",
    "                          shuffle=False, \n",
    "                          batch_size=train_batch_size, \n",
    "                          sampler=train_sampler)    \n",
    "\n",
    "eval_sample_loader = DataLoader(dataset=val_dataset, \n",
    "                          shuffle=False, \n",
    "                          batch_size=eval_batch_size, \n",
    "                          sampler=subset_eval_sampler)    \n",
    "\n",
    "eval_dataloader = DataLoader(dataset=val_dataset, \n",
    "                          shuffle=False, \n",
    "                          batch_size=eval_batch_size, \n",
    "                          sampler=eval_sampler)    \n",
    "\n",
    "test_dataloader = DataLoader(dataset=test_dataset, \n",
    "                          shuffle=False, \n",
    "                          batch_size=test_batch_size, \n",
    "                          sampler=test_sampler)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165ea065-8111-4fdb-a03d-2e982e2ddebe",
   "metadata": {},
   "source": [
    "# 4.모델 정의 및 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea28a4c-bb65-4fe1-a85a-01e6396191fd",
   "metadata": {},
   "source": [
    "## 4.1. Pre-Trained Model 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1202dfa8-5989-4f09-8b0b-871c51185e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at monologg/koelectra-small-v3-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "plm = AutoModel.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62d47c7-c9b1-4783-b393-46aff52ab1bb",
   "metadata": {},
   "source": [
    "## 4.2. Electra Model 아키텍쳐 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c870af1-4eef-40b0-acdc-e853eebf4eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_module(model):\n",
    "    for name, child in model.named_children():\n",
    "        print(\"name :\", name)\n",
    "        #print(\"child: \\n\", child)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21fe8f79-2277-4ab9-8603-ec6639d49225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name : embeddings\n",
      "name : embeddings_project\n",
      "name : encoder\n"
     ]
    }
   ],
   "source": [
    "show_module(plm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e155afb-f150-4b91-8278-32c34651eef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(plm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec64eadd-2545-40c4-a276-5d4bbaccde0d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4.3. Custom Classifier 추가 하여 Custom Model 생성 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3dd03189-b6f2-42d7-981e-d42b77ed47b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomBERTModel(nn.Module):\n",
    "    def __init__(self,model ,num_labels): \n",
    "        super(CustomBERTModel,self).__init__() \n",
    "        self.num_labels = num_labels \n",
    "\n",
    "        self.model = model\n",
    "        self.dropout = nn.Dropout(0.1) \n",
    "        self.classifier = nn.Linear(256,num_labels) # load and initialize weights    \n",
    "        # self.classifier = nn.Linear(768,num_labels) # load and initialize weights\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None,labels=None):\n",
    "        #Extract outputs from the body\n",
    "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        #Add custom layers\n",
    "        sequence_output = self.dropout(outputs[0]) #outputs[0]=last hidden state\n",
    "\n",
    "        # logits = self.classifier(sequence_output[:,0,:].view(-1,768)) # calculate losses\n",
    "        logits = self.classifier(sequence_output[:,0,:].view(-1,256)) # calculate losses    \n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "          loss_fct = nn.CrossEntropyLoss()\n",
    "          # print(\"logits.view(-1, self.num_labels)\\n\", logits.view(-1, self.num_labels))\n",
    "          # print(\"labels.view(-1): \\n\", labels.view(-1))  \n",
    "          loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "          # print(\"loss: \\n\", loss)\n",
    "\n",
    "        return TokenClassifierOutput(loss=loss, logits=logits, hidden_states=outputs.hidden_states,attentions=outputs.attentions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "05928664-cf83-42c1-aee9-27dd047b82b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "custom_model=CustomBERTModel(model = plm ,num_labels=2).to(device) # plm + custom classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908100ea-bf3b-424f-98cf-43151532c22a",
   "metadata": {},
   "source": [
    "## 4.4. Custome Model 아키텍쳐 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "93f4ef6c-f7fb-404f-bba6-ea69fab227c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name : model\n",
      "name : dropout\n",
      "name : classifier\n"
     ]
    }
   ],
   "source": [
    "show_module(custom_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8901768d-e36a-4bd4-bcaa-2dc7c9755577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(custom_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947cf866-7801-42ca-96b7-dd3db93c34ed",
   "metadata": {},
   "source": [
    "# 5. 모델 훈련 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede5473b-0b03-4a56-bc10-cb03a025fc80",
   "metadata": {},
   "source": [
    "## 5.1. 훈련 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "99abb865-3cbb-4de8-a415-e5771b4cc1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3739\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW,get_scheduler\n",
    "\n",
    "optimizer = AdamW(custom_model.parameters(), lr=5e-5)\n",
    "\n",
    "num_epochs = 1\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")\n",
    "print(num_training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a7c553d0-627c-4454-9311-dc31cea1ba70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "metric = load_metric(\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4182abae-475d-4786-8023-d65f27c94f11",
   "metadata": {},
   "source": [
    "## 5.2. 훈련 루프 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8679a041-6d01-42ad-a800-36f90ff3defc",
   "metadata": {},
   "source": [
    "훈련 루프에 입력이 될 Batch 확인 함. 'eval_dataloader' 를 'train_dataloader' 로 바꾸어서 보시면 됩니다.\n",
    "레코드가 많이 출력이 되어서 eval_dataloader 로 확인 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9ecf33b9-2878-4df2-b9ed-96b882a12354",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for batch in eval_dataloader:\n",
    "#     batch = {k: v.to(device) for k, v in batch.items()}\n",
    "#     print(batch)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14739825-c77d-41ef-bfe0-db475188c350",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5.3. 훈련 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "967963b0-ab70-4ab9-856d-7eb11bc0f2d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c4e388cc94d4681ba3b37cd8b1edd10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3739 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb75e2c0bf2844acb2e266f6f03dddeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7478 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits.view(-1, self.num_labels)\n",
      " tensor([[ 0.0798, -0.0116],\n",
      "        [ 0.3035,  0.1060],\n",
      "        [ 0.0436,  0.0612],\n",
      "        [ 0.0670,  0.0433],\n",
      "        [ 0.2970, -0.1680],\n",
      "        [ 0.4261,  0.1429],\n",
      "        [ 0.3005, -0.1175],\n",
      "        [ 0.1866, -0.1190],\n",
      "        [ 0.2968, -0.0354],\n",
      "        [ 0.0011, -0.0970],\n",
      "        [ 0.2615, -0.0395],\n",
      "        [ 0.0821, -0.0491],\n",
      "        [ 0.1728, -0.0321],\n",
      "        [ 0.0669, -0.0867],\n",
      "        [ 0.1367,  0.0228],\n",
      "        [ 0.2040, -0.0672],\n",
      "        [ 0.2185,  0.0542],\n",
      "        [ 0.2080,  0.0366],\n",
      "        [ 0.1689, -0.3635],\n",
      "        [ 0.1712, -0.1791],\n",
      "        [ 0.3028, -0.0627],\n",
      "        [ 0.2598, -0.0741],\n",
      "        [ 0.2553, -0.0443],\n",
      "        [ 0.1954,  0.0042],\n",
      "        [ 0.2033, -0.1746],\n",
      "        [ 0.2029, -0.1608],\n",
      "        [ 0.2394, -0.1464],\n",
      "        [ 0.2593, -0.2523],\n",
      "        [ 0.2253,  0.0395],\n",
      "        [ 0.1534, -0.2716],\n",
      "        [ 0.2323, -0.0643],\n",
      "        [ 0.0819, -0.1106]], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "labels.view(-1): \n",
      " tensor([1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
      "        0, 1, 1, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "loss: \n",
      " tensor(0.6703, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "progress_bar_train = tqdm(range(num_training_steps))\n",
    "progress_bar_eval = tqdm(range(num_epochs * len(eval_dataloader)))\n",
    "\n",
    "\n",
    "def train_loop(num_epochs, model, train_dataloader, progress_bar_train, \\\n",
    "               eval_dataloader, progress_bar_eval, metric):\n",
    "    for epoch in range(num_epochs):\n",
    "      model.train()\n",
    "      for batch in train_dataloader:\n",
    "          batch = {k: v.to(device) for k, v in batch.items()}\n",
    "          outputs = model(**batch)\n",
    "          loss = outputs.loss\n",
    "          loss.backward()\n",
    "\n",
    "          optimizer.step()\n",
    "          lr_scheduler.step()\n",
    "          optimizer.zero_grad()\n",
    "          progress_bar_train.update(1)\n",
    "            \n",
    "      #     break\n",
    "      # break\n",
    "\n",
    "      model.eval()\n",
    "      for batch in eval_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = custom_model(**batch)\n",
    "\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "        progress_bar_eval.update(1)\n",
    "        \n",
    "        break\n",
    "\n",
    "      print(metric.compute())\n",
    "\n",
    "train_loop(num_epochs, custom_model, train_dataloader, progress_bar_train, \\\n",
    "               eval_dataloader, progress_bar_eval, metric)      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410ec30a-60f1-47db-8dd7-36ff39557e01",
   "metadata": {},
   "source": [
    "# 6. 테스트 데이터 로 모델 평가 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "462f65e8-aef2-4867-83b4-4a2d3a95ca2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaL_model(model, test_dataloader, metric):\n",
    "    model.eval()\n",
    "\n",
    "\n",
    "    for batch in test_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "\n",
    "    print(metric.compute())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "828d93f2-6cca-4365-b9f8-76df3cf9a862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.8686185583560764}\n"
     ]
    }
   ],
   "source": [
    "evaL_model(custom_model, test_dataloader, metric)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4523038b-fb36-4d06-873d-681551c7d58f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# E. 커널 리스타팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cda480f7-c9dd-422f-a6ac-61557b7ff5d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "\n",
    "IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26f24a7-3514-4e2d-94ba-332ef6a0960b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
