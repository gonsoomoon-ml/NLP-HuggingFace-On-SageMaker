{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93c1a746-c105-4130-8044-fd4cda8f80b6",
   "metadata": {},
   "source": [
    "# Warming Up - Combined Multiple Models\n",
    "\n",
    "\n",
    "이 노트북은 독립적으로 모델1, 모델2를 생성을 하고, 이 두개의 모델의 추론 결과를 한개의 통합된 모델에서 추론하는 예제 입니다. 이를 위해서 다음과 같은 작업을 합니다.\n",
    "\n",
    "- 첫번재 Mnist 모델 생성 및 훈련\n",
    "- 두번째 Mnist 모델 생성 및 훈련\n",
    "- 첫번재, 두번째의 모델을 한개의 모델로 통합\n",
    "- 통합된 모델에서 각각 모델의 추론 결과를 얻음\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 참조: \n",
    "- 딥러닝으로 리뷰에서 제품 속성 정보 추출하기\n",
    "    * http://blog.hwahae.co.kr/all/tech/tech-tech/5967/\n",
    "- Keras Functional API\n",
    "    - https://keras.io/guides/functional_api/#setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c8fb4d-a9f1-40dd-9cab-8e53822bbdc9",
   "metadata": {},
   "source": [
    "# 0. 환경 셋업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7d838cd-4b06-4fb6-b63f-4fb52d814af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "#from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Dense, concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ccd2800-3e24-4341-a320-d2cc0eab9a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version: 2.7.1\n"
     ]
    }
   ],
   "source": [
    "print(f\"tensorflow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a2f552-fde5-4b70-aaae-eafdef9efb82",
   "metadata": {},
   "source": [
    "# 1. 첫번째 및 두번째 모델  준비"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d7f71e-c7ed-4a03-a182-0bda8e4d02d8",
   "metadata": {},
   "source": [
    "## 1.1 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6866e77b-4656-4583-b93c-2a28231485b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416fa82d-7f3d-4404-a07f-6f3f659ec65e",
   "metadata": {},
   "source": [
    "## 1.2 두개의 모델 정의 및 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61da88c8-b06e-4879-8a23-1376204cb39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_01():\n",
    "    inputs = keras.Input(shape=(784,), name=\"input_a\")\n",
    "    x = Dense(64, activation=\"relu\", name=\"a_layer_1\")(inputs)\n",
    "    x = Dense(64, activation=\"relu\", name=\"a_layer_2\")(x)\n",
    "    outputs = Dense(10, name=\"a_output_layer\")(x)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"mnist_model\")    \n",
    "    \n",
    "    return model\n",
    "\n",
    "def build_model_02():\n",
    "    inputs = keras.Input(shape=(784,), name=\"input_b\")\n",
    "    x = Dense(64, activation=\"relu\", name=\"b_layer_1\")(inputs)\n",
    "    x = Dense(64, activation=\"relu\", name=\"b_layer_2\")(x)\n",
    "    outputs = Dense(10, name=\"b_output_layer\")(x)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"mnist_model\")    \n",
    "\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99451edd-4a70-4d47-bd7f-cacf46731664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "model_01 = build_model_01()\n",
    "keras.utils.plot_model(model_01, \"model_01.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70eac803-6ab0-470d-ab75-1990f5f6fd08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "model_02 = build_model_02()\n",
    "keras.utils.plot_model(model_02, \"model_02.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64e5e98-d078-41d5-8475-a21cf971493d",
   "metadata": {},
   "source": [
    "## 1.3. 두개의 모델 훈련 및 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66ae9314-e9b1-48cf-be81-6d5bfb5cfbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epoch, x_train, y_train, x_test, y_test):\n",
    "    x_train = x_train.reshape(60000, 784).astype(\"float32\") / 255\n",
    "    x_test = x_test.reshape(10000, 784).astype(\"float32\") / 255\n",
    "\n",
    "    model.compile(\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        optimizer=keras.optimizers.RMSprop(),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    history = model.fit(x_train, y_train, batch_size=64, epochs=epoch, validation_split=0.2)\n",
    "\n",
    "    test_scores = model.evaluate(x_test, y_test, verbose=2)\n",
    "    print(\"Test loss:\", test_scores[0])\n",
    "    print(\"Test accuracy:\", test_scores[1])\n",
    "    \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def predict(model, x_test, y_test, n_sample=10):\n",
    "    x_test = x_test.reshape(10000, 784).astype(\"float32\") / 255\n",
    "\n",
    "    payload = x_test[0:n_sample]\n",
    "    print(\"Inference Input shape: \", payload.shape)\n",
    "    probs = model.predict(payload)\n",
    "    print(\"Inference Output shape:\", np.array(probs).shape)        \n",
    "    \n",
    "    ground_truth = y_test[0:n_sample]\n",
    "    print(\"Ground_Truth: \\n\", ground_truth)\n",
    "    \n",
    "    pre_labels = np.argmax(probs, axis=1)\n",
    "\n",
    "    print(f\"From model - Predicted Label: \\n {pre_labels}\")\n",
    "    \n",
    "    accuracy = accuracy_score(ground_truth, pre_labels)\n",
    "    print(f\"From model - accuracy: \\n {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198b4e63-55f4-49fa-a8c0-3c1acbe3d162",
   "metadata": {},
   "source": [
    "## 1.4. 첫번째 모델 훈련 및 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52f2d4a6-1da8-459f-b738-ea968a95b288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 4s 3ms/step - loss: 0.3492 - accuracy: 0.8999 - val_loss: 0.1885 - val_accuracy: 0.9442\n",
      "313/313 - 0s - loss: 0.1923 - accuracy: 0.9430 - 450ms/epoch - 1ms/step\n",
      "Test loss: 0.19227033853530884\n",
      "Test accuracy: 0.9430000185966492\n"
     ]
    }
   ],
   "source": [
    "epoch = 1\n",
    "train(model_01, epoch, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2d39630-701f-4076-9856-0d9c52fe0878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Input shape:  (100, 784)\n",
      "Inference Output shape: (100, 10)\n",
      "Ground_Truth: \n",
      " [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7\n",
      " 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9\n",
      " 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6 9]\n",
      "From model - Predicted Label: \n",
      " [7 2 1 0 4 1 4 9 6 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 5 7 2 7\n",
      " 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 4 3 7 4 6 4 3 0 7 0 2 9\n",
      " 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 4 3 1 4 1 7 6 9]\n",
      "From model - accuracy: \n",
      " 0.96\n"
     ]
    }
   ],
   "source": [
    "predict(model_01, x_test, y_test, n_sample=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0ef6f3-644d-4a57-9e5f-7007d583a2fa",
   "metadata": {},
   "source": [
    "## 1.5. 두번째 모델 훈련 및 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "913d1487-bbba-4691-bece-00b276b56efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "750/750 [==============================] - 3s 3ms/step - loss: 0.3499 - accuracy: 0.9023 - val_loss: 0.1876 - val_accuracy: 0.9475\n",
      "Epoch 2/5\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1625 - accuracy: 0.9522 - val_loss: 0.1366 - val_accuracy: 0.9595\n",
      "Epoch 3/5\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1192 - accuracy: 0.9639 - val_loss: 0.1244 - val_accuracy: 0.9639\n",
      "Epoch 4/5\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0943 - accuracy: 0.9709 - val_loss: 0.1151 - val_accuracy: 0.9665\n",
      "Epoch 5/5\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0780 - accuracy: 0.9767 - val_loss: 0.1108 - val_accuracy: 0.9705\n",
      "313/313 - 0s - loss: 0.1035 - accuracy: 0.9701 - 463ms/epoch - 1ms/step\n",
      "Test loss: 0.10348072648048401\n",
      "Test accuracy: 0.9700999855995178\n"
     ]
    }
   ],
   "source": [
    "epoch = 5\n",
    "train(model_02, epoch, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c7d8122-2166-403d-8c7e-0350d0efa7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Input shape:  (100, 784)\n",
      "Inference Output shape: (100, 10)\n",
      "Ground_Truth: \n",
      " [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7\n",
      " 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9\n",
      " 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6 9]\n",
      "From model - Predicted Label: \n",
      " [7 2 1 0 4 1 4 9 6 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7\n",
      " 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9\n",
      " 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6 9]\n",
      "From model - accuracy: \n",
      " 0.99\n"
     ]
    }
   ],
   "source": [
    "predict(model_02, x_test, y_test, n_sample=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d969871c-cde8-4b98-b194-53fb2c2b2a0c",
   "metadata": {},
   "source": [
    "# 2. 두 개의 모델을 한개의 모델로 통합"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51907070-561a-4fa2-a617-2b73b8fe319c",
   "metadata": {},
   "source": [
    "## 2.1. 두개의모델을 통합 및 네트워크 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15310c2c-5152-44a4-9c36-6f174c1436ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len layers of add_model:  4\n",
      "len layers of len_base_model:  4\n",
      "added modellayer # :  1\n",
      "added modellayer # :  2\n",
      "added modellayer # :  3\n"
     ]
    }
   ],
   "source": [
    "def combine_model(base_model, add_model, model_ver):\n",
    "    '''\n",
    "    # 추가할 토픽이 학습된 모델에서 PLM을 제외한 layer만을 가져옴\n",
    "    '''\n",
    "    len_add_model = len(add_model.layers)\n",
    "    start_layer_new_model_except_input = 1 # first dense layer\n",
    "    start_layer_base_model = 0    # input layer\n",
    "    \n",
    "    len_base_model = len(base_model.layers)    \n",
    "    print(\"len layers of add_model: \", len_add_model )\n",
    "    print(\"len layers of len_base_model: \", len_base_model )    \n",
    "            \n",
    "    for i in range(start_layer_new_model_except_input,len_add_model):\n",
    "        print(\"added modellayer # : \", i)\n",
    "\n",
    "        if i == 1:\n",
    "            # 첫번째 레이어는 PLM에 붙이고\n",
    "            base_input_layer_output = base_model.layers[start_layer_base_model].output # 784            \n",
    "            X = add_model.layers[i](base_input_layer_output)\n",
    "        else:\n",
    "            # 이후 레이어는 이전 레이어에 붙이자!\n",
    "            X = add_model.layers[i](X)\n",
    "    \n",
    "    outputs = base_model.outputs\n",
    "    outputs.append(X)\n",
    "        \n",
    "    # 결합모델 생성\n",
    "    combined_model = tf.keras.Model(inputs=base_model.input, outputs=outputs, name=\"1\")\n",
    "    \n",
    "    return combined_model\n",
    "\n",
    "wrapped_model = combine_model(model_01, model_02, model_ver=\"1.0\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4973992-d40e-47a7-ba8a-81c77853acd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(wrapped_model, \"my_first_combined_model_with_shape_info.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfe2959-c79a-46f0-8edd-49c3c4a53652",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.2. 통합된 모델을 예측 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d53ce17-6dbb-4796-8d00-4e733b5662f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_c(model, x_test, y_test, n_sample=10):\n",
    "    x_test = x_test.reshape(10000, 784).astype(\"float32\") / 255\n",
    "\n",
    "    payload = x_test[0:n_sample]\n",
    "    print(\"Inference Input shape: \", payload.shape)\n",
    "    probs = model.predict(payload)\n",
    "    print(\"Inference Output shape:\", np.array(probs).shape)        \n",
    "    \n",
    "    \n",
    "    ground_truth = y_test[0:n_sample]\n",
    "    print(\"Ground_Truth: \\n\", ground_truth)\n",
    "\n",
    "\n",
    "    for i, prob in enumerate(probs):\n",
    "        #print(\"prob: \", prob)\n",
    "        pre_labels = np.argmax(prob, axis=1)\n",
    "\n",
    "        print(f\"From model_0{i} - Predicted Label: \\n {pre_labels}\")\n",
    "\n",
    "        accuracy = accuracy_score(ground_truth, pre_labels)\n",
    "        print(f\"From model_0{i} - accuracy: {accuracy}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b74f281a-fe30-4741-b245-42c7017abcf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Input shape:  (100, 784)\n",
      "Inference Output shape: (2, 100, 10)\n",
      "Ground_Truth: \n",
      " [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7\n",
      " 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9\n",
      " 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6 9]\n",
      "From model_00 - Predicted Label: \n",
      " [7 2 1 0 4 1 4 9 6 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 5 7 2 7\n",
      " 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 4 3 7 4 6 4 3 0 7 0 2 9\n",
      " 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 4 3 1 4 1 7 6 9]\n",
      "From model_00 - accuracy: 0.96\n",
      "From model_01 - Predicted Label: \n",
      " [7 2 1 0 4 1 4 9 6 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7\n",
      " 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9\n",
      " 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6 9]\n",
      "From model_01 - accuracy: 0.99\n"
     ]
    }
   ],
   "source": [
    "predict_c(wrapped_model, x_test, y_test, n_sample=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993624db-8153-4cd9-bb31-48fce645f73d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
