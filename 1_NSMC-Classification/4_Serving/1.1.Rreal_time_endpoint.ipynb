{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b1b9946",
   "metadata": {},
   "source": [
    "# [ëª¨ë“ˆ 1.1] Real-Time Endpoint ë°°í¬ ë° ì¶”ë¡ \n",
    "---\n",
    "\n",
    "ë³¸ ì›Œí¬ìƒµì˜ ëª¨ë“  ë…¸íŠ¸ë¶ì€ `conda_python3` ì¶”ê°€ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ê³  ëª¨ë‘ ì´ ì»¤ë„ ì—ì„œ ì‘ì—… í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ ì•„ë˜ì™€ ê°™ì€ ì‘ì—…ì„ í•©ë‹ˆë‹¤.\n",
    "\n",
    "- 1. í™˜ê²½ ì…‹ì—…\n",
    "- 2. ëª¨ë¸ íŒ¨í‚¤ì§•\n",
    "- 3. SageMaker Endpoint Deployment\n",
    "- 4. Inference\n",
    "- 5. í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¶”ë¡  ë° ì„±ëŠ¥ í‰ê°€\n",
    "- 6. ì—”ë“œ í¬ì¸íŠ¸ ì‚­ì œ\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2a1614",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### ì°¸ê³ \n",
    "- ê¹€ëŒ€ê·¼ë‹˜ì˜ ë¦¬í¬ì—ì„œ SageMaker Hugging Face Inference Toolkit ë“±ì„ ìì„¸íˆ ì„¤ëª… í•¨.\n",
    "    - [Lab 2-1: Deploy Hugging Face Transformers in SageMaker Real-time Endpoint](https://github.com/daekeun-ml/sm-huggingface-kornlp/blob/main/lab_2_serving/1_real_time_endpoint.ipynb)\n",
    "    \n",
    "    \n",
    "- HF ê³µì‹ ì‚¬ì´íŠ¸ ì—ì„œ SM Endpint ë¥¼ ë°°í¬í•˜ëŠ” ê°€ì´ë“œ\n",
    "    - [Deploy models to Amazon SageMaker](https://huggingface.co/docs/sagemaker/inference#deploy-a-ğŸ¤—-transformers-model-trained-in-sagemaker)\n",
    "    \n",
    "    \n",
    "- SageMaker Hugging Face Inference Toolkit: \n",
    "    - https://github.com/aws/sagemaker-huggingface-inference-toolkit    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07419d60",
   "metadata": {},
   "source": [
    "# 1. í™˜ê²½ ì…‹ì—…"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e19caa",
   "metadata": {},
   "source": [
    "## ê¸°ë³¸ ì„¸íŒ…\n",
    "ì‚¬ìš©í•˜ëŠ” íŒ¨í‚¤ì§€ëŠ” import ì‹œì ì— ë‹¤ì‹œ ì¬ë¡œë”© í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25aabe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "# ì„œë¹™ ì½”ë“œ\n",
    "sys.path.append('./src')\n",
    "# í›ˆë ¨ ì½”ë“œ\n",
    "sys.path.append('../3_Training/src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba0463fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r bucket\n",
    "%store -r prefix\n",
    "%store -r artifact_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fef7b307",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ì»¤ìŠ¤í…€ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "import config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4096d9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33ea08e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "import logging\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "from sagemaker import session\n",
    "from transformers import ElectraConfig\n",
    "from transformers import (\n",
    "    ElectraModel, ElectraTokenizer, ElectraForSequenceClassification\n",
    ")\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, \n",
    "    format='[{%(filename)s:%(lineno)d} %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(filename='tmp.log'),\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298ad45f",
   "metadata": {},
   "source": [
    "# 2. ëª¨ë¸ íŒ¨í‚¤ì§•\n",
    "- ëª¨ë¸ ì•„í‹°í™íŠ¸ë¥¼ ë‹¤ìš´ë¡œë“œ í•©ë‹ˆë‹¤.\n",
    "- ë‹¤ìš´ë¡œë“œ ë°›ì€ ëª¨ë¸ ì•„í‹°í™íŠ¸ì˜ ì••ì¶•ì„ í•´ì œí•˜ê³  ëª¨ë¸ ê°€ì¤‘ì¹˜ì¸ model.pth íŒŒì¼ì„ ì–»ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a29f161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_data_dir:  models/nsmc\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import config\n",
    "\n",
    "model_data_dir = config.model_dir\n",
    "os.makedirs(model_data_dir, exist_ok=True)\n",
    "print(\"model_data_dir: \", model_data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adef4c7",
   "metadata": {},
   "source": [
    "### ëª¨ë¸ íŒ¨í‚¤ì§• í´ë” ì •ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6baed41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/nsmc\n"
     ]
    }
   ],
   "source": [
    "%%sh -s {model_data_dir}\n",
    "\n",
    "model_data_dir=$1\n",
    "\n",
    "echo $model_data_dir\n",
    "\n",
    "# ê¸°ì¡´ ë°ì´í„° ì‚­ì œ\n",
    "rm -rf $model_data_dir/*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b477bc68",
   "metadata": {},
   "source": [
    "### ëª¨ë¸ ë° í† í°ë‚˜ì´ì € ì•„í‹°í™íŠ¸ ë‹¤ìš´ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d060540e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer_id: monologg/koelectra-small-v3-discriminator\n",
      "model_id: monologg/koelectra-small-v3-discriminator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/transformers/configuration_utils.py:337: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  \"Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 \"\n",
      "Some weights of the model checkpoint at monologg/koelectra-small-v3-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-small-v3-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('models/nsmc/tokenizer_config.json',\n",
       " 'models/nsmc/special_tokens_map.json',\n",
       " 'models/nsmc/vocab.txt',\n",
       " 'models/nsmc/added_tokens.json')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_id = config.tokenizer_id\n",
    "model_id = config.model_id\n",
    "\n",
    "print(f\"tokenizer_id: {tokenizer_id}\")\n",
    "print(f\"model_id: {model_id}\")\n",
    "\n",
    "# Download model and tokenizer\n",
    "model = ElectraForSequenceClassification.from_pretrained(model_id)\n",
    "tokenizer = ElectraTokenizer.from_pretrained(tokenizer_id)\n",
    "\n",
    "# os.makedirs(model_dir, exist_ok=True)\n",
    "model.save_pretrained(model_data_dir)\n",
    "tokenizer.save_pretrained(model_data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc69398",
   "metadata": {},
   "source": [
    "### pre-trained ëª¨ë¸ ê°€ì¤‘ì¹˜ ì‚­ì œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03a771b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/nsmc\n"
     ]
    }
   ],
   "source": [
    "%%sh -s {model_data_dir}\n",
    "\n",
    "model_data_dir=$1\n",
    "\n",
    "echo $model_data_dir\n",
    "\n",
    "# ê¸°ì¡´ ëª¨ë¸ ì‚­ì œã…\n",
    "rm -rf pytorch_model.bin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c17ddf",
   "metadata": {},
   "source": [
    "### fine-tunnig ëœ ëª¨ë¸ ê°€ì¤‘ì¹˜ ë‹¤ìš´ë¡œë“œ ë° ì´ë¦„ ë³€ê²½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b603290a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-154364950293/pytorch-training-2022-06-08-14-54-26-322/output/model.tar.gz\n",
      "models/nsmc\n",
      "download: s3://sagemaker-us-east-1-154364950293/pytorch-training-2022-06-08-14-54-26-322/output/model.tar.gz to models/nsmc/model.tar.gz\n",
      "sentimental-electro-hf.pth\n"
     ]
    }
   ],
   "source": [
    "%%sh -s {artifact_path} {model_data_dir}\n",
    "\n",
    "artifact_path=$1\n",
    "model_data_dir=$2\n",
    "\n",
    "echo $artifact_path\n",
    "echo $model_data_dir\n",
    "\n",
    "\n",
    "# ëª¨ë¸ì„ S3ì—ì„œ ë¡œì»¬ë¡œ ë‹¤ìš´ë¡œë“œ\n",
    "aws s3 cp $artifact_path $model_data_dir\n",
    "\n",
    "# ëª¨ë¸ ë‹¤ìš´ë¡œë“œ í´ë”ë¡œ ì´ë™\n",
    "cd $model_data_dir\n",
    "\n",
    "# ì••ì¶• í•´ì œ\n",
    "tar -xvf model.tar.gz  \n",
    "\n",
    "rm -rf model.tar.gz  \n",
    "\n",
    "# í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ë¥¼ ì•½ì†ëœ pytorch_model.bin ì´ë¦„ìœ¼ë¡œ ë³€ê²½ã…\n",
    "mv sentimental-electro-hf.pth pytorch_model.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b662e5c8",
   "metadata": {},
   "source": [
    "### ëª¨ë¸ ì•„í…Œí™íŠ¸ë¥¼ model.tar.gz ë¡œ ì••ì¶•"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159361b3",
   "metadata": {},
   "source": [
    "ëª¨ë¸ íŒŒë¼ë©”í„° ë° í† í¬ë‚˜ì´ì €ë¥¼ `model.tar.gz`ìœ¼ë¡œ ì••ì¶•í•©ë‹ˆë‹¤. ì••ì¶• íŒŒì¼ëª…ì€ ììœ ë¡­ê²Œ ì§€ì •í•  ìˆ˜ ìˆìœ¼ë‚˜, ë°˜ë“œì‹œ `tar.gz`ë¡œ ì••ì¶•í•´ì•¼ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fec142bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.json\n",
      "pytorch_model.bin\n",
      "special_tokens_map.json\n",
      "tokenizer_config.json\n",
      "vocab.txt\n"
     ]
    }
   ],
   "source": [
    "model_artifact_name = 'model.tar.gz'\n",
    "!cd {model_data_dir} && tar -czvf {model_artifact_name} *.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0044bcab",
   "metadata": {},
   "source": [
    "### model.tar.gz ë¥¼ S3 ì— ì—…ë¡œë“œã…¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0885cb5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: models/nsmc/model.tar.gz to s3://sagemaker-us-east-1-154364950293/KoElectra-HF/model.tar.gz\n",
      "s3_model_path: \n",
      " s3://sagemaker-us-east-1-154364950293/KoElectra-HF\n"
     ]
    }
   ],
   "source": [
    "s3_prefix = prefix\n",
    "s3_model_path = f's3://{bucket}/{s3_prefix}'\n",
    "!aws s3 cp {model_data_dir}/{model_artifact_name} {s3_model_path}/{model_artifact_name}\n",
    "\n",
    "print(\"s3_model_path: \\n\", s3_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561d6535",
   "metadata": {},
   "source": [
    "ëª¨ë¸ íŒŒë¼ë©”í„° ë° í† í¬ë‚˜ì´ì €ë¥¼ `model.tar.gz`ìœ¼ë¡œ ì••ì¶•í•©ë‹ˆë‹¤. ì••ì¶• íŒŒì¼ëª…ì€ ììœ ë¡­ê²Œ ì§€ì •í•  ìˆ˜ ìˆìœ¼ë‚˜, ë°˜ë“œì‹œ `tar.gz`ë¡œ ì••ì¶•í•´ì•¼ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0be12a",
   "metadata": {},
   "source": [
    "# 3. SageMaker Endpoint Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972a8bad",
   "metadata": {},
   "source": [
    "## 3.1. ì•¤ë“œí¬ì¸íŠ¸ ë°°í¬\n",
    " \n",
    "ì•„ë˜ ì½”ë“œë¥¼ ë³´ì‹œë©´ ì•„ì‹œê² ì§€ë§Œ, ì§€ì†ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ëŠ” íŒŒì´ì¬ ë²„ì „&í”„ë ˆì„ì›Œí¬ ë²„ì „&íŠ¸ëœìŠ¤í¬ë¨¸ ë²„ì „ì— ì‰½ê²Œ ëŒ€ì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. AWSì—ì„œ ê´€ë¦¬í•˜ê³  ìˆëŠ” ë”¥ëŸ¬ë‹ ì»¨í…Œì´ë„ˆ(DLC) ëª©ë¡ì„ ì•„ë˜ ì£¼ì†Œì—ì„œ í™•ì¸í•´ ë³´ì„¸ìš”.\n",
    "\n",
    "- https://github.com/aws/deep-learning-containers/blob/master/available_images.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31e87e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# local_model_path = os.path.join(config.model_dir, 'model.tar.gz')\n",
    "# print(\"local_model_path: \", local_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38f5b06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instance_type = \"ml.m5.xlarge\"\n",
    "instance_type = 'ml.g4dn.xlarge' # $ 0.906 per Hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9217547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{session.py:2668} INFO - Creating model with name: huggingface-pytorch-inference-2022-06-08-15-19-15-231\n",
      "[{session.py:3585} INFO - Creating endpoint-config with name huggingface-pytorch-inference-2022-06-08-15-19-15-700\n",
      "[{session.py:3053} INFO - Creating endpoint with name huggingface-pytorch-inference-2022-06-08-15-19-15-700\n"
     ]
    }
   ],
   "source": [
    "# create Hugging Face Model Class\n",
    "hf_model = HuggingFaceModel(\n",
    "    model_data=f\"{s3_model_path}/{model_artifact_name}\",  # path to your trained SageMaker model\n",
    "    role=role,                                            # IAM role with permissions to create an endpoint\n",
    "    transformers_version=\"4.11.0\",                        # Transformers version used\n",
    "    pytorch_version=\"1.9.0\",                              # PyTorch version used\n",
    "    py_version='py38',                                    # Python version used\n",
    "    \n",
    ")\n",
    "\n",
    "# deploy model to SageMaker Inference\n",
    "hf_predictor = hf_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type= instance_type,\n",
    "    wait=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba7e66ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------!CPU times: user 277 ms, sys: 15.1 ms, total: 292 ms\n",
      "Wall time: 5min 3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'EndpointName': 'huggingface-pytorch-inference-2022-06-08-15-19-15-700',\n",
       " 'EndpointArn': 'arn:aws:sagemaker:us-east-1:154364950293:endpoint/huggingface-pytorch-inference-2022-06-08-15-19-15-700',\n",
       " 'EndpointConfigName': 'huggingface-pytorch-inference-2022-06-08-15-19-15-700',\n",
       " 'ProductionVariants': [{'VariantName': 'AllTraffic',\n",
       "   'DeployedImages': [{'SpecifiedImage': '763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-inference:1.9.0-transformers4.11.0-gpu-py38-cu111-ubuntu20.04',\n",
       "     'ResolvedImage': '763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-inference@sha256:b1a3fd4369a4364e153f390d81bd11b49f2c0b8193ad565b4886f10326c2c6b1',\n",
       "     'ResolutionTime': datetime.datetime(2022, 6, 8, 15, 19, 16, 978000, tzinfo=tzlocal())}],\n",
       "   'CurrentWeight': 1.0,\n",
       "   'DesiredWeight': 1.0,\n",
       "   'CurrentInstanceCount': 1,\n",
       "   'DesiredInstanceCount': 1}],\n",
       " 'EndpointStatus': 'InService',\n",
       " 'CreationTime': datetime.datetime(2022, 6, 8, 15, 19, 15, 977000, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2022, 6, 8, 15, 24, 16, 130000, tzinfo=tzlocal()),\n",
       " 'ResponseMetadata': {'RequestId': '527c68c9-6526-4caa-97eb-80536cb07a5c',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '527c68c9-6526-4caa-97eb-80536cb07a5c',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '873',\n",
       "   'date': 'Wed, 08 Jun 2022 15:24:20 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "sess.wait_for_endpoint(hf_predictor.endpoint_name, poll=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b825c5f8",
   "metadata": {},
   "source": [
    "## 3.2. Wait for the endpoint jobs to complete\n",
    "\n",
    "ì—”ë“œí¬ì¸íŠ¸ê°€ ìƒì„±ë  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦½ë‹ˆë‹¤. ì•½ 5-10ë¶„ì˜ ì‹œê°„ì´ ì†Œìš”ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8da88fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b><a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region=us-east-1#/endpoints/huggingface-pytorch-inference-2022-06-08-15-19-15-700\">[Deploy model from S3] Review Endpoint</a></b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "def make_endpoint_link(region, endpoint_name, endpoint_task):\n",
    "    \n",
    "    endpoint_link = f'<b><a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={region}#/endpoints/{endpoint_name}\">{endpoint_task} Review Endpoint</a></b>'   \n",
    "    return endpoint_link \n",
    "        \n",
    "endpoint_link1 = make_endpoint_link(region, hf_predictor.endpoint_name, '[Deploy model from S3]')\n",
    "\n",
    "\n",
    "display(HTML(endpoint_link1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ba7713",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# 4. Inference\n",
    "\n",
    "---\n",
    "\n",
    "ë‘ ê°œì˜ ì—”ë“œí¬ì¸íŠ¸ê°€ ë°°í¬ë˜ì—ˆìŠµë‹ˆë‹¤. ìƒ˜í”Œ ë°ì´í„°ë¡œ ì§ì ‘ ì¶”ë¡ ì„ ìˆ˜í–‰í•´ ë´…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cad31d",
   "metadata": {},
   "source": [
    "## 4.1. SageMaker Python SDK ì¶”ë¡ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f3b6972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example request, you always need to define \"inputs\"\n",
    "payload = {\n",
    "   \"inputs\": [\n",
    "       \"ì •ë§ ì¬ë¯¸ìˆìŠµë‹ˆë‹¤. ì„¸ ë²ˆ ë´ë„ ì§ˆë¦¬ì§€ ì•Šì•„ìš”.\",\n",
    "       \"ì‹œê°„ì´ ì•„ê¹ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì˜í™”ë¥¼ ë³´ì„¸ìš”.\"\n",
    "   ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dfea3315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_1', 'score': 0.994269847869873},\n",
       " {'label': 'LABEL_0', 'score': 0.9986905455589294}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_predictor.predict(payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bf812b",
   "metadata": {},
   "source": [
    "## 4.2. Botoe3 ì¶”ë¡ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33aaa49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "runtime_client = boto3.Session().client('sagemaker-runtime')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "911aa268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.2862389087677002 seconds ---\n",
      "result:  [{'label': 'LABEL_1', 'score': 0.994269847869873}, {'label': 'LABEL_0', 'score': 0.9986905455589294}]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "from inference_utils import invoke_endpoint_hf\n",
    "payload_dump = json.dumps(payload)\n",
    "\n",
    "start_time = time.time()\n",
    "result = invoke_endpoint_hf(runtime_client, hf_predictor.endpoint_name, \n",
    "                         payload_dump,\n",
    "                         content_type='application/json'\n",
    "                        )\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print('result: ', result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c19f211",
   "metadata": {},
   "source": [
    "# 5. í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¶”ë¡  ë° ì„±ëŠ¥ í‰ê°€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b78e2c",
   "metadata": {},
   "source": [
    "## 5.1. í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë”©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d8fdbc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_path = '../3_Training/data/nsmc/test/ratings_test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "916f895c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_util import read_nsmc_split\n",
    "from inference_utils import inference_batch, plot_confusion_matrix\n",
    "\n",
    "# í›ˆë ¨ Text, Label ë¡œë”©    \n",
    "test_texts, test_labels = read_nsmc_split(test_file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64a5f683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_df shape:  (49832, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(49832, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "test_df = pd.DataFrame(data=list(zip(test_texts, test_labels)), \n",
    "                       columns=['doc','label'])\n",
    "print(\"test_df shape: \", test_df.shape)\n",
    "sample_df = test_df[0:50000]\n",
    "sample_df.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a499ba4b",
   "metadata": {},
   "source": [
    "## 5.2. ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì¶”ë¡ \n",
    "-- ì•½ 10 ë¶„ ì •ë„ ì†Œìš” ë¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0230e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "chunk_size = 1024\n",
    "pred_list, score_list = inference_batch(sample_df, chunk_size, runtime_client, hf_predictor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd2ec21",
   "metadata": {},
   "source": [
    "## 5.3. ê¸°ì¡´ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ì‹¤í—˜ ë°ì´í„° ì¶”ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16aabd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.insert(len(sample_df.columns), column='pred', value=pred_list)\n",
    "sample_df.insert(len(sample_df.columns), column='score', value=score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859157ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2bace2",
   "metadata": {},
   "source": [
    "## 5.4. ì •í™•ë„ ë° í˜¼ëˆ í–‰ë ¬ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2ea7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = sample_df.label.tolist()\n",
    "y_pred = sample_df.pred.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8079dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cf = confusion_matrix(y_true, y_pred)\n",
    "plot_confusion_matrix(cf, normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2581fcb",
   "metadata": {},
   "source": [
    "# 6. ì—”ë“œ í¬ì¸íŠ¸ ì‚­ì œ\n",
    "- ê¸°ì¡´ì— ìƒì„±í•œ ë¡œì»¬ ì„¸ì´ì§€ ë©”ì´ì»¤ ëª¨ë¸, ì•¤ë“œí¬ì¸íŠ¸ ì»¨í”¼ê·¸, ì•¤ë“œí¬ì¸íŠ¸ ì‚­ì œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34de24b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference_utils import delete_endpoint\n",
    "\n",
    "client = boto3.Session().client('sagemaker')\n",
    "delete_endpoint(client, hf_predictor.endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a697a9d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c281c456f1b8161c8906f4af2c08ed2c40c50136979eaae69688b01f70e9f4a9"
  },
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
