{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [모듈 0.3]  네이버 영화 리뷰 스크래치\n",
    "\n",
    "- 김대근님의 [Lab 1-1: Train Hugging Face Transformers on Local Environment](https://github.com/daekeun-ml/sm-huggingface-kornlp/blob/main/lab_1_training/1_local_training.ipynb) 노트북의 대부분 내용을 실행한 내용 입니다.\n",
    "---\n",
    "\n",
    "아래 노트북은 다음과 같은 작업을 합니다.\n",
    "- 1. 환경 설정\n",
    "- 2. 데이터 셋트 로딩\n",
    "- 3. Pretrained Model 및 토큰 나이저 로딩\n",
    "- 4. 훈련 준비\n",
    "- 5. 훈련 실행\n",
    "- 6. 추론 및 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, \n",
    "    format='[{%(filename)s:%(lineno)d} %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 데이터 셋트 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    ElectraModel, ElectraTokenizer, ElectraForSequenceClassification, Trainer, TrainingArguments, set_seed\n",
    ")\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_id = 'monologg/koelectra-small-v3-discriminator'\n",
    "model_id = \"monologg/koelectra-small-v3-discriminator\"\n",
    "\n",
    "# dataset used\n",
    "dataset_name = 'nsmc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbb8c3c5519042fc9e06799c65fb82c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/1.36k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f387bf5b45244811b7eacfbb137ed935",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/807 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{builder.py:412} WARNING - Using custom data configuration default\n",
      "Downloading and preparing dataset nsmc/default (download: 18.62 MiB, generated: 20.90 MiB, post-processed: Unknown size, total: 39.52 MiB) to /home/ec2-user/.cache/huggingface/datasets/nsmc/default/1.1.0/bfd4729bf1a67114e5267e6916b9e4807010aeb238e4a3c2b95fbfa3a014b5f3...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea790bf0c17946e8949fa56654832906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11ebdf4a763e4d4f86d42170b57655bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/6.33M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8e4b14b33b5474e99d4d6be5107a1e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/2.12M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d902fbfc1c284795a7b66710a981fbf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebe26cc7b4344492a1a3cb88db78c7d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/150000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e9fc819f16c4164b522e5e4fbaa132b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset nsmc downloaded and prepared to /home/ec2-user/.cache/huggingface/datasets/nsmc/default/1.1.0/bfd4729bf1a67114e5267e6916b9e4807010aeb238e4a3c2b95fbfa3a014b5f3. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96f9ef8ed2fa4564a3d75d5412fdc0ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset, test_dataset = load_dataset(dataset_name, split=['train[:1%]', 'test[:1%]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{<ipython-input-5-6add1803b311>:1} INFO -  loaded train_dataset length is: 1500\n",
      "[{<ipython-input-5-6add1803b311>:2} INFO -  loaded test_dataset length is: 500\n",
      "[{<ipython-input-5-6add1803b311>:3} INFO - {'id': '9976970', 'document': '아 더빙.. 진짜 짜증나네요 목소리', 'label': 0}\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\" loaded train_dataset length is: {len(train_dataset)}\")\n",
    "logger.info(f\" loaded test_dataset length is: {len(test_dataset)}\")\n",
    "logger.info(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datasets.arrow_dataset.Dataset'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'datasets/train'\n",
    "test_dir = 'datasets/test'\n",
    "!rm -rf {train_dir} {test_dir}\n",
    "\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True) \n",
    "\n",
    "if not os.listdir(train_dir):\n",
    "    train_dataset.save_to_disk(train_dir)\n",
    "if not os.listdir(test_dir):\n",
    "    test_dataset.save_to_disk(test_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Pretrained Model 및 토큰 나이저 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{filelock.py:274} INFO - Lock 139738490122928 acquired on /home/ec2-user/.cache/huggingface/transformers/32dc9196217c0cc26c7dd705168e8615ea2d82613aa5b672d7647b8e8d58545f.541023ff50f833a9bab3e48e78ae1856cf6744bdb336c86e797eaf675b62b2b8.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54f5cf13d05e46e5a56acf25a06ebdc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/257k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{filelock.py:318} INFO - Lock 139738490122928 released on /home/ec2-user/.cache/huggingface/transformers/32dc9196217c0cc26c7dd705168e8615ea2d82613aa5b672d7647b8e8d58545f.541023ff50f833a9bab3e48e78ae1856cf6744bdb336c86e797eaf675b62b2b8.lock\n",
      "[{filelock.py:274} INFO - Lock 139738490122928 acquired on /home/ec2-user/.cache/huggingface/transformers/a6c32c62ff893fb2aa32dabc5722c9f9eb7243cc1cb4514b9ba3fdb1b52704d6.35f013c4fd3572cfdddbbdf6223ef162dd4fb536bf83007533f201addf3287b7.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eabf913db3b482eb13d329a36bbdbb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/61.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{filelock.py:318} INFO - Lock 139738490122928 released on /home/ec2-user/.cache/huggingface/transformers/a6c32c62ff893fb2aa32dabc5722c9f9eb7243cc1cb4514b9ba3fdb1b52704d6.35f013c4fd3572cfdddbbdf6223ef162dd4fb536bf83007533f201addf3287b7.lock\n",
      "[{filelock.py:274} INFO - Lock 139735195412128 acquired on /home/ec2-user/.cache/huggingface/transformers/bd0f09888c5a5619ddb9de81d4a9936a94e5f45064f9a23ba6d39241ceebce02.d2485d28e5c07ca60bfa4fe84af673e0df83401e5c56bcdd991878cb4966eb34.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3761f48e771a487a92d90f32cf7a6882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/458 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{filelock.py:318} INFO - Lock 139735195412128 released on /home/ec2-user/.cache/huggingface/transformers/bd0f09888c5a5619ddb9de81d4a9936a94e5f45064f9a23ba6d39241ceebce02.d2485d28e5c07ca60bfa4fe84af673e0df83401e5c56bcdd991878cb4966eb34.lock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/transformers/configuration_utils.py:337: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  \"Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a3e3eb7790e42e0bd962388f8122a68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba33da47c71d44068ad8e6053acf5ab8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# download tokenizer\n",
    "tokenizer = ElectraTokenizer.from_pretrained(tokenizer_id)\n",
    "\n",
    "# tokenizer helper function\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['document'], padding='max_length', max_length=128, truncation=True)\n",
    "\n",
    "# tokenize dataset\n",
    "train_dataset = train_dataset.map(tokenize, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize, batched=True)\n",
    "\n",
    "# set format for pytorch\n",
    "train_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "test_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "def parser_args(train_notebook=False):\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Default Setting\n",
    "    parser.add_argument(\"--epochs\", type=int, default=5)\n",
    "    parser.add_argument(\"--seed\", type=int, default=42)\n",
    "    parser.add_argument(\"--train_batch_size\", type=int, default=32)\n",
    "    parser.add_argument(\"--eval_batch_size\", type=int, default=128)\n",
    "    parser.add_argument(\"--warmup_steps\", type=int, default=0)\n",
    "    parser.add_argument(\"--learning_rate\", type=str, default=5e-5)\n",
    "    parser.add_argument(\"--disable_tqdm\", type=bool, default=False)\n",
    "    parser.add_argument(\"--fp16\", type=bool, default=True)\n",
    "    parser.add_argument(\"--tokenizer_id\", type=str, default='monologg/koelectra-small-v3-discriminator')\n",
    "    parser.add_argument(\"--model_id\", type=str, default='monologg/koelectra-small-v3-discriminator')    \n",
    "\n",
    "    # SageMaker Container environment\n",
    "    parser.add_argument(\"--output_data_dir\", type=str, default=os.environ[\"SM_OUTPUT_DATA_DIR\"])\n",
    "    parser.add_argument(\"--model_dir\", type=str, default=os.environ[\"SM_MODEL_DIR\"])\n",
    "    parser.add_argument(\"--n_gpus\", type=str, default=os.environ[\"SM_NUM_GPUS\"])\n",
    "    parser.add_argument(\"--training_dir\", type=str, default=os.environ[\"SM_CHANNEL_TRAIN\"])\n",
    "    parser.add_argument(\"--test_dir\", type=str, default=os.environ[\"SM_CHANNEL_TEST\"])\n",
    "    parser.add_argument('--chkpt_dir', type=str, default='/opt/ml/checkpoints')     \n",
    "\n",
    "    if train_notebook:\n",
    "        args = parser.parse_args([])\n",
    "    else:\n",
    "        args = parser.parse_args()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{<ipython-input-12-49fe603881c2>:19} INFO - ***** Arguments *****\n",
      "[{<ipython-input-12-49fe603881c2>:20} INFO - epochs=5\n",
      "seed=42\n",
      "train_batch_size=32\n",
      "eval_batch_size=128\n",
      "warmup_steps=0\n",
      "learning_rate=5e-05\n",
      "disable_tqdm=False\n",
      "fp16=True\n",
      "tokenizer_id=monologg/koelectra-small-v3-discriminator\n",
      "model_id=monologg/koelectra-small-v3-discriminator\n",
      "output_data_dir=/home/ec2-user/SageMaker/NLP-HuggingFace-On-SageMaker/2_WarmingUp/data\n",
      "model_dir=/home/ec2-user/SageMaker/NLP-HuggingFace-On-SageMaker/2_WarmingUp/model\n",
      "n_gpus=1\n",
      "training_dir=/home/ec2-user/SageMaker/NLP-HuggingFace-On-SageMaker/2_WarmingUp/datasets/train\n",
      "test_dir=/home/ec2-user/SageMaker/NLP-HuggingFace-On-SageMaker/2_WarmingUp/datasets/test\n",
      "chkpt_dir=chkpt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chkpt_dir = 'chkpt'\n",
    "model_dir = 'model'\n",
    "output_data_dir = 'data'    \n",
    "!rm -rf {chkpt_dir} {model_dir} {output_data_dir} \n",
    "\n",
    "if os.environ.get('SM_CURRENT_HOST') is None:\n",
    "    is_sm_container = False\n",
    "\n",
    "    #src_dir = '/'.join(os.getcwd().split('/')[:-1])\n",
    "    src_dir = os.getcwd()\n",
    "    os.environ['SM_MODEL_DIR'] = f'{src_dir}/{model_dir}'\n",
    "    os.environ['SM_OUTPUT_DATA_DIR'] = f'{src_dir}/{output_data_dir}'\n",
    "    os.environ['SM_NUM_GPUS'] = str(1)\n",
    "    os.environ['SM_CHANNEL_TRAIN'] = f'{src_dir}/{train_dir}'\n",
    "    os.environ['SM_CHANNEL_TEST'] = f'{src_dir}/{test_dir}'\n",
    "\n",
    "args = parser_args(train_notebook=True) \n",
    "args.chkpt_dir = chkpt_dir\n",
    "logger.info(\"***** Arguments *****\")\n",
    "logger.info(''.join(f'{k}={v}\\n' for k, v in vars(args).items()))\n",
    "\n",
    "os.makedirs(args.chkpt_dir, exist_ok=True) \n",
    "os.makedirs(args.model_dir, exist_ok=True)\n",
    "os.makedirs(args.output_data_dir, exist_ok=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['negative', 'positive']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = train_dataset.features[\"label\"].names\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare model labels - useful in inference API\n",
    "\n",
    "num_labels = len(labels)\n",
    "label2id, id2label = dict(), dict()\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = str(i)\n",
    "    id2label[str(i)] = label\n",
    "\n",
    "# Set seed before initializing model\n",
    "set_seed(args.seed)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{filelock.py:274} INFO - Lock 139735425719264 acquired on /home/ec2-user/.cache/huggingface/transformers/052bc3ecf8c8484f1519650794b32b6d2c70750bcba71d1f763951514b5cf0c8.84bb33167d2e89d46f4cde129b2f4c447618ac33ac46f2012ee9e5e706fec112.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8559ebfc219b443a84bdb7b1ce970b4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/54.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{filelock.py:318} INFO - Lock 139735425719264 released on /home/ec2-user/.cache/huggingface/transformers/052bc3ecf8c8484f1519650794b32b6d2c70750bcba71d1f763951514b5cf0c8.84bb33167d2e89d46f4cde129b2f4c447618ac33ac46f2012ee9e5e706fec112.lock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at monologg/koelectra-small-v3-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-small-v3-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Download pytorch model\n",
    "model = ElectraForSequenceClassification.from_pretrained(\n",
    "    model_id, num_labels=num_labels, label2id=label2id, id2label=id2label\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 훈련 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training args\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=args.chkpt_dir,\n",
    "    overwrite_output_dir=True if get_last_checkpoint(args.chkpt_dir) is not None else False,\n",
    "    num_train_epochs=args.epochs,\n",
    "    per_device_train_batch_size=args.train_batch_size,\n",
    "    per_device_eval_batch_size=args.eval_batch_size,\n",
    "    warmup_steps=args.warmup_steps,\n",
    "    fp16=args.fp16,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    disable_tqdm=args.disable_tqdm,\n",
    "    logging_dir=f\"{args.output_data_dir}/logs\",\n",
    "    learning_rate=float(args.learning_rate),\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# compute metrics function for binary classification\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"binary\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp fp16 backend\n"
     ]
    }
   ],
   "source": [
    "# create Trainer instance\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 훈련 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: id, document.\n",
      "***** Running training *****\n",
      "  Num examples = 1500\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 235\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='235' max='235' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [235/235 00:46, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.684440</td>\n",
       "      <td>0.582000</td>\n",
       "      <td>0.376119</td>\n",
       "      <td>0.863014</td>\n",
       "      <td>0.240458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.550594</td>\n",
       "      <td>0.766000</td>\n",
       "      <td>0.773694</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.763359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.486730</td>\n",
       "      <td>0.786000</td>\n",
       "      <td>0.795411</td>\n",
       "      <td>0.796935</td>\n",
       "      <td>0.793893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.504800</td>\n",
       "      <td>0.768000</td>\n",
       "      <td>0.792115</td>\n",
       "      <td>0.746622</td>\n",
       "      <td>0.843511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.461820</td>\n",
       "      <td>0.798000</td>\n",
       "      <td>0.799205</td>\n",
       "      <td>0.834025</td>\n",
       "      <td>0.767176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: id, document.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to chkpt/checkpoint-47\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/transformers/configuration_utils.py:337: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  \"Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 \"\n",
      "Configuration saved in chkpt/checkpoint-47/config.json\n",
      "Model weights saved in chkpt/checkpoint-47/pytorch_model.bin\n",
      "tokenizer config file saved in chkpt/checkpoint-47/tokenizer_config.json\n",
      "Special tokens file saved in chkpt/checkpoint-47/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: id, document.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to chkpt/checkpoint-94\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/transformers/configuration_utils.py:337: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  \"Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 \"\n",
      "Configuration saved in chkpt/checkpoint-94/config.json\n",
      "Model weights saved in chkpt/checkpoint-94/pytorch_model.bin\n",
      "tokenizer config file saved in chkpt/checkpoint-94/tokenizer_config.json\n",
      "Special tokens file saved in chkpt/checkpoint-94/special_tokens_map.json\n",
      "Deleting older checkpoint [chkpt/checkpoint-47] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: id, document.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to chkpt/checkpoint-141\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/transformers/configuration_utils.py:337: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  \"Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 \"\n",
      "Configuration saved in chkpt/checkpoint-141/config.json\n",
      "Model weights saved in chkpt/checkpoint-141/pytorch_model.bin\n",
      "tokenizer config file saved in chkpt/checkpoint-141/tokenizer_config.json\n",
      "Special tokens file saved in chkpt/checkpoint-141/special_tokens_map.json\n",
      "Deleting older checkpoint [chkpt/checkpoint-94] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: id, document.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to chkpt/checkpoint-188\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/transformers/configuration_utils.py:337: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  \"Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 \"\n",
      "Configuration saved in chkpt/checkpoint-188/config.json\n",
      "Model weights saved in chkpt/checkpoint-188/pytorch_model.bin\n",
      "tokenizer config file saved in chkpt/checkpoint-188/tokenizer_config.json\n",
      "Special tokens file saved in chkpt/checkpoint-188/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: id, document.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to chkpt/checkpoint-235\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/transformers/configuration_utils.py:337: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  \"Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 \"\n",
      "Configuration saved in chkpt/checkpoint-235/config.json\n",
      "Model weights saved in chkpt/checkpoint-235/pytorch_model.bin\n",
      "tokenizer config file saved in chkpt/checkpoint-235/tokenizer_config.json\n",
      "Special tokens file saved in chkpt/checkpoint-235/special_tokens_map.json\n",
      "Deleting older checkpoint [chkpt/checkpoint-141] due to args.save_total_limit\n",
      "Deleting older checkpoint [chkpt/checkpoint-188] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from chkpt/checkpoint-235 (score: 0.798).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40.8 s, sys: 4.14 s, total: 44.9 s\n",
      "Wall time: 46.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# train model\n",
    "if get_last_checkpoint(args.chkpt_dir) is not None:\n",
    "    logger.info(\"***** Continue Training *****\")\n",
    "    last_checkpoint = get_last_checkpoint(args.chkpt_dir)\n",
    "    trainer.train(resume_from_checkpoint=last_checkpoint)\n",
    "else:\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 추론 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: id, document.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 128\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_result = trainer.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Evaluation results *****\n",
      "[{<ipython-input-21-be30f6e1b54c>:6} INFO - epoch = 5.0\n",
      "\n",
      "[{<ipython-input-21-be30f6e1b54c>:6} INFO - eval_accuracy = 0.798\n",
      "\n",
      "[{<ipython-input-21-be30f6e1b54c>:6} INFO - eval_f1 = 0.7992047713717694\n",
      "\n",
      "[{<ipython-input-21-be30f6e1b54c>:6} INFO - eval_loss = 0.4618203043937683\n",
      "\n",
      "[{<ipython-input-21-be30f6e1b54c>:6} INFO - eval_precision = 0.8340248962655602\n",
      "\n",
      "[{<ipython-input-21-be30f6e1b54c>:6} INFO - eval_recall = 0.767175572519084\n",
      "\n",
      "[{<ipython-input-21-be30f6e1b54c>:6} INFO - eval_runtime = 0.7208\n",
      "\n",
      "[{<ipython-input-21-be30f6e1b54c>:6} INFO - eval_samples_per_second = 693.718\n",
      "\n",
      "[{<ipython-input-21-be30f6e1b54c>:6} INFO - eval_steps_per_second = 5.55\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# writes eval result to file which can be accessed later in s3 ouput\n",
    "with open(os.path.join(args.output_data_dir, \"eval_results.txt\"), \"w\") as writer:\n",
    "    print(f\"***** Evaluation results *****\")\n",
    "    for key, value in sorted(eval_result.items()):\n",
    "        writer.write(f\"{key} = {value}\\n\")\n",
    "        logger.info(f\"{key} = {value}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: id, document.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 500\n",
      "  Batch size = 128\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "results = trainer.predict(test_dataset)\n",
    "y_true = results.label_ids\n",
    "y_pred = np.argmax(results.predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, target_names=None, cmap=None, normalize=True, labels=True, title='Confusion matrix'):\n",
    "    import itertools\n",
    "    import matplotlib.pyplot as plt\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    \n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "    \n",
    "    if labels:\n",
    "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            if normalize:\n",
    "                plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                         horizontalalignment=\"center\",\n",
    "                         color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "            else:\n",
    "                plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                         horizontalalignment=\"center\",\n",
    "                         color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{font_manager.py:1423} INFO - Generating new fontManager, this may take some time...\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cf = confusion_matrix(y_true, y_pred)\n",
    "plot_confusion_matrix(cf, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /home/ec2-user/SageMaker/NLP-HuggingFace-On-SageMaker/2_WarmingUp/model\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/transformers/configuration_utils.py:337: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  \"Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 \"\n",
      "Configuration saved in /home/ec2-user/SageMaker/NLP-HuggingFace-On-SageMaker/2_WarmingUp/model/config.json\n",
      "Model weights saved in /home/ec2-user/SageMaker/NLP-HuggingFace-On-SageMaker/2_WarmingUp/model/pytorch_model.bin\n",
      "tokenizer config file saved in /home/ec2-user/SageMaker/NLP-HuggingFace-On-SageMaker/2_WarmingUp/model/tokenizer_config.json\n",
      "Special tokens file saved in /home/ec2-user/SageMaker/NLP-HuggingFace-On-SageMaker/2_WarmingUp/model/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "# Remove checkpoints\n",
    "import shutil\n",
    "dir_list = os.listdir(args.chkpt_dir)\n",
    "for d in dir_list:\n",
    "    shutil.rmtree(os.path.join(args.chkpt_dir, d))\n",
    "    \n",
    "trainer.save_model(args.model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "interpreter": {
   "hash": "c281c456f1b8161c8906f4af2c08ed2c40c50136979eaae69688b01f70e9f4a9"
  },
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
