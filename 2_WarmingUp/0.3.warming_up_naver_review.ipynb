{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [모듈 0.3]  네이버 영화 리뷰 스크래치\n",
    "\n",
    "- 김대근님의 [Lab 1-1: Train Hugging Face Transformers on Local Environment](https://github.com/daekeun-ml/sm-huggingface-kornlp/blob/main/lab_1_training/1_local_training.ipynb) 노트북의 대부분 내용을 실행한 내용 입니다.\n",
    "---\n",
    "\n",
    "아래 노트북은 다음과 같은 작업을 합니다.\n",
    "- 1. 환경 설정\n",
    "- 2. 데이터 셋트 로딩\n",
    "- 3. Pretrained Model 및 토큰 나이저 로딩\n",
    "- 4. 훈련 준비\n",
    "- 5. 훈련 실행\n",
    "- 6. 추론 및 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, \n",
    "    format='[{%(filename)s:%(lineno)d} %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 데이터 셋트 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    ElectraModel, ElectraTokenizer, ElectraForSequenceClassification, Trainer, TrainingArguments, set_seed\n",
    ")\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_id = 'monologg/koelectra-small-v3-discriminator'\n",
    "model_id = \"monologg/koelectra-small-v3-discriminator\"\n",
    "\n",
    "# dataset used\n",
    "dataset_name = 'nsmc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{builder.py:412} WARNING - Using custom data configuration default\n",
      "[{builder.py:577} WARNING - Reusing dataset nsmc (/home/ec2-user/.cache/huggingface/datasets/nsmc/default/1.1.0/bfd4729bf1a67114e5267e6916b9e4807010aeb238e4a3c2b95fbfa3a014b5f3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b549908bad2f45be8cfa28341b817d4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset, test_dataset = load_dataset(dataset_name, split=['train[:1%]', 'test[:1%]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{<ipython-input-5-6add1803b311>:1} INFO -  loaded train_dataset length is: 1500\n",
      "[{<ipython-input-5-6add1803b311>:2} INFO -  loaded test_dataset length is: 500\n",
      "[{<ipython-input-5-6add1803b311>:3} INFO - {'id': '9976970', 'document': '아 더빙.. 진짜 짜증나네요 목소리', 'label': 0}\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\" loaded train_dataset length is: {len(train_dataset)}\")\n",
    "logger.info(f\" loaded test_dataset length is: {len(test_dataset)}\")\n",
    "logger.info(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datasets.arrow_dataset.Dataset'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'datasets/train'\n",
    "test_dir = 'datasets/test'\n",
    "!rm -rf {train_dir} {test_dir}\n",
    "\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True) \n",
    "\n",
    "if not os.listdir(train_dir):\n",
    "    train_dataset.save_to_disk(train_dir)\n",
    "if not os.listdir(test_dir):\n",
    "    test_dataset.save_to_disk(test_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Pretrained Model 및 토큰 나이저 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "151c255d61794efda5b1c8b71ac4b2b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0245f2404f8543f0a7360de313cda336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# download tokenizer\n",
    "tokenizer = ElectraTokenizer.from_pretrained(tokenizer_id)\n",
    "\n",
    "# tokenizer helper function\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['document'], padding='max_length', max_length=128, truncation=True)\n",
    "\n",
    "# tokenize dataset\n",
    "train_dataset = train_dataset.map(tokenize, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize, batched=True)\n",
    "\n",
    "# set format for pytorch\n",
    "train_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "test_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser_args(train_notebook=False):\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Default Setting\n",
    "    parser.add_argument(\"--epochs\", type=int, default=5)\n",
    "    parser.add_argument(\"--seed\", type=int, default=42)\n",
    "    parser.add_argument(\"--train_batch_size\", type=int, default=32)\n",
    "    parser.add_argument(\"--eval_batch_size\", type=int, default=128)\n",
    "    parser.add_argument(\"--warmup_steps\", type=int, default=0)\n",
    "    parser.add_argument(\"--learning_rate\", type=str, default=5e-5)\n",
    "    parser.add_argument(\"--disable_tqdm\", type=bool, default=False)\n",
    "    parser.add_argument(\"--fp16\", type=bool, default=True)\n",
    "    parser.add_argument(\"--tokenizer_id\", type=str, default='monologg/koelectra-small-v3-discriminator')\n",
    "    parser.add_argument(\"--model_id\", type=str, default='monologg/koelectra-small-v3-discriminator')    \n",
    "\n",
    "    # SageMaker Container environment\n",
    "    parser.add_argument(\"--output_data_dir\", type=str, default=os.environ[\"SM_OUTPUT_DATA_DIR\"])\n",
    "    parser.add_argument(\"--model_dir\", type=str, default=os.environ[\"SM_MODEL_DIR\"])\n",
    "    parser.add_argument(\"--n_gpus\", type=str, default=os.environ[\"SM_NUM_GPUS\"])\n",
    "    parser.add_argument(\"--training_dir\", type=str, default=os.environ[\"SM_CHANNEL_TRAIN\"])\n",
    "    parser.add_argument(\"--test_dir\", type=str, default=os.environ[\"SM_CHANNEL_TEST\"])\n",
    "    parser.add_argument('--chkpt_dir', type=str, default='/opt/ml/checkpoints')     \n",
    "\n",
    "    if train_notebook:\n",
    "        args = parser.parse_args([])\n",
    "    else:\n",
    "        args = parser.parse_args()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{<ipython-input-15-49fe603881c2>:19} INFO - ***** Arguments *****\n",
      "[{<ipython-input-15-49fe603881c2>:20} INFO - epochs=5\n",
      "seed=42\n",
      "train_batch_size=32\n",
      "eval_batch_size=128\n",
      "warmup_steps=0\n",
      "learning_rate=5e-05\n",
      "disable_tqdm=False\n",
      "fp16=True\n",
      "tokenizer_id=monologg/koelectra-small-v3-discriminator\n",
      "model_id=monologg/koelectra-small-v3-discriminator\n",
      "output_data_dir=/home/ec2-user/SageMaker/sm-huggingface-kornlp/lab_1_training/gsmoon/data\n",
      "model_dir=/home/ec2-user/SageMaker/sm-huggingface-kornlp/lab_1_training/gsmoon/model\n",
      "n_gpus=1\n",
      "training_dir=/home/ec2-user/SageMaker/sm-huggingface-kornlp/lab_1_training/gsmoon/datasets/train\n",
      "test_dir=/home/ec2-user/SageMaker/sm-huggingface-kornlp/lab_1_training/gsmoon/datasets/test\n",
      "chkpt_dir=chkpt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chkpt_dir = 'chkpt'\n",
    "model_dir = 'model'\n",
    "output_data_dir = 'data'    \n",
    "!rm -rf {chkpt_dir} {model_dir} {output_data_dir} \n",
    "\n",
    "if os.environ.get('SM_CURRENT_HOST') is None:\n",
    "    is_sm_container = False\n",
    "\n",
    "    #src_dir = '/'.join(os.getcwd().split('/')[:-1])\n",
    "    src_dir = os.getcwd()\n",
    "    os.environ['SM_MODEL_DIR'] = f'{src_dir}/{model_dir}'\n",
    "    os.environ['SM_OUTPUT_DATA_DIR'] = f'{src_dir}/{output_data_dir}'\n",
    "    os.environ['SM_NUM_GPUS'] = str(1)\n",
    "    os.environ['SM_CHANNEL_TRAIN'] = f'{src_dir}/{train_dir}'\n",
    "    os.environ['SM_CHANNEL_TEST'] = f'{src_dir}/{test_dir}'\n",
    "\n",
    "args = parser_args(train_notebook=True) \n",
    "args.chkpt_dir = chkpt_dir\n",
    "logger.info(\"***** Arguments *****\")\n",
    "logger.info(''.join(f'{k}={v}\\n' for k, v in vars(args).items()))\n",
    "\n",
    "os.makedirs(args.chkpt_dir, exist_ok=True) \n",
    "os.makedirs(args.model_dir, exist_ok=True)\n",
    "os.makedirs(args.output_data_dir, exist_ok=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['negative', 'positive']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = train_dataset.features[\"label\"].names\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare model labels - useful in inference API\n",
    "\n",
    "num_labels = len(labels)\n",
    "label2id, id2label = dict(), dict()\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = str(i)\n",
    "    id2label[str(i)] = label\n",
    "\n",
    "# Set seed before initializing model\n",
    "set_seed(args.seed)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at monologg/koelectra-small-v3-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-small-v3-discriminator and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Download pytorch model\n",
    "model = ElectraForSequenceClassification.from_pretrained(\n",
    "    model_id, num_labels=num_labels, label2id=label2id, id2label=id2label\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 훈련 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training args\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=args.chkpt_dir,\n",
    "    overwrite_output_dir=True if get_last_checkpoint(args.chkpt_dir) is not None else False,\n",
    "    num_train_epochs=args.epochs,\n",
    "    per_device_train_batch_size=args.train_batch_size,\n",
    "    per_device_eval_batch_size=args.eval_batch_size,\n",
    "    warmup_steps=args.warmup_steps,\n",
    "    fp16=args.fp16,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    disable_tqdm=args.disable_tqdm,\n",
    "    logging_dir=f\"{args.output_data_dir}/logs\",\n",
    "    learning_rate=float(args.learning_rate),\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# compute metrics function for binary classification\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"binary\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "# create Trainer instance\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 훈련 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: id, document. If id, document are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 1500\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 60\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [60/60 00:15, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.693302</td>\n",
       "      <td>0.476000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.686711</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.152672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.670213</td>\n",
       "      <td>0.692000</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.752336</td>\n",
       "      <td>0.614504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.649212</td>\n",
       "      <td>0.692000</td>\n",
       "      <td>0.663755</td>\n",
       "      <td>0.775510</td>\n",
       "      <td>0.580153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.638277</td>\n",
       "      <td>0.724000</td>\n",
       "      <td>0.730469</td>\n",
       "      <td>0.748000</td>\n",
       "      <td>0.713740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: id, document. If id, document are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 128\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to chkpt/checkpoint-12\n",
      "Configuration saved in chkpt/checkpoint-12/config.json\n",
      "Model weights saved in chkpt/checkpoint-12/pytorch_model.bin\n",
      "tokenizer config file saved in chkpt/checkpoint-12/tokenizer_config.json\n",
      "Special tokens file saved in chkpt/checkpoint-12/special_tokens_map.json\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: id, document. If id, document are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to chkpt/checkpoint-24\n",
      "Configuration saved in chkpt/checkpoint-24/config.json\n",
      "Model weights saved in chkpt/checkpoint-24/pytorch_model.bin\n",
      "tokenizer config file saved in chkpt/checkpoint-24/tokenizer_config.json\n",
      "Special tokens file saved in chkpt/checkpoint-24/special_tokens_map.json\n",
      "Deleting older checkpoint [chkpt/checkpoint-12] due to args.save_total_limit\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: id, document. If id, document are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to chkpt/checkpoint-36\n",
      "Configuration saved in chkpt/checkpoint-36/config.json\n",
      "Model weights saved in chkpt/checkpoint-36/pytorch_model.bin\n",
      "tokenizer config file saved in chkpt/checkpoint-36/tokenizer_config.json\n",
      "Special tokens file saved in chkpt/checkpoint-36/special_tokens_map.json\n",
      "Deleting older checkpoint [chkpt/checkpoint-24] due to args.save_total_limit\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: id, document. If id, document are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to chkpt/checkpoint-48\n",
      "Configuration saved in chkpt/checkpoint-48/config.json\n",
      "Model weights saved in chkpt/checkpoint-48/pytorch_model.bin\n",
      "tokenizer config file saved in chkpt/checkpoint-48/tokenizer_config.json\n",
      "Special tokens file saved in chkpt/checkpoint-48/special_tokens_map.json\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: id, document. If id, document are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to chkpt/checkpoint-60\n",
      "Configuration saved in chkpt/checkpoint-60/config.json\n",
      "Model weights saved in chkpt/checkpoint-60/pytorch_model.bin\n",
      "tokenizer config file saved in chkpt/checkpoint-60/tokenizer_config.json\n",
      "Special tokens file saved in chkpt/checkpoint-60/special_tokens_map.json\n",
      "Deleting older checkpoint [chkpt/checkpoint-36] due to args.save_total_limit\n",
      "Deleting older checkpoint [chkpt/checkpoint-48] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from chkpt/checkpoint-60 (score: 0.724).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.2 s, sys: 3.93 s, total: 38.1 s\n",
      "Wall time: 26.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# train model\n",
    "if get_last_checkpoint(args.chkpt_dir) is not None:\n",
    "    logger.info(\"***** Continue Training *****\")\n",
    "    last_checkpoint = get_last_checkpoint(args.chkpt_dir)\n",
    "    trainer.train(resume_from_checkpoint=last_checkpoint)\n",
    "else:\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 추론 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: id, document. If id, document are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 128\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:18]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_result = trainer.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Evaluation results *****\n",
      "[{<ipython-input-23-be30f6e1b54c>:6} INFO - epoch = 5.0\n",
      "\n",
      "[{<ipython-input-23-be30f6e1b54c>:6} INFO - eval_accuracy = 0.724\n",
      "\n",
      "[{<ipython-input-23-be30f6e1b54c>:6} INFO - eval_f1 = 0.73046875\n",
      "\n",
      "[{<ipython-input-23-be30f6e1b54c>:6} INFO - eval_loss = 0.6382773518562317\n",
      "\n",
      "[{<ipython-input-23-be30f6e1b54c>:6} INFO - eval_precision = 0.748\n",
      "\n",
      "[{<ipython-input-23-be30f6e1b54c>:6} INFO - eval_recall = 0.7137404580152672\n",
      "\n",
      "[{<ipython-input-23-be30f6e1b54c>:6} INFO - eval_runtime = 0.2919\n",
      "\n",
      "[{<ipython-input-23-be30f6e1b54c>:6} INFO - eval_samples_per_second = 1712.937\n",
      "\n",
      "[{<ipython-input-23-be30f6e1b54c>:6} INFO - eval_steps_per_second = 3.426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# writes eval result to file which can be accessed later in s3 ouput\n",
    "with open(os.path.join(args.output_data_dir, \"eval_results.txt\"), \"w\") as writer:\n",
    "    print(f\"***** Evaluation results *****\")\n",
    "    for key, value in sorted(eval_result.items()):\n",
    "        writer.write(f\"{key} = {value}\\n\")\n",
    "        logger.info(f\"{key} = {value}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: id, document. If id, document are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 500\n",
      "  Batch size = 128\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "results = trainer.predict(test_dataset)\n",
    "y_true = results.label_ids\n",
    "y_pred = np.argmax(results.predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, target_names=None, cmap=None, normalize=True, labels=True, title='Confusion matrix'):\n",
    "    import itertools\n",
    "    import matplotlib.pyplot as plt\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    \n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "    \n",
    "    if labels:\n",
    "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            if normalize:\n",
    "                plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                         horizontalalignment=\"center\",\n",
    "                         color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "            else:\n",
    "                plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                         horizontalalignment=\"center\",\n",
    "                         color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cf = confusion_matrix(y_true, y_pred)\n",
    "plot_confusion_matrix(cf, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /home/ec2-user/SageMaker/sm-huggingface-kornlp/lab_1_training/gsmoon/model\n",
      "Configuration saved in /home/ec2-user/SageMaker/sm-huggingface-kornlp/lab_1_training/gsmoon/model/config.json\n",
      "Model weights saved in /home/ec2-user/SageMaker/sm-huggingface-kornlp/lab_1_training/gsmoon/model/pytorch_model.bin\n",
      "tokenizer config file saved in /home/ec2-user/SageMaker/sm-huggingface-kornlp/lab_1_training/gsmoon/model/tokenizer_config.json\n",
      "Special tokens file saved in /home/ec2-user/SageMaker/sm-huggingface-kornlp/lab_1_training/gsmoon/model/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "# Remove checkpoints\n",
    "import shutil\n",
    "dir_list = os.listdir(args.chkpt_dir)\n",
    "for d in dir_list:\n",
    "    shutil.rmtree(os.path.join(args.chkpt_dir, d))\n",
    "    \n",
    "trainer.save_model(args.model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "interpreter": {
   "hash": "c281c456f1b8161c8906f4af2c08ed2c40c50136979eaae69688b01f70e9f4a9"
  },
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
