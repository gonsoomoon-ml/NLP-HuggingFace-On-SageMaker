{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1914cf4b",
   "metadata": {},
   "source": [
    "# [ëª¨ë“ˆ 1.1] Real-Time Endpoint ë°°í¬ ë° ì¶”ë¡ \n",
    "---\n",
    "\n",
    "ë³¸ ì›Œí¬ìƒµì˜ ëª¨ë“  ë…¸íŠ¸ë¶ì€ `conda_python3` ì¶”ê°€ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ê³  ëª¨ë‘ ì´ ì»¤ë„ ì—ì„œ ì‘ì—… í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ ì•„ë˜ì™€ ê°™ì€ ì‘ì—…ì„ í•©ë‹ˆë‹¤.\n",
    "\n",
    "- 1. í™˜ê²½ ì…‹ì—…\n",
    "- 2. ë°°í¬ ì¤€ë¹„\n",
    "- 3. ì—”ë“œí¬ì¸íŠ¸ ìƒì„±\n",
    "- 4. ì—”ë“œ í¬ì¸íŠ¸ ì¶”ë¡ \n",
    "- 5. ë¡œì»¬ ì—”ë“œ í¬ì¸íŠ¸ ì‚­ì œ\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b8258d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### ì°¸ê³ \n",
    "- ê¹€ëŒ€ê·¼ë‹˜ì˜ ë¦¬í¬ì—ì„œ SageMaker Hugging Face Inference Toolkit ë“±ì„ ìì„¸íˆ ì„¤ëª… í•¨.\n",
    "    - [Lab 2-1: Deploy Hugging Face Transformers in SageMaker Real-time Endpoint](https://github.com/daekeun-ml/sm-huggingface-kornlp/blob/main/lab_2_serving/1_real_time_endpoint.ipynb)\n",
    "    \n",
    "    \n",
    "- HF ê³µì‹ ì‚¬ì´íŠ¸ ì—ì„œ SM Endpint ë¥¼ ë°°í¬í•˜ëŠ” ê°€ì´ë“œ\n",
    "    - [Deploy models to Amazon SageMaker](https://huggingface.co/docs/sagemaker/inference#deploy-a-ğŸ¤—-transformers-model-trained-in-sagemaker)\n",
    "    \n",
    "    \n",
    "- SageMaker Hugging Face Inference Toolkit: \n",
    "    - https://github.com/aws/sagemaker-huggingface-inference-toolkit    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a76dc1",
   "metadata": {},
   "source": [
    "# 1. í™˜ê²½ ì…‹ì—…"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c647aa6c",
   "metadata": {},
   "source": [
    "## ê¸°ë³¸ ì„¸íŒ…\n",
    "ì‚¬ìš©í•˜ëŠ” íŒ¨í‚¤ì§€ëŠ” import ì‹œì ì— ë‹¤ì‹œ ì¬ë¡œë”© í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b24f8eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('./src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05ea23f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r bucket\n",
    "%store -r prefix\n",
    "%store -r artifact_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc0f0131",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ì»¤ìŠ¤í…€ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "import config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bde786ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d9c1822",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "import logging\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "from sagemaker import session\n",
    "from transformers import ElectraConfig\n",
    "from transformers import (\n",
    "    ElectraModel, ElectraTokenizer, ElectraForSequenceClassification\n",
    ")\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, \n",
    "    format='[{%(filename)s:%(lineno)d} %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(filename='tmp.log'),\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c7b7e1",
   "metadata": {},
   "source": [
    "# 2. ëª¨ë¸ íŒ¨í‚¤ì§•\n",
    "- ëª¨ë¸ ì•„í‹°í™íŠ¸ë¥¼ ë‹¤ìš´ë¡œë“œ í•©ë‹ˆë‹¤.\n",
    "- ë‹¤ìš´ë¡œë“œ ë°›ì€ ëª¨ë¸ ì•„í‹°í™íŠ¸ì˜ ì••ì¶•ì„ í•´ì œí•˜ê³  ëª¨ë¸ ê°€ì¤‘ì¹˜ì¸ model.pth íŒŒì¼ì„ ì–»ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d23c6e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_data_dir:  models/nsmc\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import config\n",
    "\n",
    "model_data_dir = config.model_dir\n",
    "os.makedirs(model_data_dir, exist_ok=True)\n",
    "print(\"model_data_dir: \", model_data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb15d2d",
   "metadata": {},
   "source": [
    "### ëª¨ë¸ íŒ¨í‚¤ì§• í´ë” ì •ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d70da7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/nsmc\n"
     ]
    }
   ],
   "source": [
    "%%sh -s {model_data_dir}\n",
    "\n",
    "model_data_dir=$1\n",
    "\n",
    "echo $model_data_dir\n",
    "\n",
    "# ê¸°ì¡´ ë°ì´í„° ì‚­ì œ\n",
    "rm -rf $model_data_dir/*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35fc6e6",
   "metadata": {},
   "source": [
    "### ëª¨ë¸ ë° í† í°ë‚˜ì´ì € ì•„í‹°í™íŠ¸ ë‹¤ìš´ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd2b01c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer_id: monologg/koelectra-small-v3-discriminator\n",
      "model_id: monologg/koelectra-small-v3-discriminator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at monologg/koelectra-small-v3-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense_prediction.weight']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-small-v3-discriminator and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('models/nsmc/tokenizer_config.json',\n",
       " 'models/nsmc/special_tokens_map.json',\n",
       " 'models/nsmc/vocab.txt',\n",
       " 'models/nsmc/added_tokens.json')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_id = config.tokenizer_id\n",
    "model_id = config.model_id\n",
    "\n",
    "print(f\"tokenizer_id: {tokenizer_id}\")\n",
    "print(f\"model_id: {model_id}\")\n",
    "\n",
    "# Download model and tokenizer\n",
    "model = ElectraForSequenceClassification.from_pretrained(model_id)\n",
    "tokenizer = ElectraTokenizer.from_pretrained(tokenizer_id)\n",
    "\n",
    "# os.makedirs(model_dir, exist_ok=True)\n",
    "model.save_pretrained(model_data_dir)\n",
    "tokenizer.save_pretrained(model_data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34534457",
   "metadata": {},
   "source": [
    "### pre-trained ëª¨ë¸ ê°€ì¤‘ì¹˜ ì‚­ì œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db03363a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/nsmc\n"
     ]
    }
   ],
   "source": [
    "%%sh -s {model_data_dir}\n",
    "\n",
    "model_data_dir=$1\n",
    "\n",
    "echo $model_data_dir\n",
    "\n",
    "# ê¸°ì¡´ ëª¨ë¸ ì‚­ì œã…\n",
    "rm -rf pytorch_model.bin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36622b17",
   "metadata": {},
   "source": [
    "### fine-tunnig ëœ ëª¨ë¸ ê°€ì¤‘ì¹˜ ë‹¤ìš´ë¡œë“œ ë° ì´ë¦„ ë³€ê²½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "feffd26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-057716757052/pytorch-training-2022-06-05-11-54-33-968/output/model.tar.gz\n",
      "models/nsmc\n",
      "download: s3://sagemaker-us-east-1-057716757052/pytorch-training-2022-06-05-11-54-33-968/output/model.tar.gz to models/nsmc/model.tar.gz\n",
      "sentimental-electro-hf.pth\n"
     ]
    }
   ],
   "source": [
    "%%sh -s {artifact_path} {model_data_dir}\n",
    "\n",
    "artifact_path=$1\n",
    "model_data_dir=$2\n",
    "\n",
    "echo $artifact_path\n",
    "echo $model_data_dir\n",
    "\n",
    "\n",
    "# ëª¨ë¸ì„ S3ì—ì„œ ë¡œì»¬ë¡œ ë‹¤ìš´ë¡œë“œ\n",
    "aws s3 cp $artifact_path $model_data_dir\n",
    "\n",
    "# ëª¨ë¸ ë‹¤ìš´ë¡œë“œ í´ë”ë¡œ ì´ë™\n",
    "cd $model_data_dir\n",
    "\n",
    "# ì••ì¶• í•´ì œ\n",
    "tar -xvf model.tar.gz  \n",
    "\n",
    "rm -rf model.tar.gz  \n",
    "\n",
    "# í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ë¥¼ ì•½ì†ëœ pytorch_model.bin ì´ë¦„ìœ¼ë¡œ ë³€ê²½ã…\n",
    "mv sentimental-electro-hf.pth pytorch_model.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dec23a0",
   "metadata": {},
   "source": [
    "### ëª¨ë¸ ì•„í…Œí™íŠ¸ë¥¼ model.tar.gz ë¡œ ì••ì¶•"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a204c37",
   "metadata": {},
   "source": [
    "ëª¨ë¸ íŒŒë¼ë©”í„° ë° í† í¬ë‚˜ì´ì €ë¥¼ `model.tar.gz`ìœ¼ë¡œ ì••ì¶•í•©ë‹ˆë‹¤. ì••ì¶• íŒŒì¼ëª…ì€ ììœ ë¡­ê²Œ ì§€ì •í•  ìˆ˜ ìˆìœ¼ë‚˜, ë°˜ë“œì‹œ `tar.gz`ë¡œ ì••ì¶•í•´ì•¼ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "188f6d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.json\n",
      "pytorch_model.bin\n",
      "special_tokens_map.json\n",
      "tokenizer_config.json\n",
      "vocab.txt\n"
     ]
    }
   ],
   "source": [
    "model_artifact_name = 'model.tar.gz'\n",
    "!cd {model_data_dir} && tar -czvf {model_artifact_name} *.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171717f9",
   "metadata": {},
   "source": [
    "### model.tar.gz ë¥¼ S3 ì— ì—…ë¡œë“œã…¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f013b753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: models/nsmc/model.tar.gz to s3://sagemaker-us-east-1-057716757052/KoElectra-HF/model.tar.gz\n",
      "s3_model_path: \n",
      " s3://sagemaker-us-east-1-057716757052/KoElectra-HF\n"
     ]
    }
   ],
   "source": [
    "s3_prefix = prefix\n",
    "s3_model_path = f's3://{bucket}/{s3_prefix}'\n",
    "!aws s3 cp {model_data_dir}/{model_artifact_name} {s3_model_path}/{model_artifact_name}\n",
    "\n",
    "print(\"s3_model_path: \\n\", s3_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c903821",
   "metadata": {},
   "source": [
    "ëª¨ë¸ íŒŒë¼ë©”í„° ë° í† í¬ë‚˜ì´ì €ë¥¼ `model.tar.gz`ìœ¼ë¡œ ì••ì¶•í•©ë‹ˆë‹¤. ì••ì¶• íŒŒì¼ëª…ì€ ììœ ë¡­ê²Œ ì§€ì •í•  ìˆ˜ ìˆìœ¼ë‚˜, ë°˜ë“œì‹œ `tar.gz`ë¡œ ì••ì¶•í•´ì•¼ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a40e11",
   "metadata": {},
   "source": [
    "# 3. SageMaker Endpoint Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9384ba42",
   "metadata": {},
   "source": [
    "## 3.1. ì•¤ë“œí¬ì¸íŠ¸ ë°°í¬\n",
    " \n",
    "ì•„ë˜ ì½”ë“œë¥¼ ë³´ì‹œë©´ ì•„ì‹œê² ì§€ë§Œ, ì§€ì†ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ëŠ” íŒŒì´ì¬ ë²„ì „&í”„ë ˆì„ì›Œí¬ ë²„ì „&íŠ¸ëœìŠ¤í¬ë¨¸ ë²„ì „ì— ì‰½ê²Œ ëŒ€ì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. AWSì—ì„œ ê´€ë¦¬í•˜ê³  ìˆëŠ” ë”¥ëŸ¬ë‹ ì»¨í…Œì´ë„ˆ(DLC) ëª©ë¡ì„ ì•„ë˜ ì£¼ì†Œì—ì„œ í™•ì¸í•´ ë³´ì„¸ìš”.\n",
    "\n",
    "- https://github.com/aws/deep-learning-containers/blob/master/available_images.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe672b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# local_model_path = os.path.join(config.model_dir, 'model.tar.gz')\n",
    "# print(\"local_model_path: \", local_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4030bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_type = \"ml.m5.xlarge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2abfb475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{session.py:2668} INFO - Creating model with name: huggingface-pytorch-inference-2022-06-06-02-48-36-525\n",
      "[{session.py:3585} INFO - Creating endpoint-config with name huggingface-pytorch-inference-2022-06-06-02-48-36-821\n",
      "[{session.py:3053} INFO - Creating endpoint with name huggingface-pytorch-inference-2022-06-06-02-48-36-821\n"
     ]
    }
   ],
   "source": [
    "# create Hugging Face Model Class\n",
    "hf_model = HuggingFaceModel(\n",
    "    model_data=f\"{s3_model_path}/{model_artifact_name}\",  # path to your trained SageMaker model\n",
    "    role=role,                                            # IAM role with permissions to create an endpoint\n",
    "#     transformers_version=\"4.17.0\",                        # Transformers version used\n",
    "#     pytorch_version=\"1.9.1\",                              # PyTorch version used\n",
    "#     py_version='py38',                                    # Python version used\n",
    "    transformers_version=\"4.12.3\",                        # Transformers version used\n",
    "    pytorch_version=\"1.9.1\",                              # PyTorch version used\n",
    "    py_version='py38',                                    # Python version used\n",
    "    \n",
    ")\n",
    "\n",
    "# deploy model to SageMaker Inference\n",
    "hf_predictor = hf_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type= instance_type,\n",
    "    wait=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bed61af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------!CPU times: user 295 ms, sys: 32.8 ms, total: 327 ms\n",
      "Wall time: 5min 43s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'EndpointName': 'huggingface-pytorch-inference-2022-06-06-02-48-36-821',\n",
       " 'EndpointArn': 'arn:aws:sagemaker:us-east-1:057716757052:endpoint/huggingface-pytorch-inference-2022-06-06-02-48-36-821',\n",
       " 'EndpointConfigName': 'huggingface-pytorch-inference-2022-06-06-02-48-36-821',\n",
       " 'ProductionVariants': [{'VariantName': 'AllTraffic',\n",
       "   'DeployedImages': [{'SpecifiedImage': '763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-inference:1.9.1-transformers4.12.3-cpu-py38-ubuntu20.04',\n",
       "     'ResolvedImage': '763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-inference@sha256:13a97f950cc426afa114b777d443e2f9c6292ac169b65340e59a86ee5315cef1',\n",
       "     'ResolutionTime': datetime.datetime(2022, 6, 6, 2, 49, 25, 659000, tzinfo=tzlocal())}],\n",
       "   'CurrentWeight': 1.0,\n",
       "   'DesiredWeight': 1.0,\n",
       "   'CurrentInstanceCount': 1,\n",
       "   'DesiredInstanceCount': 1}],\n",
       " 'EndpointStatus': 'InService',\n",
       " 'CreationTime': datetime.datetime(2022, 6, 6, 2, 48, 37, 55000, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2022, 6, 6, 2, 54, 16, 993000, tzinfo=tzlocal()),\n",
       " 'ResponseMetadata': {'RequestId': '8fdfeabd-58ad-41a8-8da0-dfc495cb03d8',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '8fdfeabd-58ad-41a8-8da0-dfc495cb03d8',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '868',\n",
       "   'date': 'Mon, 06 Jun 2022 02:54:19 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "sess.wait_for_endpoint(hf_predictor.endpoint_name, poll=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a0a74b",
   "metadata": {},
   "source": [
    "## 3.2. Wait for the endpoint jobs to complete\n",
    "\n",
    "ì—”ë“œí¬ì¸íŠ¸ê°€ ìƒì„±ë  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦½ë‹ˆë‹¤. ì•½ 5-10ë¶„ì˜ ì‹œê°„ì´ ì†Œìš”ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e0cdf8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b><a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region=us-east-1#/endpoints/huggingface-pytorch-inference-2022-06-06-02-48-36-821\">[Deploy model from S3] Review Endpoint</a></b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "def make_endpoint_link(region, endpoint_name, endpoint_task):\n",
    "    \n",
    "    endpoint_link = f'<b><a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={region}#/endpoints/{endpoint_name}\">{endpoint_task} Review Endpoint</a></b>'   \n",
    "    return endpoint_link \n",
    "        \n",
    "endpoint_link1 = make_endpoint_link(region, hf_predictor.endpoint_name, '[Deploy model from S3]')\n",
    "\n",
    "\n",
    "display(HTML(endpoint_link1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f615dca9",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# 4. Inference\n",
    "\n",
    "---\n",
    "\n",
    "ë‘ ê°œì˜ ì—”ë“œí¬ì¸íŠ¸ê°€ ë°°í¬ë˜ì—ˆìŠµë‹ˆë‹¤. ìƒ˜í”Œ ë°ì´í„°ë¡œ ì§ì ‘ ì¶”ë¡ ì„ ìˆ˜í–‰í•´ ë´…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ba7040",
   "metadata": {},
   "source": [
    "## 4.1. SageMaker Python SDK ì¶”ë¡ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b5ff748f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example request, you always need to define \"inputs\"\n",
    "payload = {\n",
    "   \"inputs\": [\n",
    "       \"ì •ë§ ì¬ë¯¸ìˆìŠµë‹ˆë‹¤. ì„¸ ë²ˆ ë´ë„ ì§ˆë¦¬ì§€ ì•Šì•„ìš”.\",\n",
    "       \"ì‹œê°„ì´ ì•„ê¹ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì˜í™”ë¥¼ ë³´ì„¸ìš”.\"\n",
    "   ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee2c45a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_1', 'score': 0.9441463351249695},\n",
       " {'label': 'LABEL_0', 'score': 0.6941782832145691}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_predictor.predict(payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b364a50",
   "metadata": {},
   "source": [
    "## 4.2. Botoe3 ì¶”ë¡ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e087af32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "runtime_client = boto3.Session().client('sagemaker-runtime')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9dd873e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.24317169189453125 seconds ---\n",
      "result:  [{'label': 'LABEL_1', 'score': 0.9441463351249695}, {'label': 'LABEL_0', 'score': 0.6941782832145691}]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "from inference_utils import invoke_endpoint_hf\n",
    "payload_dump = json.dumps(payload)\n",
    "\n",
    "start_time = time.time()\n",
    "result = invoke_endpoint_hf(runtime_client, hf_predictor.endpoint_name, \n",
    "                         payload_dump,\n",
    "                         content_type='application/json'\n",
    "                        )\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print('result: ', result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d357c6",
   "metadata": {},
   "source": [
    "# 5. ì—”ë“œ í¬ì¸íŠ¸ ì‚­ì œ\n",
    "- ê¸°ì¡´ì— ìƒì„±í•œ ë¡œì»¬ ì„¸ì´ì§€ ë©”ì´ì»¤ ëª¨ë¸, ì•¤ë“œí¬ì¸íŠ¸ ì»¨í”¼ê·¸, ì•¤ë“œí¬ì¸íŠ¸ ì‚­ì œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a1fd6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Deleted model: huggingface-pytorch-inference-2022-06-06-02-48-36-525\n",
      "--- Deleted endpoint: huggingface-pytorch-inference-2022-06-06-02-48-36-821\n",
      "--- Deleted endpoint_config: huggingface-pytorch-inference-2022-06-06-02-48-36-821\n"
     ]
    }
   ],
   "source": [
    "from inference_utils import delete_endpoint\n",
    "\n",
    "client = boto3.Session().client('sagemaker')\n",
    "delete_endpoint(client, hf_predictor.endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3f55ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c281c456f1b8161c8906f4af2c08ed2c40c50136979eaae69688b01f70e9f4a9"
  },
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
