{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1914cf4b",
   "metadata": {},
   "source": [
    "# [모듈 1.1] Real-Time Endpoint 배포 및 추론\n",
    "---\n",
    "\n",
    "본 워크샵의 모든 노트북은 `conda_python3` 추가 패키지를 설치하고 모두 이 커널 에서 작업 합니다.\n",
    "\n",
    "이 노트북은 아래와 같은 작업을 합니다.\n",
    "\n",
    "- 1. 환경 셋업\n",
    "- 2. 배포 준비\n",
    "- 3. 엔드포인트 생성\n",
    "- 4. 엔드 포인트 추론\n",
    "- 5. 로컬 엔드 포인트 삭제\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b8258d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 참고\n",
    "- 김대근님의 리포에서 SageMaker Hugging Face Inference Toolkit 등을 자세히 설명 함.\n",
    "    - [Lab 2-1: Deploy Hugging Face Transformers in SageMaker Real-time Endpoint](https://github.com/daekeun-ml/sm-huggingface-kornlp/blob/main/lab_2_serving/1_real_time_endpoint.ipynb)\n",
    "    \n",
    "    \n",
    "- HF 공식 사이트 에서 SM Endpint 를 배포하는 가이드\n",
    "    - [Deploy models to Amazon SageMaker](https://huggingface.co/docs/sagemaker/inference#deploy-a-🤗-transformers-model-trained-in-sagemaker)\n",
    "    \n",
    "    \n",
    "- SageMaker Hugging Face Inference Toolkit: \n",
    "    - https://github.com/aws/sagemaker-huggingface-inference-toolkit    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a76dc1",
   "metadata": {},
   "source": [
    "# 1. 환경 셋업"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c647aa6c",
   "metadata": {},
   "source": [
    "## 기본 세팅\n",
    "사용하는 패키지는 import 시점에 다시 재로딩 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b24f8eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('./src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05ea23f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r bucket\n",
    "%store -r prefix\n",
    "%store -r artifact_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc0f0131",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 커스텀 라이브러리\n",
    "import config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bde786ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d9c1822",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "import logging\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "from sagemaker import session\n",
    "from transformers import ElectraConfig\n",
    "from transformers import (\n",
    "    ElectraModel, ElectraTokenizer, ElectraForSequenceClassification\n",
    ")\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, \n",
    "    format='[{%(filename)s:%(lineno)d} %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(filename='tmp.log'),\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c7b7e1",
   "metadata": {},
   "source": [
    "# 2. 모델 패키징\n",
    "- 모델 아티펙트를 다운로드 합니다.\n",
    "- 다운로드 받은 모델 아티펙트의 압축을 해제하고 모델 가중치인 model.pth 파일을 얻습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d23c6e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_data_dir:  models/nsmc\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import config\n",
    "\n",
    "model_data_dir = config.model_dir\n",
    "os.makedirs(model_data_dir, exist_ok=True)\n",
    "print(\"model_data_dir: \", model_data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb15d2d",
   "metadata": {},
   "source": [
    "### 모델 패키징 폴더 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d70da7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/nsmc\n"
     ]
    }
   ],
   "source": [
    "%%sh -s {model_data_dir}\n",
    "\n",
    "model_data_dir=$1\n",
    "\n",
    "echo $model_data_dir\n",
    "\n",
    "# 기존 데이터 삭제\n",
    "rm -rf $model_data_dir/*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35fc6e6",
   "metadata": {},
   "source": [
    "### 모델 및 토큰나이저 아티펙트 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd2b01c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer_id: monologg/koelectra-small-v3-discriminator\n",
      "model_id: monologg/koelectra-small-v3-discriminator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at monologg/koelectra-small-v3-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense_prediction.weight']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-small-v3-discriminator and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('models/nsmc/tokenizer_config.json',\n",
       " 'models/nsmc/special_tokens_map.json',\n",
       " 'models/nsmc/vocab.txt',\n",
       " 'models/nsmc/added_tokens.json')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_id = config.tokenizer_id\n",
    "model_id = config.model_id\n",
    "\n",
    "print(f\"tokenizer_id: {tokenizer_id}\")\n",
    "print(f\"model_id: {model_id}\")\n",
    "\n",
    "# Download model and tokenizer\n",
    "model = ElectraForSequenceClassification.from_pretrained(model_id)\n",
    "tokenizer = ElectraTokenizer.from_pretrained(tokenizer_id)\n",
    "\n",
    "# os.makedirs(model_dir, exist_ok=True)\n",
    "model.save_pretrained(model_data_dir)\n",
    "tokenizer.save_pretrained(model_data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34534457",
   "metadata": {},
   "source": [
    "### pre-trained 모델 가중치 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db03363a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/nsmc\n"
     ]
    }
   ],
   "source": [
    "%%sh -s {model_data_dir}\n",
    "\n",
    "model_data_dir=$1\n",
    "\n",
    "echo $model_data_dir\n",
    "\n",
    "# 기존 모델 삭제ㅁ\n",
    "rm -rf pytorch_model.bin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36622b17",
   "metadata": {},
   "source": [
    "### fine-tunnig 된 모델 가중치 다운로드 및 이름 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "feffd26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-057716757052/pytorch-training-2022-06-05-11-54-33-968/output/model.tar.gz\n",
      "models/nsmc\n",
      "download: s3://sagemaker-us-east-1-057716757052/pytorch-training-2022-06-05-11-54-33-968/output/model.tar.gz to models/nsmc/model.tar.gz\n",
      "sentimental-electro-hf.pth\n"
     ]
    }
   ],
   "source": [
    "%%sh -s {artifact_path} {model_data_dir}\n",
    "\n",
    "artifact_path=$1\n",
    "model_data_dir=$2\n",
    "\n",
    "echo $artifact_path\n",
    "echo $model_data_dir\n",
    "\n",
    "\n",
    "# 모델을 S3에서 로컬로 다운로드\n",
    "aws s3 cp $artifact_path $model_data_dir\n",
    "\n",
    "# 모델 다운로드 폴더로 이동\n",
    "cd $model_data_dir\n",
    "\n",
    "# 압축 해제\n",
    "tar -xvf model.tar.gz  \n",
    "\n",
    "rm -rf model.tar.gz  \n",
    "\n",
    "# 훈련된 가중치를 약속된 pytorch_model.bin 이름으로 변경ㅁ\n",
    "mv sentimental-electro-hf.pth pytorch_model.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dec23a0",
   "metadata": {},
   "source": [
    "### 모델 아테펙트를 model.tar.gz 로 압축"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a204c37",
   "metadata": {},
   "source": [
    "모델 파라메터 및 토크나이저를 `model.tar.gz`으로 압축합니다. 압축 파일명은 자유롭게 지정할 수 있으나, 반드시 `tar.gz`로 압축해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "188f6d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.json\n",
      "pytorch_model.bin\n",
      "special_tokens_map.json\n",
      "tokenizer_config.json\n",
      "vocab.txt\n"
     ]
    }
   ],
   "source": [
    "model_artifact_name = 'model.tar.gz'\n",
    "!cd {model_data_dir} && tar -czvf {model_artifact_name} *.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171717f9",
   "metadata": {},
   "source": [
    "### model.tar.gz 를 S3 에 업로드ㅡ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f013b753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: models/nsmc/model.tar.gz to s3://sagemaker-us-east-1-057716757052/KoElectra-HF/model.tar.gz\n",
      "s3_model_path: \n",
      " s3://sagemaker-us-east-1-057716757052/KoElectra-HF\n"
     ]
    }
   ],
   "source": [
    "s3_prefix = prefix\n",
    "s3_model_path = f's3://{bucket}/{s3_prefix}'\n",
    "!aws s3 cp {model_data_dir}/{model_artifact_name} {s3_model_path}/{model_artifact_name}\n",
    "\n",
    "print(\"s3_model_path: \\n\", s3_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c903821",
   "metadata": {},
   "source": [
    "모델 파라메터 및 토크나이저를 `model.tar.gz`으로 압축합니다. 압축 파일명은 자유롭게 지정할 수 있으나, 반드시 `tar.gz`로 압축해야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a40e11",
   "metadata": {},
   "source": [
    "# 3. SageMaker Endpoint Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9384ba42",
   "metadata": {},
   "source": [
    "## 3.1. 앤드포인트 배포\n",
    " \n",
    "아래 코드를 보시면 아시겠지만, 지속적으로 업데이트되는 파이썬 버전&프레임워크 버전&트랜스포머 버전에 쉽게 대응할 수 있습니다. AWS에서 관리하고 있는 딥러닝 컨테이너(DLC) 목록을 아래 주소에서 확인해 보세요.\n",
    "\n",
    "- https://github.com/aws/deep-learning-containers/blob/master/available_images.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe672b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# local_model_path = os.path.join(config.model_dir, 'model.tar.gz')\n",
    "# print(\"local_model_path: \", local_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4030bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_type = \"ml.m5.xlarge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2abfb475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{session.py:2668} INFO - Creating model with name: huggingface-pytorch-inference-2022-06-06-02-48-36-525\n",
      "[{session.py:3585} INFO - Creating endpoint-config with name huggingface-pytorch-inference-2022-06-06-02-48-36-821\n",
      "[{session.py:3053} INFO - Creating endpoint with name huggingface-pytorch-inference-2022-06-06-02-48-36-821\n"
     ]
    }
   ],
   "source": [
    "# create Hugging Face Model Class\n",
    "hf_model = HuggingFaceModel(\n",
    "    model_data=f\"{s3_model_path}/{model_artifact_name}\",  # path to your trained SageMaker model\n",
    "    role=role,                                            # IAM role with permissions to create an endpoint\n",
    "#     transformers_version=\"4.17.0\",                        # Transformers version used\n",
    "#     pytorch_version=\"1.9.1\",                              # PyTorch version used\n",
    "#     py_version='py38',                                    # Python version used\n",
    "    transformers_version=\"4.12.3\",                        # Transformers version used\n",
    "    pytorch_version=\"1.9.1\",                              # PyTorch version used\n",
    "    py_version='py38',                                    # Python version used\n",
    "    \n",
    ")\n",
    "\n",
    "# deploy model to SageMaker Inference\n",
    "hf_predictor = hf_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type= instance_type,\n",
    "    wait=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bed61af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------!CPU times: user 295 ms, sys: 32.8 ms, total: 327 ms\n",
      "Wall time: 5min 43s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'EndpointName': 'huggingface-pytorch-inference-2022-06-06-02-48-36-821',\n",
       " 'EndpointArn': 'arn:aws:sagemaker:us-east-1:057716757052:endpoint/huggingface-pytorch-inference-2022-06-06-02-48-36-821',\n",
       " 'EndpointConfigName': 'huggingface-pytorch-inference-2022-06-06-02-48-36-821',\n",
       " 'ProductionVariants': [{'VariantName': 'AllTraffic',\n",
       "   'DeployedImages': [{'SpecifiedImage': '763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-inference:1.9.1-transformers4.12.3-cpu-py38-ubuntu20.04',\n",
       "     'ResolvedImage': '763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-inference@sha256:13a97f950cc426afa114b777d443e2f9c6292ac169b65340e59a86ee5315cef1',\n",
       "     'ResolutionTime': datetime.datetime(2022, 6, 6, 2, 49, 25, 659000, tzinfo=tzlocal())}],\n",
       "   'CurrentWeight': 1.0,\n",
       "   'DesiredWeight': 1.0,\n",
       "   'CurrentInstanceCount': 1,\n",
       "   'DesiredInstanceCount': 1}],\n",
       " 'EndpointStatus': 'InService',\n",
       " 'CreationTime': datetime.datetime(2022, 6, 6, 2, 48, 37, 55000, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2022, 6, 6, 2, 54, 16, 993000, tzinfo=tzlocal()),\n",
       " 'ResponseMetadata': {'RequestId': '8fdfeabd-58ad-41a8-8da0-dfc495cb03d8',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '8fdfeabd-58ad-41a8-8da0-dfc495cb03d8',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '868',\n",
       "   'date': 'Mon, 06 Jun 2022 02:54:19 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "sess.wait_for_endpoint(hf_predictor.endpoint_name, poll=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a0a74b",
   "metadata": {},
   "source": [
    "## 3.2. Wait for the endpoint jobs to complete\n",
    "\n",
    "엔드포인트가 생성될 때까지 기다립니다. 약 5-10분의 시간이 소요됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e0cdf8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b><a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region=us-east-1#/endpoints/huggingface-pytorch-inference-2022-06-06-02-48-36-821\">[Deploy model from S3] Review Endpoint</a></b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "def make_endpoint_link(region, endpoint_name, endpoint_task):\n",
    "    \n",
    "    endpoint_link = f'<b><a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={region}#/endpoints/{endpoint_name}\">{endpoint_task} Review Endpoint</a></b>'   \n",
    "    return endpoint_link \n",
    "        \n",
    "endpoint_link1 = make_endpoint_link(region, hf_predictor.endpoint_name, '[Deploy model from S3]')\n",
    "\n",
    "\n",
    "display(HTML(endpoint_link1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f615dca9",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# 4. Inference\n",
    "\n",
    "---\n",
    "\n",
    "두 개의 엔드포인트가 배포되었습니다. 샘플 데이터로 직접 추론을 수행해 봅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ba7040",
   "metadata": {},
   "source": [
    "## 4.1. SageMaker Python SDK 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b5ff748f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example request, you always need to define \"inputs\"\n",
    "payload = {\n",
    "   \"inputs\": [\n",
    "       \"정말 재미있습니다. 세 번 봐도 질리지 않아요.\",\n",
    "       \"시간이 아깝습니다. 다른 영화를 보세요.\"\n",
    "   ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee2c45a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_1', 'score': 0.9441463351249695},\n",
       " {'label': 'LABEL_0', 'score': 0.6941782832145691}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_predictor.predict(payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b364a50",
   "metadata": {},
   "source": [
    "## 4.2. Botoe3 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e087af32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "runtime_client = boto3.Session().client('sagemaker-runtime')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9dd873e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.24317169189453125 seconds ---\n",
      "result:  [{'label': 'LABEL_1', 'score': 0.9441463351249695}, {'label': 'LABEL_0', 'score': 0.6941782832145691}]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "from inference_utils import invoke_endpoint_hf\n",
    "payload_dump = json.dumps(payload)\n",
    "\n",
    "start_time = time.time()\n",
    "result = invoke_endpoint_hf(runtime_client, hf_predictor.endpoint_name, \n",
    "                         payload_dump,\n",
    "                         content_type='application/json'\n",
    "                        )\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print('result: ', result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d357c6",
   "metadata": {},
   "source": [
    "# 5. 엔드 포인트 삭제\n",
    "- 기존에 생성한 로컬 세이지 메이커 모델, 앤드포인트 컨피그, 앤드포인트 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a1fd6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Deleted model: huggingface-pytorch-inference-2022-06-06-02-48-36-525\n",
      "--- Deleted endpoint: huggingface-pytorch-inference-2022-06-06-02-48-36-821\n",
      "--- Deleted endpoint_config: huggingface-pytorch-inference-2022-06-06-02-48-36-821\n"
     ]
    }
   ],
   "source": [
    "from inference_utils import delete_endpoint\n",
    "\n",
    "client = boto3.Session().client('sagemaker')\n",
    "delete_endpoint(client, hf_predictor.endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3f55ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c281c456f1b8161c8906f4af2c08ed2c40c50136979eaae69688b01f70e9f4a9"
  },
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
