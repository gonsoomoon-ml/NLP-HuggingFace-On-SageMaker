{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94ed44ac-98e5-4200-8f1c-3adedec2866b",
   "metadata": {},
   "source": [
    "# [모듈 1.1] Semantic Textual Similarity 모델 파인 튜닝\n",
    "\n",
    "아래의 노트북은 김대근님의 워크샵을 참조 하였습니다. \n",
    "- [sentence-bert-finetuning](https://github.com/daekeun-ml/sm-kornlp-usecases/tree/main/sentence-bert-finetuning)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d897cd6-a127-4a1c-9980-aa033c332f6a",
   "metadata": {},
   "source": [
    "\n",
    "# 0. Introduction\n",
    "---\n",
    "\n",
    "본 모듈에서는 문장 임베딩을 산출하는 Sentence-BERT 모델을 STS(Semantic Textual Similarity) 데이터셋으로 파인튜닝해 봅니다.\n",
    "SentenceTransformers 패키지를 사용하면 파인튜닝을 쉽게 수행할 수 있습니다. 다만, 현 시점에는 분산 훈련 기능 지원이 잘 되지 않으므로, 대용량 데이터셋으로 파인튜닝하는 니즈가 있다면 커스텀 훈련 코드를 직접 작성하셔야 합니다.\n",
    "\n",
    "\n",
    "### References\n",
    "\n",
    "- Hugging Face Tutorial: https://huggingface.co/docs/transformers/training\n",
    "- Sentence-BERT paper: https://arxiv.org/abs/1908.10084\n",
    "- SentenceTransformers: https://www.sbert.net\n",
    "- KorNLU Datasets: https://github.com/kakaobrain/KorNLUDatasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577d681d-0f93-44ea-a3d1-0e0a9bb5e063",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "# 1. Setup Environments\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6cd89c-04e3-41d3-91b3-1aa2fe9dded8",
   "metadata": {},
   "source": [
    "#### 사용자 정의 라이브러러 환경 셋업 및 라이브러리 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69eaf22d-e370-4a9f-9cfe-f974ed79640c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d3e0887-da61-40a0-b377-cbeee07dfed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "sys.path.append('src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6d4b001-3508-4ca1-b73b-76b11fdcce7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import logging\n",
    "import argparse\n",
    "import torch\n",
    "import gzip\n",
    "import csv\n",
    "import math\n",
    "import urllib\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from datetime import datetime\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import SentenceTransformer, SentencesDataset, LoggingHandler, losses, models, util\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from sentence_transformers.readers import InputExample\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "\n",
    "from os.path import exists\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "    handlers=[LoggingHandler()]\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cdb95d-c62c-4174-a637-af73887f2785",
   "metadata": {},
   "source": [
    "# 2. 데이터 준비 및 알고리즘 훈련에 관련된 변수 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296b5a92-2172-4e9f-a36c-2497bb42d497",
   "metadata": {},
   "source": [
    "## 2.1. 데이타 저장 위치 및 모델 훈련 후의 아티펙트 위치 정의 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "970aca02-6ba6-4111-943a-8ffa15e5ead9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= 'KorSTS'\n",
    "\n",
    "train_dir = f'data/{dataset}/train'\n",
    "valid_dir = f'data/{dataset}/valid'\n",
    "test_dir = f'data/{dataset}/test'\n",
    "\n",
    "\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(valid_dir, exist_ok=True) \n",
    "os.makedirs(test_dir, exist_ok=True) \n",
    "\n",
    "chkpt_dir = f'{dataset}/chkpt'\n",
    "model_dir = f'{dataset}/model'\n",
    "output_data_dir = f'{dataset}/output'\n",
    "\n",
    "os.makedirs(chkpt_dir, exist_ok=True) \n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "os.makedirs(output_data_dir, exist_ok=True) \n",
    "\n",
    "# 기존 파일 제거\n",
    "!rm -rf {chkpt_dir} {model_dir} {output_data_dir} \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af49427d-290a-4b11-87b9-cae8740822b5",
   "metadata": {},
   "source": [
    "## 2.2. 환경 변수 정의\n",
    "- 아래의 환경 변수는 아래 `입력 변수` 를  정의 할때에 사용합니다.\n",
    "- \"잠시 이런 것이 있다\" 하고 지나가시기를 바랍니다.\n",
    "    - 아래 스크립트는 현재의 \"세이지 메이커 노트북\" 에서도 동작하고, 추후에 세이지 메이커의 도커 컨테이노를 통한 모델 훈련시에 도 사용하기 위한 코드 입니다. \n",
    "    - `os.environ.get('SM_CURRENT_HOST')` 이 NULL 이기에 아래의 환경 변수가 세팅이 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92c72675-ac16-44cc-8a79-11557785a206",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if os.environ.get('SM_CURRENT_HOST') is None:\n",
    "    is_sm_container = False\n",
    "\n",
    "    #src_dir = '/'.join(os.getcwd().split('/')[:-1])\n",
    "    src_dir = os.getcwd()\n",
    "    os.environ['SM_MODEL_DIR'] = f'{src_dir}/{model_dir}'\n",
    "    os.environ['SM_OUTPUT_DATA_DIR'] = f'{src_dir}/{output_data_dir}'\n",
    "    os.environ['SM_NUM_GPUS'] = str(torch.cuda.device_count())\n",
    "    os.environ['SM_CHANNEL_TRAIN'] = f'{src_dir}/{train_dir}'\n",
    "    os.environ['SM_CHANNEL_VALID'] = f'{src_dir}/{valid_dir}'\n",
    "    os.environ['SM_CHANNEL_TEST'] = f'{src_dir}/{test_dir}'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1215e31-b560-4ea9-8fd2-eb097c9dd30b",
   "metadata": {},
   "source": [
    "## 2.3. Argument parser 함수 준비 및 변수 로딩\n",
    "- parser_args() 를 정의하고 정의된 변수를 로딩 하여 값을 확인 합니다.\n",
    "    - 아래의 코드는 세이지 메이커에서 훈련시에 바로 재사용 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9635cf55-6781-4f0b-bed4-c4c49a76619c",
   "metadata": {
    "tags": []
   },
   "source": [
    "주피터 노트북에서 곧바로 실행할 수 있도록 설정값들을 로드합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c512803f-d734-4edd-a868-0f369f6b3888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-15 07:09:00 - ***** Arguments *****\n",
      "\n",
      "2022-08-15 07:09:00 - epochs=1\n",
      "seed=42\n",
      "train_batch_size=32\n",
      "eval_batch_size=32\n",
      "warmup_steps=100\n",
      "logging_steps=100\n",
      "learning_rate=5e-05\n",
      "disable_tqdm=False\n",
      "fp16=True\n",
      "tokenizer_id=sentence-transformers/xlm-r-100langs-bert-base-nli-stsb-mean-tokens\n",
      "model_id=sentence-transformers/xlm-r-100langs-bert-base-nli-stsb-mean-tokens\n",
      "output_data_dir=/home/ec2-user/SageMaker/NLP-HuggingFace-On-SageMaker/3_Semantic-Textual-Similarity/3_Training/KorSTS/output\n",
      "model_dir=/home/ec2-user/SageMaker/NLP-HuggingFace-On-SageMaker/3_Semantic-Textual-Similarity/3_Training/KorSTS/model\n",
      "n_gpus=4\n",
      "train_dir=/home/ec2-user/SageMaker/NLP-HuggingFace-On-SageMaker/3_Semantic-Textual-Similarity/3_Training/data/KorSTS/train\n",
      "valid_dir=/home/ec2-user/SageMaker/NLP-HuggingFace-On-SageMaker/3_Semantic-Textual-Similarity/3_Training/data/KorSTS/valid\n",
      "test_dir=/home/ec2-user/SageMaker/NLP-HuggingFace-On-SageMaker/3_Semantic-Textual-Similarity/3_Training/data/KorSTS/test\n",
      "chkpt_dir=KorSTS/chkpt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def parser_args(train_notebook=False):\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # 알고리즘에 대한 사용자 정의 세팅\n",
    "    parser.add_argument(\"--epochs\", type=int, default=1)\n",
    "    parser.add_argument(\"--seed\", type=int, default=42)\n",
    "    parser.add_argument(\"--train_batch_size\", type=int, default=32)\n",
    "    parser.add_argument(\"--eval_batch_size\", type=int, default=32)\n",
    "    parser.add_argument(\"--warmup_steps\", type=int, default=100)\n",
    "    parser.add_argument(\"--logging_steps\", type=int, default=100)\n",
    "    parser.add_argument(\"--learning_rate\", type=str, default=5e-5)\n",
    "    parser.add_argument(\"--disable_tqdm\", type=bool, default=False)\n",
    "    parser.add_argument(\"--fp16\", type=bool, default=True)\n",
    "    parser.add_argument(\"--tokenizer_id\", type=str, default='sentence-transformers/xlm-r-100langs-bert-base-nli-stsb-mean-tokens')\n",
    "    parser.add_argument(\"--model_id\", type=str, default='sentence-transformers/xlm-r-100langs-bert-base-nli-stsb-mean-tokens')\n",
    "    \n",
    "    # SageMaker Container environment\n",
    "    parser.add_argument(\"--output_data_dir\", type=str, default=os.environ[\"SM_OUTPUT_DATA_DIR\"])\n",
    "    parser.add_argument(\"--model_dir\", type=str, default=os.environ[\"SM_MODEL_DIR\"])\n",
    "    parser.add_argument(\"--n_gpus\", type=str, default=os.environ[\"SM_NUM_GPUS\"])\n",
    "    parser.add_argument(\"--train_dir\", type=str, default=os.environ[\"SM_CHANNEL_TRAIN\"])\n",
    "    parser.add_argument(\"--valid_dir\", type=str, default=os.environ[\"SM_CHANNEL_VALID\"])\n",
    "    parser.add_argument(\"--test_dir\", type=str, default=os.environ[\"SM_CHANNEL_TEST\"])    \n",
    "    parser.add_argument('--chkpt_dir', type=str, default='/opt/ml/checkpoints')     \n",
    "\n",
    "    if train_notebook:\n",
    "        args = parser.parse_args([])\n",
    "    else:\n",
    "        args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "\n",
    "args = parser_args(train_notebook=True) \n",
    "\n",
    "args.chkpt_dir = chkpt_dir\n",
    "logger.info(\"***** Arguments *****\\n\")\n",
    "logger.info(''.join(f'{k}={v}\\n' for k, v in vars(args).items()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5478a4d9-eaad-4652-8b1a-141d40b18d88",
   "metadata": {},
   "source": [
    "# 3. Data Preparation\n",
    "---\n",
    "본 핸즈온에서 사용할 데이터셋은 KorSTS (https://github.com/kakaobrain/KorNLUDatasets) 와 KLUE-STS (https://github.com/KLUE-benchmark/KLUE) 입니다.\n",
    "단일 데이터셋으로 훈련해도 무방하지만, 두 데이터셋을 모두 활용하여 훈련 시, 약간의 성능 향상이 있습니다.\n",
    "\n",
    "### Training Tips\n",
    "SBERT 훈련은 일반적으로 아래 3가지 방법들을 베이스라인으로 사용합니다.\n",
    "1. NLI (Natural Language Inference) 데이터셋으로 훈련\n",
    "2. STS 데이터셋으로 훈련\n",
    "3. NLI 데이터셋으로 훈련 후 STS 데이터셋으로 파인튜닝\n",
    "\n",
    "한국어 데이터의 경우, STS의 훈련 데이터가 상대적으로 적음에도 불구하고 NLI 기반 모델보다 예측 성능이 우수합니다. 따라서, 2번째 방법으로 진행합니다. <br>\n",
    "다만, STS보다 조금 더 좋은 예측 성능을 원한다면 NLI 데이터로 먼저 훈련하고 STS 데이터셋으로 이어서 훈련하는 것을 권장합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa546b9-2072-42f3-b886-18a06069edf0",
   "metadata": {},
   "source": [
    "## 3.1. KLUE-STS 데이터셋 다운로드 및 피쳐셋 생성\n",
    "KLUE-STS 데이터셋을 허깅페이스 데이터셋 허브에서 다운로드 후, SBERT 훈련에 필요한 피쳐셋을 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc5b4880-9907-44f0-9e45-2e67f3938a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-15 07:09:00 - Read KLUE-STS train/dev dataset\n",
      "2022-08-15 07:09:01 - Reusing dataset klue (/home/ec2-user/.cache/huggingface/datasets/klue/sts/1.0.0/e0fc3bc3de3eb03be2c92d72fd04a60ecc71903f821619cb28ca0e1e29e4233e)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d31d9bf42eb4401c9fea5268090a5b5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logger.info(\"Read KLUE-STS train/dev dataset\")\n",
    "datasets = load_dataset(\"klue\", \"sts\")\n",
    "\n",
    "train_samples = []\n",
    "dev_samples = []\n",
    "\n",
    "for phase in [\"train\", \"validation\"]:\n",
    "    examples = datasets[phase]\n",
    "\n",
    "    for example in examples:\n",
    "        score = float(example[\"labels\"][\"label\"]) / 5.0  # 0.0 ~ 1.0 스케일로 유사도 정규화\n",
    "        inp_example = InputExample(texts=[example[\"sentence1\"], example[\"sentence2\"]], label=score)\n",
    "\n",
    "        if phase == \"validation\":\n",
    "            dev_samples.append(inp_example)\n",
    "        else:\n",
    "            train_samples.append(inp_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f8f0110-b122-4597-bbb7-559e67c39032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev_samples:  519\n",
      "train_samples:  11668\n"
     ]
    }
   ],
   "source": [
    "print(\"dev_samples: \", len(dev_samples))\n",
    "print(\"train_samples: \", len(train_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e95be88f-ab30-487a-814e-fb714b0c0314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 2 is \n",
      "\n",
      "0.74 ['숙소 위치는 찾기 쉽고 일반적인 한국의 반지하 숙소입니다.', '숙박시설의 위치는 쉽게 찾을 수 있고 한국의 대표적인 반지하 숙박시설입니다.']\n",
      "0.0 ['위반행위 조사 등을 거부·방해·기피한 자는 500만원 이하 과태료 부과 대상이다.', '시민들 스스로 자발적인 예방 노력을\\xa0한 것은 아산 뿐만이 아니었다.']\n",
      "\n",
      "The last 2 is \n",
      "\n",
      "0.9400000000000001 ['개 1마리 고양이 3마리 너무 귀여워요!', '개 한 마리와 고양이 세 마리는 정말 귀여워요!']\n",
      "0.6599999999999999 ['학회 홍보 메일은 회신 메일을 보내지마', '학회 홍보 메일은 회신 하지마']\n"
     ]
    }
   ],
   "source": [
    "num = 2\n",
    "def show_head_tail_samples(num, train_samples ):\n",
    "    print(f\"The first {num} is \\n\")\n",
    "    for i in range(num):\n",
    "        print(train_samples[i].label , train_samples[i].texts)\n",
    "\n",
    "    print(f\"\\nThe last {num} is \\n\")    \n",
    "    for i in range(len(train_samples) -num, len(train_samples)):\n",
    "        print(train_samples[i].label , train_samples[i].texts)    \n",
    "        \n",
    "show_head_tail_samples(num, train_samples)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972b0261-3a0e-4612-b1ff-128a46fb37fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "## 3.2. KorSTS 데이터셋 다운로드 및 피쳐셋 생성\n",
    "KorSTS 데이터셋은 허깅페이스에도 등록되어 있지만, 향후 여러분의 커스텀 데이터셋을 같이 사용하는 유즈케이스를 고려하여 GitHub의 데이터셋을 다운로드받아 사용하겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "589cb12d-9a43-4651-912c-466dbbfcd75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-15 07:09:02 - File exists\n"
     ]
    }
   ],
   "source": [
    "repo = 'https://raw.githubusercontent.com/kakaobrain/KorNLUDatasets/master/KorSTS'\n",
    "sts_train = f'{args.train_dir}/sts-train.tsv'\n",
    "sts_valid = f'{args.valid_dir}/sts-dev.tsv'\n",
    "sts_test = f'{args.test_dir}/sts-test.tsv'\n",
    "\n",
    "if exists(sts_train) and exists(sts_valid) and exists(sts_test):\n",
    "    logger.info(\"File exists\")\n",
    "else: \n",
    "    logger.info(\"File is downloaded\")\n",
    "    urllib.request.urlretrieve(f'{repo}/sts-train.tsv', filename=f'{args.train_dir}/sts-train.tsv')\n",
    "    urllib.request.urlretrieve(f'{repo}/sts-dev.tsv', filename=f'{args.valid_dir}/sts-dev.tsv')\n",
    "    urllib.request.urlretrieve(f'{repo}/sts-test.tsv', filename=f'{args.test_dir}/sts-test.tsv')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ad5f3ed-a0b9-4970-9b11-e3740cd92aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-15 07:09:02 - Read KorSTS train dataset\n",
      "2022-08-15 07:09:02 - Read KorSTS dev dataset\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Read KorSTS train dataset\")\n",
    "\n",
    "with open(f'{args.train_dir}/sts-train.tsv', 'rt', encoding='utf8') as fIn:\n",
    "    reader = csv.DictReader(fIn, delimiter='\\t', quoting=csv.QUOTE_NONE)\n",
    "    for row in reader:\n",
    "        if row[\"sentence1\"] and row[\"sentence2\"]:          \n",
    "            score = float(row['score']) / 5.0  # Normalize score to range 0 ... 1\n",
    "            inp_example = InputExample(texts=[row['sentence1'], row['sentence2']], label=score)\n",
    "            train_samples.append(inp_example)\n",
    "            \n",
    "logging.info(\"Read KorSTS dev dataset\")            \n",
    "with open(f'{args.valid_dir}/sts-dev.tsv', 'rt', encoding='utf8') as fIn:\n",
    "    reader = csv.DictReader(fIn, delimiter='\\t', quoting=csv.QUOTE_NONE)\n",
    "    for row in reader:\n",
    "        if row[\"sentence1\"] and row[\"sentence2\"]:        \n",
    "            score = float(row['score']) / 5.0  # Normalize score to range 0 ... 1\n",
    "            inp_example = InputExample(texts=[row['sentence1'], row['sentence2']], label=score)\n",
    "            dev_samples.append(inp_example)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57247912-538a-497d-8739-c58407b41a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev_samples:  2019\n",
      "train_samples:  17417\n"
     ]
    }
   ],
   "source": [
    "print(\"dev_samples: \", len(dev_samples))\n",
    "print(\"train_samples: \", len(train_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dba029c5-338e-4843-b37a-8c48689d27c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 2 is \n",
      "\n",
      "0.74 ['숙소 위치는 찾기 쉽고 일반적인 한국의 반지하 숙소입니다.', '숙박시설의 위치는 쉽게 찾을 수 있고 한국의 대표적인 반지하 숙박시설입니다.']\n",
      "0.0 ['위반행위 조사 등을 거부·방해·기피한 자는 500만원 이하 과태료 부과 대상이다.', '시민들 스스로 자발적인 예방 노력을\\xa0한 것은 아산 뿐만이 아니었다.']\n",
      "\n",
      "The last 2 is \n",
      "\n",
      "0.0 ['중국, 인도는 양국 관계를 증진시키겠다고 맹세한다', '중국은 불안한 주식 거래자들을 안심시키기 위해 뒤뚱거리고 있다.']\n",
      "0.0 ['푸틴 대변인 : 도핑 혐의는 근거 없는 것으로 보인다.', '가장 최근의 심한 날씨 : 토네이도 후 텍사스에서 1명 사망']\n"
     ]
    }
   ],
   "source": [
    "show_head_tail_samples(num, train_samples)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118a5b4e-81b3-48ad-b97e-b0cb8f98b099",
   "metadata": {},
   "source": [
    "# 4. Training\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d7fdc0-6779-44d1-b9b6-c2a7a5d43706",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4.1. Model 준비\n",
    "\n",
    "- model_name = 'sentence-transformers/xlm-r-100langs-bert-base-nli-stsb-mean-tokens'\n",
    "    - https://huggingface.co/sentence-transformers/xlm-r-100langs-bert-base-nli-stsb-mean-tokens\n",
    "        - 모델의 이름은 'xlm-r-100langs-bert-base-nli-stsb-mean-tokens'인데 이름이 의미하는 바는 100가지 언어를 지원(한국어 포함)하는 다국어 BERT BASE 모델로 SNLI 데이터를 학습 후 STS-B 데이터로 학습되었으며, 문장 표현을 얻기 위해서는 평균 풀링(mean-tokens)을 사용했다는 의미입니다. 다시 말해서 NLI 데이터를 학습 후에 STS 데이터로 추가 파인 튜닝한 모델이라는 의미입니다.    \n",
    "        - 출처: [08) BERT의 문장 임베딩(SBERT)을 이용한 한국어 챗봇](https://wikidocs.net/154530)\n",
    "    - 위 사이트에 Deprecated 되었다고 하지만, 아래에서 훈련후 Kor-STS Test Data 로 0.801 의 유사도 나옴.\n",
    "- model_name = 'sentence-transformers/distiluse-base-multilingual-cased-v1'     \n",
    "    - https://www.sbert.net/docs/pretrained_models.html#multi-lingual-models\n",
    "    - 아래에서 훈련후 Kor-STS Test Data 로 0.831 의 유사도 나옴."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ef7a33c-a8bc-427c-a64f-c5d7dfa5a09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-15 07:09:03 - /home/ec2-user/SageMaker/NLP-HuggingFace-On-SageMaker/3_Semantic-Textual-Similarity/3_Training/KorSTS/model/training_sts_sentence-transformers-xlm-r-100langs-bert-base-nli-stsb-mean-tokens-2022-08-15_07-09-03\n"
     ]
    }
   ],
   "source": [
    "model_name = 'sentence-transformers/xlm-r-100langs-bert-base-nli-stsb-mean-tokens'\n",
    "# model_name = 'sentence-transformers/distiluse-base-multilingual-cased-v1'\n",
    "\n",
    "train_batch_size = args.train_batch_size\n",
    "num_epochs = args.epochs\n",
    "model_save_path = f'{args.model_dir}/training_sts_'+model_name.replace(\"/\", \"-\")+'-'+datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "logger.info(model_save_path)\n",
    "\n",
    "# Use Huggingface/transformers model (like BERT, RoBERTa, XLNet, XLM-R) for mapping tokens to embeddings\n",
    "word_embedding_model = models.Transformer(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b92c650-3ae4-4319-a756-8457b8f03c97",
   "metadata": {},
   "source": [
    "문장 임베딩을 계산하기 위한 Pooler를 정의합니다. BERT로 분류 태스크를 수행할 때는 첫 번째 [CLS] 토큰의 출력 벡터를 임베딩 벡터로 사용하지만, SBERT에서는 BERT의 모든 토큰들의 출력 벡터들을 사용하여 임베딩 벡터를 계산합니다. 이 때 mean pooling이나 max pooling을 사용할 수 있으며, 본 예제에서는 mean pooling을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b01d0e7c-0ac6-410a-b07d-9fdbea08162c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-15 07:09:07 - Use pytorch device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Apply mean pooling to get one fixed sized sentence vector\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(),\n",
    "                               pooling_mode_mean_tokens=True,\n",
    "                               pooling_mode_cls_token=False,\n",
    "                               pooling_mode_max_tokens=False)\n",
    "\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4932a6fd-a2f2-4235-8c0a-dce48dff0281",
   "metadata": {},
   "source": [
    "## 4.2. 데이터 로더 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9d05c9e-de08-410d-ace1-07212e4e4625",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SentencesDataset(train_samples, model)\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=train_batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abad28b2-2ac0-4937-8a09-6f995dafe178",
   "metadata": {},
   "source": [
    "## 4.3. Loss 및 evaluator 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c317c627-4ee2-4eca-bd12-dc25a76dfef2",
   "metadata": {},
   "source": [
    "모델 훈련 및 검증에 필요한 클래스 인스턴스를 생성합니다. 베이스라인으로 사용되는 검증 지표는 두 문장의 임베딩 벡터의 유사도를 산출하는 코사인 유사도입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f20d8263-04b6-498e-aa67-55dd266274b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-15 07:09:07 - Warmup-steps: 55\n"
     ]
    }
   ],
   "source": [
    "train_loss = losses.CosineSimilarityLoss(model=model)\n",
    "\n",
    "evaluator = EmbeddingSimilarityEvaluator.from_input_examples(dev_samples, name='sts-dev')\n",
    "\n",
    "warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1) # 10% of train data for warm-up\n",
    "logger.info(\"Warmup-steps: {}\".format(warmup_steps))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e178954-f94a-4f8c-8a05-6c396d10f9e6",
   "metadata": {},
   "source": [
    "훈련을 수행합니다. 분산 훈련을 수행하지는 않지만, 데이터 볼륨이 크지 않으므로 수 분 내에 훈련이 완료됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e990ec0-0bd7-40dd-b276-0d91a3758188",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4.4. 훈련 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3905a80-e2c9-4295-a34b-70f12920dad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8139295c057f4848ab175c1d5fb4ce84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b143c105e8d4388a9794ea966cf2a59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/545 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-15 07:09:48 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset in epoch 0 after 272 steps:\n",
      "2022-08-15 07:09:51 - Cosine-Similarity :\tPearson: 0.8449\tSpearman: 0.8451\n",
      "2022-08-15 07:09:51 - Manhattan-Distance:\tPearson: 0.8340\tSpearman: 0.8370\n",
      "2022-08-15 07:09:51 - Euclidean-Distance:\tPearson: 0.8346\tSpearman: 0.8376\n",
      "2022-08-15 07:09:51 - Dot-Product-Similarity:\tPearson: 0.8101\tSpearman: 0.8113\n",
      "2022-08-15 07:09:51 - Save model to /home/ec2-user/SageMaker/NLP-HuggingFace-On-SageMaker/3_Semantic-Textual-Similarity/3_Training/KorSTS/model/training_sts_sentence-transformers-xlm-r-100langs-bert-base-nli-stsb-mean-tokens-2022-08-15_07-09-03\n",
      "2022-08-15 07:10:31 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset in epoch 0 after 544 steps:\n",
      "2022-08-15 07:10:35 - Cosine-Similarity :\tPearson: 0.8500\tSpearman: 0.8500\n",
      "2022-08-15 07:10:35 - Manhattan-Distance:\tPearson: 0.8356\tSpearman: 0.8394\n",
      "2022-08-15 07:10:35 - Euclidean-Distance:\tPearson: 0.8361\tSpearman: 0.8401\n",
      "2022-08-15 07:10:35 - Dot-Product-Similarity:\tPearson: 0.8130\tSpearman: 0.8162\n",
      "2022-08-15 07:10:35 - Save model to /home/ec2-user/SageMaker/NLP-HuggingFace-On-SageMaker/3_Semantic-Textual-Similarity/3_Training/KorSTS/model/training_sts_sentence-transformers-xlm-r-100langs-bert-base-nli-stsb-mean-tokens-2022-08-15_07-09-03\n",
      "2022-08-15 07:10:38 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset after epoch 0:\n",
      "2022-08-15 07:10:42 - Cosine-Similarity :\tPearson: 0.8500\tSpearman: 0.8500\n",
      "2022-08-15 07:10:42 - Manhattan-Distance:\tPearson: 0.8356\tSpearman: 0.8394\n",
      "2022-08-15 07:10:42 - Euclidean-Distance:\tPearson: 0.8361\tSpearman: 0.8401\n",
      "2022-08-15 07:10:42 - Dot-Product-Similarity:\tPearson: 0.8130\tSpearman: 0.8162\n",
      "2022-08-15 07:10:42 - Save model to /home/ec2-user/SageMaker/NLP-HuggingFace-On-SageMaker/3_Semantic-Textual-Similarity/3_Training/KorSTS/model/training_sts_sentence-transformers-xlm-r-100langs-bert-base-nli-stsb-mean-tokens-2022-08-15_07-09-03\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    evaluator=evaluator,\n",
    "    epochs=num_epochs,\n",
    "    evaluation_steps=int(len(train_dataloader)*0.5),\n",
    "    warmup_steps=warmup_steps,\n",
    "    output_path=model_save_path,\n",
    "    use_amp=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e370591f-cb30-4b2e-a637-c664ef8fc918",
   "metadata": {},
   "source": [
    "\n",
    "# 5. 모델 평가\n",
    "---\n",
    "훈련이 완료되었다면, 테스트 데이터셋으로 예측 성능을 볼 수 있는 지표들을 산출합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cee8590-c2c4-4a8a-b765-6ad5f7bcd03e",
   "metadata": {},
   "source": [
    "## 5.1. Test 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b94aa7e-ff24-453c-a0c5-28ee104b89c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-15 07:10:45 - Read KorSTS test dataset\n"
     ]
    }
   ],
   "source": [
    "test_samples = []\n",
    "logger.info(\"Read KorSTS test dataset\")            \n",
    "with open(f'{args.test_dir}/sts-test.tsv', 'rt', encoding='utf8') as fIn:\n",
    "    reader = csv.DictReader(fIn, delimiter='\\t', quoting=csv.QUOTE_NONE)\n",
    "    for row in reader:\n",
    "        if row[\"sentence1\"] and row[\"sentence2\"]:        \n",
    "            score = float(row['score']) / 5.0  # Normalize score to range 0 ... 1\n",
    "            inp_example = InputExample(texts=[row['sentence1'], row['sentence2']], label=score)\n",
    "            test_samples.append(inp_example)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a5807b-311a-4120-a6dd-c2befe15ff23",
   "metadata": {},
   "source": [
    "## 5.2. 훈련된 모델 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a14d71a6-8e0a-472b-80f0-382efb4c4895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_save_path: \n",
      " /home/ec2-user/SageMaker/NLP-HuggingFace-On-SageMaker/3_Semantic-Textual-Similarity/3_Training/KorSTS/model/training_sts_sentence-transformers-xlm-r-100langs-bert-base-nli-stsb-mean-tokens-2022-08-15_07-09-03 \n",
      "\n",
      "\n",
      "2022-08-15 07:10:45 - Load pretrained SentenceTransformer: /home/ec2-user/SageMaker/NLP-HuggingFace-On-SageMaker/3_Semantic-Textual-Similarity/3_Training/KorSTS/model/training_sts_sentence-transformers-xlm-r-100langs-bert-base-nli-stsb-mean-tokens-2022-08-15_07-09-03\n",
      "2022-08-15 07:10:49 - Use pytorch device: cuda\n"
     ]
    }
   ],
   "source": [
    "##############################################################################\n",
    "# Load the stored model and evaluate its performance on STS benchmark dataset\n",
    "##############################################################################\n",
    "\n",
    "print(\"model_save_path: \\n\", model_save_path, \"\\n\\n\")\n",
    "model = SentenceTransformer(model_save_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08f75dc-6455-469a-9f64-17769a5d20a3",
   "metadata": {},
   "source": [
    "## 5.3. Evaluator 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98a96778-da38-41d7-b617-25db5b721c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-15 07:10:49 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-test dataset:\n",
      "2022-08-15 07:10:52 - Cosine-Similarity :\tPearson: 0.8285\tSpearman: 0.8298\n",
      "2022-08-15 07:10:52 - Manhattan-Distance:\tPearson: 0.8233\tSpearman: 0.8275\n",
      "2022-08-15 07:10:52 - Euclidean-Distance:\tPearson: 0.8237\tSpearman: 0.8279\n",
      "2022-08-15 07:10:52 - Dot-Product-Similarity:\tPearson: 0.7628\tSpearman: 0.7611\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8298312989794001"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(test_samples, name='sts-test')\n",
    "test_evaluator(model, output_path=model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91d30ea-2685-4c0f-8cd0-b6b8662fea82",
   "metadata": {},
   "source": [
    "# 6. 모델 경로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4603373-7677-4e1b-bfb4-47244ac148bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'model_save_path' (str)\n"
     ]
    }
   ],
   "source": [
    "%store model_save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9c968f-1c33-4a2b-95a7-99288d175785",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
